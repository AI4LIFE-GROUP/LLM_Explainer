{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import Vocab\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:21.072784Z",
     "start_time": "2024-06-06T01:43:21.069757Z"
    }
   },
   "id": "2f9e2ad29b1eedff",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9250d84e33de9832",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:23.051746Z",
     "start_time": "2024-06-06T01:43:23.049839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the All_Beauty reviews file you downloaded\n",
    "reviews_file_path = 'All_Beauty.jsonl'\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the reviews and the ratings\n",
    "texts, ratings = [], []\n",
    "with open(reviews_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        review = json.loads(line.strip())\n",
    "        texts.append(review['text'])\n",
    "        ratings.append(review['rating'])"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:25.919547Z",
     "start_time": "2024-06-06T01:43:23.259648Z"
    }
   },
   "id": "initial_id",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get indices where number of words is > 5 and number of words is < 100\n",
    "indices = [i for i, text in enumerate(texts) if 5 < len(text.split()) < 100]\n",
    "texts = [texts[i] for i in indices]\n",
    "ratings = [ratings[i] for i in indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:26.797647Z",
     "start_time": "2024-06-06T01:43:25.920714Z"
    }
   },
   "id": "92298968a0dd52c2",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert ratings to binary sentiment (1 for positive, 0 for negative)\n",
    "sentiments = [1 if rating >= 4 else 0 for rating in ratings]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, sentiments, test_size=0.2, random_state=SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:26.944470Z",
     "start_time": "2024-06-06T01:43:26.798453Z"
    }
   },
   "id": "1798ae5c06e9b573",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pkl the train and test data\n",
    "train_df = pd.DataFrame({'text': X_train, 'sentiment': y_train})\n",
    "test_df = pd.DataFrame({'text': X_test, 'sentiment': y_test})\n",
    "train_df.to_pickle('beauty-train.pkl')\n",
    "test_df.to_pickle('beauty-test.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:27.439892Z",
     "start_time": "2024-06-06T01:43:26.946057Z"
    }
   },
   "id": "f158be4817dcb1e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(434663, 108666)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:27.471557Z",
     "start_time": "2024-06-06T01:43:27.440739Z"
    }
   },
   "id": "9409a62bb82d449f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14635\n",
      "Num of classes: 2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "word_counter = Counter()\n",
    "for (line, label) in zip(X_train, y_train):\n",
    "    word_counter.update(tokenizer(line))\n",
    "voc = Vocab(word_counter, min_freq=10)\n",
    "\n",
    "print('Vocabulary size:', len(voc))\n",
    "\n",
    "num_class = len(set(y_train))\n",
    "print('Num of classes:', num_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:34.277263Z",
     "start_time": "2024-06-06T01:43:28.842551Z"
    }
   },
   "id": "7eb8348a4b60e31d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class EmbeddingBagModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs, offsets):\n",
    "        embedded = self.embedding(inputs, offsets)\n",
    "        return self.linear(embedded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:43:34.281690Z",
     "start_time": "2024-06-06T01:43:34.278481Z"
    }
   },
   "id": "aa87561ee014896d",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels = torch.tensor([label for _, label in batch]) \n",
    "    text_list = [tokenizer(line) for line, _ in batch]\n",
    "    \n",
    "    # flatten tokens across the whole batch\n",
    "    text = torch.tensor([voc[t] for tokens in text_list for t in tokens])\n",
    "    tokenized_list = [torch.tensor([voc[t] for t in tokens]) for tokens in text_list]\n",
    "    # the offset of each example\n",
    "    offsets = torch.tensor(\n",
    "        [0] + [len(tokens) for tokens in text_list][:-1]\n",
    "    ).cumsum(dim=0)\n",
    "\n",
    "    return labels, text, offsets, tokenized_list\n",
    "\n",
    "train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(list(zip(X_test, y_test)), batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:43:25.489072Z",
     "start_time": "2024-06-06T16:43:25.357422Z"
    }
   },
   "id": "7e5985ec22764fd9",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1 |   500/ 6792 batches | accuracy    0.729\n",
      "epoch   1 |  1000/ 6792 batches | accuracy    0.834\n",
      "epoch   1 |  1500/ 6792 batches | accuracy    0.862\n",
      "epoch   1 |  2000/ 6792 batches | accuracy    0.875\n",
      "epoch   1 |  2500/ 6792 batches | accuracy    0.876\n",
      "epoch   1 |  3000/ 6792 batches | accuracy    0.881\n",
      "epoch   1 |  3500/ 6792 batches | accuracy    0.885\n",
      "epoch   1 |  4000/ 6792 batches | accuracy    0.886\n",
      "epoch   1 |  4500/ 6792 batches | accuracy    0.888\n",
      "epoch   1 |  5000/ 6792 batches | accuracy    0.887\n",
      "epoch   1 |  5500/ 6792 batches | accuracy    0.888\n",
      "epoch   1 |  6000/ 6792 batches | accuracy    0.888\n",
      "epoch   1 |  6500/ 6792 batches | accuracy    0.894\n",
      "-----------------------------------------------------------\n",
      "end of epoch   1 | valid accuracy    0.891 \n",
      "-----------------------------------------------------------\n",
      "epoch   2 |   500/ 6792 batches | accuracy    0.896\n",
      "epoch   2 |  1000/ 6792 batches | accuracy    0.898\n",
      "epoch   2 |  1500/ 6792 batches | accuracy    0.897\n",
      "epoch   2 |  2000/ 6792 batches | accuracy    0.896\n",
      "epoch   2 |  2500/ 6792 batches | accuracy    0.896\n",
      "epoch   2 |  3000/ 6792 batches | accuracy    0.897\n",
      "epoch   2 |  3500/ 6792 batches | accuracy    0.897\n",
      "epoch   2 |  4000/ 6792 batches | accuracy    0.895\n",
      "epoch   2 |  4500/ 6792 batches | accuracy    0.895\n",
      "epoch   2 |  5000/ 6792 batches | accuracy    0.899\n",
      "epoch   2 |  5500/ 6792 batches | accuracy    0.892\n",
      "epoch   2 |  6000/ 6792 batches | accuracy    0.895\n",
      "epoch   2 |  6500/ 6792 batches | accuracy    0.897\n",
      "-----------------------------------------------------------\n",
      "end of epoch   2 | valid accuracy    0.894 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "EMB_SIZE = 64\n",
    "CHECKPOINT = './models/embedding_bag_beauty.pt'\n",
    "USE_PRETRAINED = False  # change to False if you want to retrain your own model\n",
    "\n",
    "def train_model(train_loader, val_loader):\n",
    "    model = EmbeddingBagModel(len(voc), EMB_SIZE, num_class)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):      \n",
    "        # training\n",
    "        model.train()\n",
    "        total_acc, total_count = 0, 0\n",
    "        \n",
    "        for idx, (label, text, offsets, _) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predited_label = model(text, offsets)\n",
    "            loss(predited_label, label).backward()\n",
    "            optimizer.step()\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print('epoch {:3d} | {:5d}/{:5d} batches | accuracy {:8.3f}'.format(\n",
    "                    epoch, idx + 1, len(train_loader), total_acc / total_count\n",
    "                ))\n",
    "                total_acc, total_count = 0, 0       \n",
    "        \n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for label, text, offsets, _ in val_loader:\n",
    "                predited_label = model(text, offsets)\n",
    "                total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "                total_count += label.size(0)\n",
    "\n",
    "        print('-' * 59)\n",
    "        print('end of epoch {:3d} | valid accuracy {:8.3f} '.format(epoch, total_acc / total_count))\n",
    "        print('-' * 59)\n",
    "    \n",
    "    torch.save(model, CHECKPOINT)\n",
    "    return model\n",
    "        \n",
    "eb_model = torch.load(CHECKPOINT) if USE_PRETRAINED else train_model(train_loader, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:47:53.462330Z",
     "start_time": "2024-06-06T01:47:06.399290Z"
    }
   },
   "id": "b836fcfc02c90d4d",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probability: 0.757\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "test_label = 1 \n",
    "test_line = ('I sort of like this product, its really not my favorite, but it really isnt the best. could be way better.')\n",
    "\n",
    "test_labels, test_text, test_offsets, _ = collate_batch([(test_line, test_label)])\n",
    "\n",
    "probs = F.softmax(eb_model(test_text, test_offsets), dim=1).squeeze(0)\n",
    "print('Prediction probability:', round(probs[test_labels[0]].item(), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:43:58.174184Z",
     "start_time": "2024-06-06T16:43:58.168794Z"
    }
   },
   "id": "8e52ee8551f92f7a",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2430, 0.7570], grad_fn=<SqueezeBackward1>)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:43:59.491380Z",
     "start_time": "2024-06-06T16:43:59.488570Z"
    }
   },
   "id": "a2ddfbf7897e87c",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from captum.attr import Lime, LimeBase\n",
    "from captum._utils.models.linear_model import SkLearnLinearRegression, SkLearnLasso"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:44:05.038569Z",
     "start_time": "2024-06-06T16:44:05.036643Z"
    }
   },
   "id": "9c54a9c0dedb7957",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove the batch dimension for the embedding-bag model\n",
    "def forward_func(text, offsets):\n",
    "    return eb_model(text.squeeze(0), offsets)\n",
    "\n",
    "# encode text indices into latent representations & calculate cosine similarity\n",
    "def exp_embedding_cosine_distance(original_inp, perturbed_inp, _, **kwargs):\n",
    "    original_emb = eb_model.embedding(original_inp, None)\n",
    "    perturbed_emb = eb_model.embedding(perturbed_inp, None)\n",
    "    distance = 1 - F.cosine_similarity(original_emb, perturbed_emb, dim=1)\n",
    "    return torch.exp(-1 * (distance ** 2) / 2)\n",
    "\n",
    "# binary vector where each word is selected independently and uniformly at random\n",
    "def bernoulli_perturb(text, **kwargs):\n",
    "    probs = torch.ones_like(text) * 0.5\n",
    "    return torch.bernoulli(probs).long()\n",
    "\n",
    "# remove absenst token based on the intepretable representation sample\n",
    "def interp_to_input(interp_sample, original_input, **kwargs):\n",
    "    return original_input[interp_sample.bool()].view(original_input.size(0), -1)\n",
    "\n",
    "lasso_lime_base = LimeBase(\n",
    "    forward_func, \n",
    "    interpretable_model=SkLearnLasso(alpha=0.08),\n",
    "    similarity_func=exp_embedding_cosine_distance,\n",
    "    perturb_func=bernoulli_perturb,\n",
    "    perturb_interpretable_space=True,\n",
    "    from_interp_rep_transform=interp_to_input,\n",
    "    to_interp_rep_transform=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:44:05.612633Z",
     "start_time": "2024-06-06T16:44:05.608952Z"
    }
   },
   "id": "de3143f011d1cb80",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([   3, 1526,   16,   34,   11,   31,    7,  150,   46,   18,   12,  312,\n            7,   17,    5,   46, 2860,    4,  120,    2,  179,   45,  128,  112,\n            2]),\n tensor([1]))"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T18:29:57.009984Z",
     "start_time": "2024-06-06T18:29:57.006039Z"
    }
   },
   "id": "31d6a18d85c35407",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_tokenized_sents = next(iter(train_loader))[3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:45:02.373803Z",
     "start_time": "2024-06-06T16:45:02.360666Z"
    }
   },
   "id": "5d142f48d2164c3c",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 0, 0, 1, 1, 1, 1, 0, 1])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli_perturb(batch_tokenized_sents[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:45:17.096420Z",
     "start_time": "2024-06-06T16:45:17.093317Z"
    }
   },
   "id": "9a50534a7fc691d7",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Lime Base attribution:   0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5599cf8361a4d3faa7bb79f5905c5af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution range: -0.8227580189704895 to 1.4743865728378296\n"
     ]
    }
   ],
   "source": [
    "attrs = lasso_lime_base.attribute(\n",
    "    test_text.unsqueeze(0), # add batch dimension for Captum\n",
    "    target=test_labels,\n",
    "    additional_forward_args=(test_offsets,),\n",
    "    n_samples=16,\n",
    "    show_progress=True\n",
    ").squeeze(0)\n",
    "\n",
    "print('Attribution range:', attrs.min().item(), 'to', attrs.max().item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T18:30:14.721654Z",
     "start_time": "2024-06-06T18:30:14.709821Z"
    }
   },
   "id": "e3a7c21739844d11",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def show_text_attr(attrs):\n",
    "    rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "    alpha = lambda x: abs(x) ** 0.5\n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "    ]\n",
    "    \n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T19:14:22.051558Z",
     "start_time": "2024-06-06T19:14:22.047785Z"
    }
   },
   "id": "c15471d13c2c2e5e",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Lime Base attribution:   0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f72ae72a28cd437c870e9e41710f44d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution range: -0.8754809498786926 to 1.2592147588729858\n"
     ]
    }
   ],
   "source": [
    "# positive\n",
    "attrs = lasso_lime_base.attribute(\n",
    "    test_text.unsqueeze(0), # add batch dimension for Captum\n",
    "    target=test_labels,\n",
    "    additional_forward_args=(test_offsets,),\n",
    "    n_samples=5000,\n",
    "    show_progress=True\n",
    ").squeeze(0)\n",
    "\n",
    "print('Attribution range:', attrs.min().item(), 'to', attrs.max().item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T19:15:44.975926Z",
     "start_time": "2024-06-06T19:15:44.377868Z"
    }
   },
   "id": "55f91266e8fd54b1",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">i</mark> <mark style=\"background-color:rgba(255,0,0,0.23713232774577808)\">sort</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">of</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">like</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">this</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">product</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">its</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">really</mark> <mark style=\"background-color:rgba(255,0,0,0.9356713899006919)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">my</mark> <mark style=\"background-color:rgba(0,255,0,1.1221473873217305)\">favorite</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(255,0,0,0.39577284986615413)\">but</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">it</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">really</mark> <mark style=\"background-color:rgba(255,0,0,0.5725891448667839)\">isnt</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">the</mark> <mark style=\"background-color:rgba(0,255,0,1.0416845638009236)\">best</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">could</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">be</mark> <mark style=\"background-color:rgba(255,0,0,0.3972534087786855)\">way</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">better</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">.</mark></p>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# positive\n",
    "show_text_attr(attrs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T19:15:44.983423Z",
     "start_time": "2024-06-06T19:15:44.978535Z"
    }
   },
   "id": "3e188d4988bfec00",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Lime Base attribution:   0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a15377c935747e199721fe3f4286285"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution range: -1.2927688360214233 to 0.8326038718223572\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">i</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">sort</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">of</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">like</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">this</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">product</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">its</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">really</mark> <mark style=\"background-color:rgba(0,255,0,0.9124712991773261)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">my</mark> <mark style=\"background-color:rgba(255,0,0,1.1369999278898058)\">favorite</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.3660656857123148)\">but</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">it</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">really</mark> <mark style=\"background-color:rgba(0,255,0,0.5980729289892162)\">isnt</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">the</mark> <mark style=\"background-color:rgba(255,0,0,1.003388742731309)\">best</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">could</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">be</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">way</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">better</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">.</mark></p>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# positive\n",
    "attrs = lasso_lime_base.attribute(\n",
    "    test_text.unsqueeze(0), # add batch dimension for Captum\n",
    "    target=test_labels-1,\n",
    "    additional_forward_args=(test_offsets,),\n",
    "    n_samples=5000,\n",
    "    show_progress=True\n",
    ").squeeze(0)\n",
    "\n",
    "print('Attribution range:', attrs.min().item(), 'to', attrs.max().item())\n",
    "show_text_attr(attrs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T19:15:40.678107Z",
     "start_time": "2024-06-06T19:15:39.792824Z"
    }
   },
   "id": "e425618c3a1cb295",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5000 sentences. Showing the first 10:\n",
      "Sample 0: This is an example sentence to demonstrate how to randomly remove words.\n",
      "Sample 1: is an sentence to demonstrate to remove\n",
      "Sample 2: This demonstrate\n",
      "Sample 3: This demonstrate remove words.\n",
      "Sample 4: demonstrate how remove words.\n",
      "Sample 5: This is an example to demonstrate how to randomly remove words.\n",
      "Sample 6: This an example sentence demonstrate how randomly remove words.\n",
      "Sample 7: example sentence demonstrate how randomly words.\n",
      "Sample 8: is an to demonstrate how to randomly remove words.\n",
      "Sample 9: is to to remove\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_ordered_sentence_neighborhood(sentence, num_samples=5000):\n",
    "    words = sentence.split()\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Initialize the list to store neighborhood sentences\n",
    "    neighborhood_sentences = [sentence]  # Include the original sentence as the first sample\n",
    "    \n",
    "    for _ in range(num_samples - 1):  # We already have the original sentence, hence num_samples - 1\n",
    "        num_words_to_remove = np.random.randint(1, num_words)  # Number of words to remove\n",
    "        words_to_remove = np.random.choice(range(num_words), size=num_words_to_remove, replace=False)\n",
    "        perturbed_sentence = ' '.join([word for idx, word in enumerate(words) if idx not in words_to_remove])\n",
    "        neighborhood_sentences.append(perturbed_sentence)\n",
    "    \n",
    "    return neighborhood_sentences\n",
    "\n",
    "# Example usage:\n",
    "original_sentence = \"This is an example sentence to demonstrate how to randomly remove words.\"\n",
    "\n",
    "# Generating 5000 sentences (including the original)\n",
    "neighborhood = generate_ordered_sentence_neighborhood(original_sentence)\n",
    "print(f\"Generated {len(neighborhood)} sentences. Showing the first 10:\")\n",
    "for idx, sentence in enumerate(neighborhood[:10]):\n",
    "    print(f\"Sample {idx}: {sentence}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:51:21.209033Z",
     "start_time": "2024-03-28T17:51:21.062324Z"
    }
   },
   "id": "1579420c4ce4d5b",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "39be94e14c1cdd5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm_explainer",
   "language": "python",
   "display_name": "LLM_Explainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
