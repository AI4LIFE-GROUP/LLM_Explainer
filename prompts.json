{
    "COT_0": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model, while the Output corresponds to the model's prediction.\n",
        "post_text": "\nThink step-by-step and identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the test sample (in descending order, starting with the most important feature). For the final answer, provide the list of features (in descending order, starting with the most important feature and use comma separated value format) after 'The answer is: '"
    },
    "simple_0": {
        "pre_text": "",
        "post_text": "\nPlease identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample (in descending order, starting with the most important feature). Use comma separated value format for generation. Don't provide any description of the features."
    },
    "simple_1": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model, while the Output corresponds to the model's prediction.\n",
        "post_text": "\nPlease identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample (in descending order, starting with the most important feature). Use comma separated value format for generation. Don't provide any further descriptions besides your answer."
    },
    "simple_2": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model, while the Output corresponds to the model's prediction.\n",
        "post_text": "\nBased solely on a provided set of (Input, Output) samples given above, please identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample (in descending order, starting with the most important feature). Use comma separated value format for generation. Don't provide any further descriptions besides your answer."
    },
    "simple_3": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model, while the Output corresponds to the model's prediction.\n",
        "post_text": "\nBased solely on a provided set of (Input, Output) samples given above, please identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample (in descending order, starting with the most important feature). Use comma separated value format for generation. Don't provide any further descriptions besides your answer. Do not merely rank the last test sample by feature values, instead use the above samples to learn the feature importance utilized by the machine learning model to predict either class 0 or 1."
    },


    "LIME_0": {
        "pre_text": "LIME (Local Interpretable Model-Agnostic Explanations) is an interpretable machine learning technique. LIME is a method that fits a surrogate “interpretable” model around the decision space of any blackbox model’s prediction. LIME explicitly tries to model the local neighborhood of any prediction – by focusing on a narrow enough decision surface, even simple linear models can provide good approximations of blackbox model behavior. Users can then inspect the surrogate model to understand how the blackbox model behaves in that region.\nLIME works by perturbing any individual datapoint and generating synthetic data which gets evaluated by the blackbox system, and ultimately used as a training set for the surrogate model. You can interpret an explanation the same way you reason about a linear model, and that it can be used on almost any model.\nUse this definition of LIME to rank the features in descending order of importance utilized by a machine learning model to predict the outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model (ranging from 0 to 1), while the Output corresponds to the model's prediction (either 0 or 1).\n",
        "post_text": "\nBased solely on a provided set of (Input, Output) samples given above, please identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample (in descending order, starting with the most important feature). Use comma separated value format for generation. Don't provide any further descriptions besides your answer. Do not merely rank the last test sample by feature values, instead use the above samples to learn the feature importance utilized by the machine learning model to predict either class 0 or 1."
    },


    "feature_importance_0": {
        "pre_text": "",
        "post_text": "\nI want you to identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the test sample (in descending order, starting with the most important feature) and use your internal calculator and coding capabilities to look at all the feature values of the {n_shot} samples and generate an importance score between 0 and 1 for each feature. For the final answer, provide me with only the list of features and their importance scores (in descending order, starting with the most important feature) in comma separated values format, and do not generate any other texts.\n"
    },


    "soft_preds_simple_0": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model (in the range of 0 to 1), while the Output corresponds to the model's prediction (in the range 0 to 1).\n",
        "post_text": "\nPlease identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample (in descending order, starting with the most important feature). Use comma separated value format for generation. Don't provide any further descriptions besides your answer."
    },
    "soft_preds_simple_1": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model (in the range of 0 to 1), while the Output corresponds to the model's prediction (in the range 0 to 1).\n",
        "post_text": "\nBased solely on a provided set of (Input, Output) samples given above, please identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample. State your answer in descending order, starting with the most important feature. Use comma separated value format for generation. Don't provide any further descriptions besides your answer."
    },
    "soft_preds_simple_2": {
        "pre_text": "Task: Rank the features in descending order of importance utilized by a machine learning model to predict outcome for a given test sample. The objective is to determine the relative importance of these features based solely on a provided set of (Input, Output) samples. Each Input represents the feature values provided to the model (in the range of 0 to 1), while the Output corresponds to the model's probability of belonging to class 1 (in the range of 0 to 1).\n",
        "post_text": "\nBased solely on a provided set of (Input, Output) samples given above, please identify the {k_word} most important features among {{A, B, C, D, E, F}} for predicting the output of the last sample. State your answer in descending order, starting with the most important feature. Use comma separated value format for generation. Don't provide any further descriptions besides your answer."
    },
    "chirag_v1": {
        "pre_text": "Below are sets of input-output pairs, where 'Input' denotes the input data of the machine learning model and 'Output' is the model predicted class.\n",
        "mid_text": "\nUsing the above sets of input-output pairs, find the importance of all {k_word} features in predicting the output of the below test sample:\n\n",
        "post_text": "\n\nUse comma separated value format for the generation and start with the most important feature. State your answer in descending order and don't provide any further descriptions besides your answer."
    },
    "chirag_v2": {
        "pre_text": "Below are sets of input-output pairs, where 'Input' denotes the input data of the machine learning model and 'Output' is the model predicted class.\n",
        "mid_text": "\nUsing the above sets of input-output pairs, find the importance of all {k_word} features in predicting the output.",
        "post_text": "\nFind the importance of all {k_word} input features in the above pairs for predicting the respective output. Starting with the most important feature, state your answer in descending order using comma-separated value format for the generation. Don't provide any further descriptions besides your answer.",
        "result": "FA 0.749 +/- 0.005; RA 0.4847 +/- 0.0103; PGU 0.132 +/- 0.0017; PGI 0.2436 +/- 0.0023"
    },
    "chirag_v3": {
      "pre_text": "Below are sets of input-output pairs, where 'Input' denotes the input data of the machine learning model and 'Output' is the model predicted class.\n",
      "mid_text": "\nUsing the above sets of input-output pairs, find the importance of the top {k_word} features in predicting the output of the below test sample:\n\n",
      "post_text": "\n\nUse comma separated value format for the generation and start with the most important feature. State your answer in descending order and don't provide any further descriptions besides your answer."
    },
    "icl_exp": {
        "pre_text": "",
        "mid_text": "\n",
        "post_text": "\n",
        "backup": "Using the above sets of input-output pairs, find the importance of all {k_word} features in predicting the output of the inputs. Use comma separated value format for the generation and, starting with the most important feature, state your answer in descending order. Don't provide any further descriptions besides your answer."
    },
    "no_test_sample": {
         "pre_text": "Below are sets of input-output pairs, where 'Input' denotes the input data of the machine learning model and 'Output' is the model predicted class.\n",
         "mid_text": "\n",
        "post_text": "\nUsing the above sets of input-output pairs, find the importance of all {k_word} features in predicting the output of the inputs. Use comma separated value format for the generation and, starting with the most important feature, state your answer in descending order. Don't provide any further descriptions besides your answer."
    },
    "context-task": {
         "pre_text": "Context: Below are sets of input-output pairs, where 'Input' denotes the input data of the machine learning model and 'Output' is the model predicted class.\n",
         "mid_text": "\n",
         "post_text": "\nTask: Using the above examples, find the most important feature in predicting the output. Only write the feature name in your answer and no other description.\nAnswer:"
    },
    "dan_topk": {
        "pre_text": "",
        "mid_text": "\nInput: ",
        "post_text": "Output: \nTop {k_word} features for determining this output: \n\nComplete the output for the last input. Do not provide any other details besides the output, and the {k_word} most important features in determining the output in your answer. Use comma separated values for the top {k_word} features."
    },
    "dan_topk_corr": {
        "pre_text": "",
        "mid_text": "\nInput: ",
        "post_text": "Output: \nTop {k_word} features most correlated (positively or negatively) with the output: \n\nComplete the output for the last input. Do not provide any other details besides the output, and the top {k_word} features most correlated (positively or negatively) with the output. Use comma separated values for the top {k_word} features."
    },
    "dan_rank": {
        "pre_text": "",
        "mid_text": "\nInput: ",
        "post_text": "Output: \nRank of feature importances: \n\nComplete the output for the last input. Then, rank all of the features in descending order of importance, starting with the feature that contributed the most to the output. Use comma separated values for the rank."
    },
    "io1": {
        "pre_text": "Context: \"We have a two-class machine learning model that predicts based on {num_features} features: {feat_words}. The model has been trained on a dataset and has made the following predictions.\"\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "\n```\n\nQuestion: \"Based on the model's predictions and the given dataset, what appears to be the most important feature in determining the model's prediction?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as a feature name on the last line. Do not provide any further details on the last line.\""
    },
    "io1-topk": {
        "pre_text": "Context: \"We have a two-class machine learning model that predicts based on {num_features} features: {feat_words}. The model has been trained on a dataset and has made the following predictions.\"\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nQuestion: \"Based on the model's predictions and the given dataset, what appears to be the top {k_word} most important features in determining the model's prediction?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\""
    },
    "pe1": {
        "pre_text": "",
        "mid_text": "\nInput: ",
        "post_text": "\nOutput: \nMost important feature for determining this output: "
    },
    "pe1-topk": {
        "pre_text": "",
        "mid_text": "\nInput: ",
        "post_text": "Output: \nTop {k_word} most important features for determining this output, in descending order of importance: "
    },
    "pe2": {
        "pre_text": "Context: \"We have a two-class machine learning model that predicts based on {num_features} features: {feat_words}. The model has been trained on a dataset and has made the following predictions.\"\n\nDataset:\n```\n",
        "mid_text": "\nInput: ",
        "post_text": "\nOutput: \nMost important feature: \n```\n\nQuestion: \"Based on the model's predictions and the given dataset, estimate the model's prediction for the last input. What appears to be the most important feature in determining the model's prediction?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as a feature name on the last line. Do not provide any further details on the last line.\""
    },
    "pe2-topk": {
        "pre_text": "Context: \"We have a two-class machine learning model that predicts based on {num_features} features: {feat_words}. The model has been trained on a dataset and has made the following predictions.\"\n\nDataset:\n```\n",
        "mid_text": "\nInput: ",
        "post_text": "\nOutput: \nTop {k_word} most important features for determining this output: \n```\n\nQuestion: \"Based on the model's predictions and the given dataset, estimate the model's prediction for the last input. What appears to be the top {k_word} most important features in determining the model's prediction?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\""
    },
    "ionew": {
        "pre_text": "Context: \"We have a two-class machine learning model that predicts based on {num_features} features: {feat_words}. The model has been trained on a dataset and has made the following predictions.\"\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "\n```\n\nQuestion: \"Based on the given dataset, find the top most important feature in determining the model's prediction.\"\n\nInstructions: \"Analyze the dataset and fit a logistic regression model and provide your answer of the top most important feature. Only provide the feature names on the last line. Do not provide any further details on the last line.\""
    },
    "algorithm-v1": {
        "pre_text": "We can use the permutation feature importance algorithm to find the most important features for a given set of inputs and model outputs. The basic idea is to measure the importance of a feature by calculating the change in the model’s predicted output after permuting the feature. A feature is “important” if shuffling its values changes the model output because in this case, the model relied on the feature for the prediction. A feature is “unimportant” if shuffling its values leaves the model output unchanged because in this case, the model ignored the feature for the prediction.\n",
        "mid_text": "",
        "post_text": "\nTop three most important features in determining the model's prediction:\n\nOnly provide the feature names on the last line. Do not provide any further details on the last line."
    },
    "algorithm-v2-best-results": {
        "pre_text": "We can use the perturbation feature importance algorithm to find the most important features for a given set of inputs and model outputs. The basic idea is to measure the importance of a feature by calculating the change in the model’s predicted output after perturbing the features. A feature is “important” if perturbing its values changes the model output because in this case, the model relied on the feature for the prediction. A feature is “unimportant” if perturbing its values leaves the model output unchanged because in this case, the model ignored the feature for the prediction. Below are a given set of pertubed feature values and their output.\n",
        "mid_text": "",
        "post_text": "\nYou are a post hoc explainer tasked with generating explanations. Only provide the top three important features in the last line. Do not provide any further details on the last line.\n\nThe top three important features:"
    },
    "algorithm":{
        "pre_text": "The algorithm uses a decision tree classifier to identify the most important features in determining an output. It starts with example data containing input features and corresponding output values. The decision tree model is trained on this data to learn the relationships between features and output. By analyzing the model's feature importance scores, the algorithm ranks the features based on their contribution to the model's decisions. The top three features with the highest importance scores are then considered the most influential in determining the output.\n",
        "mid_text": "",
        "post_text": "\nOnly provide the top three important features and no further details in the last line.\nThe top three important features:"
},
    "pf1": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains values for features 'A' through '{final_feature}' and their corresponding outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nFor each feature from 'A' to '{final_feature}':\n\n1. Compare instances where its values are high to where its values are low and explain how this difference correlates with the output.\n\n2. Identify any instances where a feature's value changes substantially but the output remains consistent.\n\n3. Rate the importance of each feature in determining the output on a scale of 1-10, considering both positive and negative correlations.\n\nEnsure to give equal emphasis to both positive and negative correlations and avoid focusing only on absolute values. Based on the provided perturbations, which feature do you deduce as most directly influencing the model's output? After completing the task, provide the importance rating of each feature from 'A' to '{final_feature}' in a comma-separated list on the last line. Do not provide further details on the last line."
    },
    "pfp": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nFor each feature from 'A' to '{final_feature}':\n\n1. Compare instances where its changes are positive to where its changes are negative and explain how this difference correlates with the change in output.\n\n2. Rate the importance of each feature in determining the output on a scale of 0-100, considering both positive and negative correlations. Ensure to give equal emphasis to both positive and negative correlations and avoid focusing only on absolute values.\n\nAfter completing the task, provide the importance rating of each feature from 'A' to '{final_feature}' in a comma-separated list on the penultimate line. Then, identify the top {k_word} features with the highest ratings. If there are ties in the top {k_word}, conduct a further analysis to break the ties and finalize your top {k_word}. Do not provide further details on the last two lines.\n\nAvoid providing general methodologies or suggesting tools. Justify your findings as you go. Do not provide the same importance for any two features."
    },
    "pfpv2": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nFor each feature from 'A' to '{final_feature}':\n\n1. Compare instances where its changes are positive to where its changes are negative and explain how this difference correlates with the change in output.\n\n2. Rate the importance of each feature in determining the output on a scale of 0-100, considering both positive and negative correlations. Ensure to give equal emphasis to both positive and negative correlations and avoid focusing only on absolute values. If you have already used an importance score once, do not use the same value again.\n\nAfter completing the task, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\n\nAvoid providing general methodologies or suggesting tools."
    },
    "pfp2": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nFor each feature, starting with 'A' and continuing to '{final_feature}':\n\n1. Analyze the feature in question:\na. Compare instances where its changes are positive to where its changes are negative and explain how this difference correlates with the change in output.\nb. Rate the importance of the feature in determining the output on a scale of 0-100, considering both positive and negative correlations. Ensure to give equal emphasis to both positive and negative correlations and avoid focusing only on absolute values.\n\n2. After analyzing the feature, position it in a running rank compared to the features already analyzed. For instance, after analyzing feature 'B', determine its relative importance compared to 'A' and position it accordingly in the rank (e.g., BA or AB). Continue this process until all features from 'A' to '{final_feature}' are ranked.\n\nUpon completion of all analyses, provide the final rank of features from 'A' to '{final_feature}' on the last line.\n\nAvoid providing general methodologies or suggesting tools. Justify your findings as you go."
    },
    "pfp4": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nFor each feature, starting with 'A' and continuing to '{final_feature}':\n\n1. Analyze the feature in question:\na. Compare instances where its changes are positive to where its changes are negative and explain how this difference correlates with the change in output.\nb. Identify any instances where a feature's value changes substantially but the output remains consistent.\nc. Rate the importance of the feature in determining the output on a scale of 0-100, considering both positive and negative correlations. Ensure to give equal emphasis to both positive and negative correlations and avoid focusing only on absolute values.\n\n2. After analyzing the feature, position it in a running rank compared to the features already analyzed. For instance, after analyzing feature 'B', determine its relative importance compared to 'A' and position it accordingly in the rank (e.g., BA or AB). Continue this process until all features from 'A' to '{final_feature}' are ranked.\n\nUpon completion of all analyses, provide the final rank of features from 'A' to '{final_feature}' on the last line.\n\nAvoid providing general methodologies or suggesting tools. Justify your findings as you go. Do not provide the same importance for any two features."
    },
    "pfp-io1-topk": {
        "pre_text": "Context: \"We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nQuestion: \"Based on the model's predictions and the given dataset, what appears to be the top {k_word} most important features in determining the model's prediction?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\""
    },
    "io1-topk-v2": {
        "pre_text": "Context: \"We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the features 'A' through '{final_feature}' and the corresponding outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nQuestion: \"Based on the model's predictions and the given dataset, what appears to be the top {k_word} most important features in determining the model's prediction?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\""
    },
    "pfpe": {
        "pre_text": "",
        "mid_text": "\nChange in Input: {zero_change}",
        "post_text": "\nChange in Output: \nMost important feature for determining the change in output: "
    },
    "pfpe2": {
        "pre_text": "Context: \"We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "\n```\n\nQuestion: \"Based on the given dataset, estimate the change in output for the final change in input. What appears to be the most important feature in determining this change?\"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as a feature name on the last line. Do not provide any further details on the last line.\""
    },
    "pfpe2-topk": {
        "pre_text": "Context: \"We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nQuestion: \"Based on the model's predictions and the given dataset, estimate the change in output for the final change in input.\"\n\nInstructions: \"Think about the question. After explaining your reasoning provide your answer as:\n\na) on the penultimate line, the estimated change in output\n\nb) on the last line, the top {k_word} most important features ranked from most important to least important, in descending order.\n\nOnly provide the change in output and the feature names on the last two lines. Do not provide any further details on the last two lines.\""
    },
    "pe2-topk-v2": {
        "pre_text": "Context: \"We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the features 'A' through '{final_feature}' and the corresponding outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nQuestion: \"Based on the model's predictions and the given dataset, estimate the output for the final input.\"\n\nInstructions: \"Think about the question. After explaining your reasoning provide your answer as:\n\na) on the penultimate line, the estimated output\n\nb) on the last line, the top {k_word} most important features ranked from most important to least important, in descending order.\n\nOnly provide the output and the feature names on the last two lines. Do not provide any further details on the last two lines.\""
    },
    "ko1": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nQuestion: \"Based on the model's predictions and the given dataset, what appears to be the most important feature in determining the model's prediction? Explain your reasoning. What appears to be the next most important feature? Repeat the process until you have determined the top {k_word} most important features. After explaining your reasoning, \"\n\nInstructions: \"Think about the question. After explaining your reasoning, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\""
    },
    "pfp3": {
        "pre_text": "We are analyzing a fixed set of perturbations around a specific input to understand the influence of each feature on the model's output. The dataset below contains the change in features 'A' through '{final_feature}' (with negative values denoting a decrease in a feature's value) and the corresponding change in outputs.\n\nDataset:\n```",
        "mid_text": "",
        "post_text": "```\n\nAnalyze the data, and provide:\n\n1. A summarized analysis of each feature's effect on the output when it increases or decreases.\n\n2. Rank the features based on their inferred importance from the data.\n\nAfter explaining your reasoning, provide your answer as the top {k_word} most important features ranked from most important to least important, in descending order. Only provide the feature names on the last line. Do not provide any further details on the last line.\n\nAvoid providing general methodologies or suggesting tools. Justify your findings as you go."
    }
}