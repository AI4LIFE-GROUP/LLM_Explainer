{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T11:17:41.245265Z",
     "start_time": "2024-06-11T11:17:41.242818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train a set of models on different OpenXAI datasets"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:51.496976Z",
     "start_time": "2024-06-13T07:44:51.482592Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# go up a directory\n",
    "import os\n",
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:52.355942Z",
     "start_time": "2024-06-13T07:44:52.019865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.050329Z",
     "start_time": "2024-06-13T07:44:53.111694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import datetime\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "# Data loaders\n",
    "from openxai.dataloader import return_loaders, get_tokenizer_and_vocab\n",
    "from openxai.ML_Models.LR.model import LogisticRegression\n",
    "import openxai.ML_Models.ANN.MLP as model_MLP\n",
    "import openxai.ML_Models.ANN.Text_MLP as model_MLP_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.077073Z",
     "start_time": "2024-06-13T07:44:55.051970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x326f38030>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('default')\n",
    "SEED = 3407\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.098507Z",
     "start_time": "2024-06-13T07:44:55.078111Z"
    }
   },
   "outputs": [],
   "source": [
    "def getExperimentID():\n",
    "    date_info = datetime.datetime.now()\n",
    "    testID    = '%d%02d%02d_%02d%02d' % (date_info.year, date_info.month, date_info.day, date_info.hour, date_info.minute)\n",
    "    return testID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.203496Z",
     "start_time": "2024-06-13T07:44:55.101340Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model, loader_train, loader_test, ml_model, dir_name, learning_rate, epochs, dataset, exp_id, layer_info_str, use_class_weighting, device, targets, modality='tabular'):\n",
    "    loaders = {'train': loader_train, 'test': loader_test}\n",
    "\n",
    "    if use_class_weighting: \n",
    "        # Compute class weights\n",
    "        # convert targets to numpy array if not already\n",
    "        if not isinstance(targets, np.ndarray):\n",
    "            targets = targets.to_numpy()\n",
    "        class_counts  = torch.bincount(torch.tensor(targets.astype(np.compat.long)))\n",
    "        total_samples = len(loader_train.dataset)\n",
    "        class_weights = total_samples / (class_counts.float())\n",
    "        class_weights = class_weights.to(device)\n",
    "\n",
    "    # model collector\n",
    "    best_auc_roc = 0\n",
    "\n",
    "    model  = model.to(device)\n",
    "\n",
    "    # declaring optimizer and loss\n",
    "    if use_class_weighting:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # training\n",
    "    for e in range(epochs):\n",
    "        print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluation mode\n",
    "\n",
    "            all_preds  = []\n",
    "            all_labels = []\n",
    "            for i, input_tuple in enumerate(loaders[phase]):\n",
    "                if modality == 'tabular':\n",
    "                    inputs = input_tuple[0].float()\n",
    "                    labels = input_tuple[1]\n",
    "                elif modality == 'text':\n",
    "                    (labels, inputs) = input_tuple\n",
    "                    \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).type(torch.long)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if modality == 'tabular':\n",
    "                        y_pred = model(inputs)\n",
    "                    elif modality == 'text':\n",
    "                        y_pred = model(inputs)\n",
    "                    loss   = criterion(y_pred.float(), labels.long())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                all_preds.append(y_pred)\n",
    "                all_labels.append(labels)\n",
    "            # statistics\n",
    "            preds = torch.cat(all_preds, dim=0)\n",
    "            labels = torch.cat(all_labels, dim=0).cpu()\n",
    "            \n",
    "            raw_preds      = preds.data[:, 1]\n",
    "            raw_preds_np   = raw_preds.view(-1).cpu().numpy()\n",
    "            class_preds    = raw_preds >= 0.5\n",
    "            class_preds_np = class_preds.view(-1).long().cpu().numpy()\n",
    "            \n",
    "            epoch_loss     = loss.item()\n",
    "            epoch_acc      = accuracy_score(labels.numpy(), class_preds_np)\n",
    "            epoch_f1       = f1_score(labels.numpy(), class_preds_np)\n",
    "            epoch_auc_roc  = roc_auc_score(labels.numpy(), raw_preds_np)\n",
    "\n",
    "            print(f'{phase}: Loss: {epoch_loss:.4f} | F1-score: {epoch_f1:.4f} | AUC ROC: {epoch_auc_roc:.4f} | Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_auc_roc > best_auc_roc:\n",
    "                best_auc_roc = epoch_auc_roc\n",
    "                best_model_name = '{}_{}_{}_{}_{}_auc_roc_{:.2f}.pt'.format(exp_id, layer_info_str, dataset, ml_model, learning_rate, best_auc_roc)\n",
    "                print('new best model', e)\n",
    "                if use_class_weighting:\n",
    "                    fpth = 'models/ClassWeighted/' + dir_name\n",
    "                else:\n",
    "                    fpth = 'models/NotClassWeighted/' + dir_name\n",
    "                if not os.path.isdir(fpth):  # If folder doesn't exist, then create it.\n",
    "                    os.makedirs(fpth)\n",
    "                output_file_path = fpth + '/' + best_model_name\n",
    "                torch.save(model.state_dict(), output_file_path)\n",
    "\n",
    "    return best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.225368Z",
     "start_time": "2024-06-13T07:44:55.204318Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotROC(output_dir, labels, preds, addtlNameInfo=''):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)\n",
    "    auc         = roc_auc_score(labels, preds)\n",
    "    plt.figure(dpi=100)\n",
    "    plt.plot([0,1],[0,1], color='k')\n",
    "    plt.plot([0,0],[0,1], color='k', linestyle='dashed')\n",
    "    plt.plot([0,1],[1,1], color='k', linestyle='dashed')\n",
    "    plt.plot([1,1],[1,0], color='k', linestyle='dashed')\n",
    "    plt.plot([1,0],[0,0], color='k', linestyle='dashed')\n",
    "    plt.plot(fpr, tpr, color='b', label=\"AUC: \" + str(round(auc,2)))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('ROC Curve - ' + addtlNameInfo)\n",
    "    plt.savefig(output_dir + 'ROC_'+addtlNameInfo+'.png', bbox_inches='tight')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.251787Z",
     "start_time": "2024-06-13T07:44:55.226880Z"
    }
   },
   "outputs": [],
   "source": [
    "def EvaluateNetwork(best_model_name, model_name, dim_per_layer, activation_per_layer, loader_train, loader_val, \n",
    "                    use_class_weighting, device, modality='tabular'):\n",
    "    print('Evaluating', best_model_name)\n",
    "\n",
    "    print('Best model:', best_model_name)\n",
    "    # model = DefineModel(model_name, dim_per_layer, activation_per_layer)\n",
    "    if 'text' in model_name:\n",
    "        tokenizer, voc = get_tokenizer_and_vocab(X_train, y_train)\n",
    "        \n",
    "        model = DefineModel(model_name, vocab_size=len(voc), embed_dim=embedding_dim, num_class=2)\n",
    "    else:\n",
    "        model = DefineModel(model_name, dim_per_layer, activation_per_layer)\n",
    "    \n",
    "    if use_class_weighting:\n",
    "        fpth = 'models/ClassWeighted/'\n",
    "    else:\n",
    "        fpth = 'models/NotClassWeighted/'\n",
    "\n",
    "    model.load_state_dict(torch.load(fpth + model_name.upper() + '/' + best_model_name))\n",
    "\n",
    "    model  = model.to(device)\n",
    "    model.eval()   # Set model to evaluation mode\n",
    "\n",
    "    all_preds  = []\n",
    "    all_labels = []\n",
    "    for i, input_tuple in enumerate(loader_val):\n",
    "        if modality == 'tabular':\n",
    "            inputs = input_tuple[0].float()\n",
    "            labels = input_tuple[1]\n",
    "        elif modality == 'text':\n",
    "            (labels, inputs) = input_tuple\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).type(torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            if modality == 'tabular':\n",
    "                y_pred = model(inputs)\n",
    "            elif modality == 'text':\n",
    "                y_pred = model(inputs)\n",
    "        all_preds.append(y_pred)\n",
    "        all_labels.append(labels)\n",
    "    # statistics\n",
    "    preds  = torch.cat(all_preds, dim=0)\n",
    "    labels = torch.cat(all_labels, dim=0).cpu()\n",
    "    \n",
    "    raw_preds      = preds.data[:, 1]\n",
    "    raw_preds_np   = raw_preds.view(-1).cpu().numpy()\n",
    "    class_preds    = raw_preds >= 0.5\n",
    "    class_preds_np = class_preds.view(-1).long().cpu().numpy()\n",
    "    \n",
    "    total_acc     = accuracy_score(labels.numpy(), class_preds_np)\n",
    "    total_f1      = f1_score(labels.numpy(), class_preds_np)\n",
    "    total_auc_roc = roc_auc_score(labels.numpy(), raw_preds_np)\n",
    "    \n",
    "    y_preds_test = []\n",
    "    for i, input_tuple in enumerate(loader_val):\n",
    "        if modality == 'tabular':\n",
    "            inputs = input_tuple[0].float()\n",
    "            labels = input_tuple[1]\n",
    "        elif modality == 'text':\n",
    "            (labels, inputs) = input_tuple\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).type(torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            if modality == 'tabular':\n",
    "                y_pred = model(inputs).data\n",
    "            elif modality == 'text':\n",
    "                y_pred = model(inputs)\n",
    "        # inputs = input_tuple[0].float().to(device)\n",
    "        # y_pred = model(inputs).data\n",
    "        y_pred = y_pred[:, 1]# >= 0.5  # True if bigger than 0.5\n",
    "        y_preds_test.append(y_pred.cpu())  # convert true and false to 1 and 0, respectively.\n",
    "    y_preds_test_flat = np.array([item for sublist in y_preds_test for item in sublist])\n",
    "\n",
    "    y_preds_train = []\n",
    "    for i, input_tuple in enumerate(loader_train):\n",
    "        if modality == 'tabular':\n",
    "            inputs = input_tuple[0].float()\n",
    "            labels = input_tuple[1]\n",
    "        elif modality == 'text':\n",
    "            (labels, inputs) = input_tuple\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).type(torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            if modality == 'tabular':\n",
    "                y_pred = model(inputs).data\n",
    "            elif modality == 'text':\n",
    "                y_pred = model(inputs)\n",
    "            # inputs = input_tuple[0].float().to(device)\n",
    "            # y_pred = model(inputs).data\n",
    "        y_pred = y_pred[:, 1]# >= 0.5  # True if bigger than 0.5\n",
    "        y_preds_train.append(y_pred.cpu())  # convert true and false to 1 and 0, respectively.\n",
    "    y_preds_train_flat = np.array([item for sublist in y_preds_train for item in sublist])\n",
    "\n",
    "    return total_acc, total_f1, total_auc_roc, y_preds_test_flat, y_preds_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.342295Z",
     "start_time": "2024-06-13T07:44:55.320218Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotConfusionMatrix(labels, preds, num_of_classes, output_dir, addtlNameInfo=''):\n",
    "    preds      = preds >= 0.5\n",
    "    conf_mat   = confusion_matrix(labels, preds, normalize=None)\n",
    "    pathToSave = os.path.join(output_dir + 'ConfusionMatrix_'+addtlNameInfo+'.png')\n",
    "    df_cm      = pd.DataFrame(conf_mat, range(num_of_classes), range(num_of_classes))\n",
    "    \n",
    "    plt.figure(figsize=(12, 9), dpi=100)\n",
    "    plt.title('Confusion Matrix - ' + addtlNameInfo)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    # sn.set(font_scale=2) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 18}, cmap=\"Blues\", fmt='d') # font size\n",
    "    plt.savefig(pathToSave, format = 'png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:55.458255Z",
     "start_time": "2024-06-13T07:44:55.434275Z"
    }
   },
   "outputs": [],
   "source": [
    "def SaveModelInfo(model_name, data_name, model, exp_id, epochs, learning_rate, X_train, y_train, X_val, y_val, X_test, y_test, total_f1, total_acc, total_auc_roc, loader_val, y_preds_test_flat, loader_train, y_preds_train_flat, layer_info_str, use_class_weighting, dim_per_layer='', activation_per_layer='', modality='tabular'):\n",
    "    # Save to .txt\n",
    "    if use_class_weighting:\n",
    "        output_dir = 'models/ClassWeighted/' + model_name.upper() + '/'\n",
    "    else:\n",
    "        output_dir = 'models/NotClassWeighted/' + model_name.upper() + '/'\n",
    "    file_name  =  exp_id + '_' + layer_info_str + model_name.upper() + '_' + data_name + '_summary'\n",
    "\n",
    "    fpth = os.path.join(output_dir, file_name+'.txt')\n",
    "    paramTxt = open(fpth, 'w')\n",
    "\n",
    "    paramTxt.write(file_name)\n",
    "    paramTxt.write('Hyperparameters')\n",
    "    paramTxt.write('exp_id:\\t' + exp_id + '\\n')\n",
    "    paramTxt.write('data_name:\\t' + data_name + '\\n')\n",
    "    paramTxt.write('model_name:\\t' + model_name + '\\n')\n",
    "    paramTxt.write('epochs:\\t\\t' + str(epochs) + '\\n')\n",
    "    paramTxt.write('learning_rate:\\t' + str(learning_rate) + '\\n\\n')\n",
    "    if modality == 'tabular':\n",
    "        paramTxt.write('X_train.shape:\\t' + str(X_train.shape) + '\\n')\n",
    "        paramTxt.write('X_val.shape:\\t' + str(X_val.shape) + '\\n')\n",
    "        paramTxt.write('X_test.shape:\\t' + str(X_test.shape) + '\\n')\n",
    "    else:\n",
    "        paramTxt.write('X_train.shape:\\t' + str(len(X_train)) + '\\n')\n",
    "        paramTxt.write('X_val.shape:\\t' + str(len(X_val)) + '\\n')\n",
    "        paramTxt.write('X_test.shape:\\t' + str(len(X_test)) + '\\n')\n",
    "    paramTxt.write('y_train.shape:\\t' + str(y_train.shape) + '\\n\\n')\n",
    "    paramTxt.write('y_val.shape:\\t' + str(y_val.shape) + '\\n\\n')\n",
    "    paramTxt.write('y_test.shape:\\t' + str(y_test.shape) + '\\n\\n')\n",
    "    paramTxt.write('dim_per_layer:\\t' + str(dim_per_layer) + '\\n')\n",
    "    if 'ann' in model_name:\n",
    "        paramTxt.write('activation_per_layer:\\t' + str(activation_per_layer) + '\\n')\n",
    "    paramTxt.write('\\nF1-score: '+ str(round(total_f1,4)) +' | Accuracy: ' + str(round(total_acc, 4)) + ' | AUC-ROC: ' + str(round(total_auc_roc, 4)) + '\\n\\n')\n",
    "    paramTxt.write(\"Proportion of ones in val set: \" + str(round(np.mean(y_val),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones predicted in test set: \" + str(round(np.mean(y_preds_test_flat),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones in train set: \" + str(round(np.mean(y_train),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones predicted in train set: \" + str(round(np.mean(y_preds_train_flat),3)) + '\\n')\n",
    "    paramTxt.write('\\nArchitecture:\\n')\n",
    "    paramTxt.write(str(model.__dict__['_modules']))\n",
    "    paramTxt.close()\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    PlotROC(fpth, y_val, y_preds_test_flat, addtlNameInfo = model_name.upper() + '_' + data_name)\n",
    "    \n",
    "    PlotConfusionMatrix(y_val, y_preds_test_flat, 2, output_dir, addtlNameInfo = model_name.upper() + '_' + data_name)\n",
    "\n",
    "    print(f'F1-score: {total_f1:.4f} | Accuracy: {total_acc:.4f} | AUC-ROC: {total_auc_roc:.4f}')\n",
    "    print(\"Proportion of ones in val set:\", round(np.mean(y_val),3))\n",
    "    print(\"Proportion of ones predicted in val set: \", round(np.mean(y_preds_test_flat),3))\n",
    "    print(\"Proportion of ones in train set:\", round(np.mean(y_train),3))\n",
    "    print(\"Proportion of ones predicted in train set: \", round(np.mean(y_preds_train_flat),3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:44:56.086847Z",
     "start_time": "2024-06-13T07:44:56.065753Z"
    }
   },
   "outputs": [],
   "source": [
    "def DefineModel(model_name, dim_per_layer=None, activation_per_layer=None, vocab_size=None, embed_dim=None, num_class=None):\n",
    "    if 'text_ann' in model_name:\n",
    "        # model = model_MLP_Text.Text_MLP(vocab_size, embed_dim, num_class)\n",
    "        model = model_MLP_Text.Text_MLP(vocab_size)\n",
    "    else:\n",
    "        input_size = loader_train.dataset.get_number_of_features()\n",
    "        if 'ann' in model_name:\n",
    "            dim_per_layer = [input_size] + dim_per_layer\n",
    "            model         = model_MLP.MLP(dim_per_layer, activation_per_layer)\n",
    "        elif model_name == 'lr':\n",
    "            dim_per_layer = [input_size] + dim_per_layer\n",
    "            model         = LogisticRegression(dim_per_layer[0], dim_per_layer[1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: text_ann on imdb\n",
      "Vocabulary size: 2595\n",
      "Vocabulary size: 2595\n",
      "text_ann\n",
      "Epoch 0/299\n",
      "----------\n",
      "train: Loss: 0.7755 | F1-score: 0.3768 | AUC ROC: 0.5082 | Accuracy: 0.5083\n",
      "test: Loss: 0.7722 | F1-score: 0.4118 | AUC ROC: 0.4753 | Accuracy: 0.5000\n",
      "new best model 0\n",
      "Epoch 1/299\n",
      "----------\n",
      "train: Loss: 0.6969 | F1-score: 0.4847 | AUC ROC: 0.5154 | Accuracy: 0.5097\n",
      "test: Loss: 0.7878 | F1-score: 0.4533 | AUC ROC: 0.4853 | Accuracy: 0.4875\n",
      "new best model 1\n",
      "Epoch 2/299\n",
      "----------\n",
      "train: Loss: 0.6253 | F1-score: 0.5173 | AUC ROC: 0.5460 | Accuracy: 0.5361\n",
      "test: Loss: 0.8055 | F1-score: 0.4722 | AUC ROC: 0.4709 | Accuracy: 0.5250\n",
      "Epoch 3/299\n",
      "----------\n",
      "train: Loss: 0.6424 | F1-score: 0.5147 | AUC ROC: 0.5519 | Accuracy: 0.5417\n",
      "test: Loss: 0.8212 | F1-score: 0.4359 | AUC ROC: 0.4947 | Accuracy: 0.4500\n",
      "new best model 3\n",
      "Epoch 4/299\n",
      "----------\n",
      "train: Loss: 0.7516 | F1-score: 0.5228 | AUC ROC: 0.5551 | Accuracy: 0.5486\n",
      "test: Loss: 0.8060 | F1-score: 0.4595 | AUC ROC: 0.5147 | Accuracy: 0.5000\n",
      "new best model 4\n",
      "Epoch 5/299\n",
      "----------\n",
      "train: Loss: 0.7584 | F1-score: 0.5313 | AUC ROC: 0.5846 | Accuracy: 0.5736\n",
      "test: Loss: 0.8351 | F1-score: 0.5116 | AUC ROC: 0.5103 | Accuracy: 0.4750\n",
      "Epoch 6/299\n",
      "----------\n",
      "train: Loss: 0.6561 | F1-score: 0.5754 | AUC ROC: 0.5903 | Accuracy: 0.5778\n",
      "test: Loss: 0.8250 | F1-score: 0.4810 | AUC ROC: 0.5247 | Accuracy: 0.4875\n",
      "new best model 6\n",
      "Epoch 7/299\n",
      "----------\n",
      "train: Loss: 0.7659 | F1-score: 0.5597 | AUC ROC: 0.5913 | Accuracy: 0.5694\n",
      "test: Loss: 0.8460 | F1-score: 0.4810 | AUC ROC: 0.5360 | Accuracy: 0.4875\n",
      "new best model 7\n",
      "Epoch 8/299\n",
      "----------\n",
      "train: Loss: 0.6649 | F1-score: 0.5528 | AUC ROC: 0.5996 | Accuracy: 0.5708\n",
      "test: Loss: 0.8670 | F1-score: 0.4878 | AUC ROC: 0.5235 | Accuracy: 0.4750\n",
      "Epoch 9/299\n",
      "----------\n",
      "train: Loss: 0.5983 | F1-score: 0.5677 | AUC ROC: 0.6087 | Accuracy: 0.5875\n",
      "test: Loss: 0.8735 | F1-score: 0.4810 | AUC ROC: 0.5247 | Accuracy: 0.4875\n",
      "Epoch 10/299\n",
      "----------\n",
      "train: Loss: 0.5528 | F1-score: 0.5587 | AUC ROC: 0.6170 | Accuracy: 0.5875\n",
      "test: Loss: 0.8873 | F1-score: 0.4878 | AUC ROC: 0.5222 | Accuracy: 0.4750\n",
      "Epoch 11/299\n",
      "----------\n",
      "train: Loss: 0.6729 | F1-score: 0.5747 | AUC ROC: 0.6261 | Accuracy: 0.5889\n",
      "test: Loss: 0.9118 | F1-score: 0.5060 | AUC ROC: 0.5097 | Accuracy: 0.4875\n",
      "Epoch 12/299\n",
      "----------\n",
      "train: Loss: 0.8895 | F1-score: 0.5606 | AUC ROC: 0.6140 | Accuracy: 0.5667\n",
      "test: Loss: 0.9136 | F1-score: 0.5349 | AUC ROC: 0.5147 | Accuracy: 0.5000\n",
      "Epoch 13/299\n",
      "----------\n",
      "train: Loss: 0.6136 | F1-score: 0.5836 | AUC ROC: 0.6355 | Accuracy: 0.6056\n",
      "test: Loss: 0.9242 | F1-score: 0.4810 | AUC ROC: 0.5222 | Accuracy: 0.4875\n",
      "Epoch 14/299\n",
      "----------\n",
      "train: Loss: 0.7092 | F1-score: 0.5936 | AUC ROC: 0.6477 | Accuracy: 0.6139\n",
      "test: Loss: 0.9467 | F1-score: 0.5060 | AUC ROC: 0.5097 | Accuracy: 0.4875\n",
      "Epoch 15/299\n",
      "----------\n",
      "train: Loss: 0.5729 | F1-score: 0.6086 | AUC ROC: 0.6668 | Accuracy: 0.6194\n",
      "test: Loss: 0.9630 | F1-score: 0.4938 | AUC ROC: 0.5178 | Accuracy: 0.4875\n",
      "Epoch 16/299\n",
      "----------\n",
      "train: Loss: 0.4984 | F1-score: 0.5936 | AUC ROC: 0.6576 | Accuracy: 0.6139\n",
      "test: Loss: 0.9266 | F1-score: 0.5122 | AUC ROC: 0.5278 | Accuracy: 0.5000\n",
      "Epoch 17/299\n",
      "----------\n",
      "train: Loss: 0.5006 | F1-score: 0.6125 | AUC ROC: 0.6714 | Accuracy: 0.6222\n",
      "test: Loss: 0.9466 | F1-score: 0.5647 | AUC ROC: 0.5410 | Accuracy: 0.5375\n",
      "new best model 17\n",
      "Epoch 18/299\n",
      "----------\n",
      "train: Loss: 0.4945 | F1-score: 0.6193 | AUC ROC: 0.6755 | Accuracy: 0.6278\n",
      "test: Loss: 0.9735 | F1-score: 0.5610 | AUC ROC: 0.5397 | Accuracy: 0.5500\n",
      "Epoch 19/299\n",
      "----------\n",
      "train: Loss: 0.9481 | F1-score: 0.6570 | AUC ROC: 0.6850 | Accuracy: 0.6403\n",
      "test: Loss: 1.0270 | F1-score: 0.5610 | AUC ROC: 0.5416 | Accuracy: 0.5500\n",
      "new best model 19\n",
      "Epoch 20/299\n",
      "----------\n",
      "train: Loss: 0.7057 | F1-score: 0.6294 | AUC ROC: 0.6773 | Accuracy: 0.6500\n",
      "test: Loss: 1.0018 | F1-score: 0.5647 | AUC ROC: 0.5460 | Accuracy: 0.5375\n",
      "new best model 20\n",
      "Epoch 21/299\n",
      "----------\n",
      "train: Loss: 0.6773 | F1-score: 0.6414 | AUC ROC: 0.6689 | Accuracy: 0.6319\n",
      "test: Loss: 1.0166 | F1-score: 0.5316 | AUC ROC: 0.5572 | Accuracy: 0.5375\n",
      "new best model 21\n",
      "Epoch 22/299\n",
      "----------\n",
      "train: Loss: 0.6092 | F1-score: 0.6219 | AUC ROC: 0.6649 | Accuracy: 0.6167\n",
      "test: Loss: 0.9659 | F1-score: 0.5128 | AUC ROC: 0.5460 | Accuracy: 0.5250\n",
      "Epoch 23/299\n",
      "----------\n",
      "train: Loss: 0.4372 | F1-score: 0.6189 | AUC ROC: 0.6822 | Accuracy: 0.6528\n",
      "test: Loss: 0.9404 | F1-score: 0.5250 | AUC ROC: 0.5391 | Accuracy: 0.5250\n",
      "Epoch 24/299\n",
      "----------\n",
      "train: Loss: 0.7095 | F1-score: 0.5991 | AUC ROC: 0.6829 | Accuracy: 0.6208\n",
      "test: Loss: 0.9841 | F1-score: 0.5063 | AUC ROC: 0.5247 | Accuracy: 0.5125\n",
      "Epoch 25/299\n",
      "----------\n",
      "train: Loss: 0.4368 | F1-score: 0.6165 | AUC ROC: 0.6954 | Accuracy: 0.6458\n",
      "test: Loss: 0.9513 | F1-score: 0.5063 | AUC ROC: 0.5341 | Accuracy: 0.5125\n",
      "Epoch 26/299\n",
      "----------\n",
      "train: Loss: 0.6213 | F1-score: 0.6379 | AUC ROC: 0.7152 | Accuracy: 0.6500\n",
      "test: Loss: 0.9459 | F1-score: 0.5500 | AUC ROC: 0.5491 | Accuracy: 0.5500\n",
      "Epoch 27/299\n",
      "----------\n",
      "train: Loss: 0.6035 | F1-score: 0.6482 | AUC ROC: 0.7194 | Accuracy: 0.6653\n",
      "test: Loss: 0.9693 | F1-score: 0.5263 | AUC ROC: 0.5503 | Accuracy: 0.5500\n",
      "Epoch 28/299\n",
      "----------\n",
      "train: Loss: 0.8089 | F1-score: 0.6413 | AUC ROC: 0.7242 | Accuracy: 0.6722\n",
      "test: Loss: 0.9843 | F1-score: 0.5067 | AUC ROC: 0.5528 | Accuracy: 0.5375\n",
      "Epoch 29/299\n",
      "----------\n",
      "train: Loss: 0.5350 | F1-score: 0.6479 | AUC ROC: 0.7368 | Accuracy: 0.6694\n",
      "test: Loss: 0.9954 | F1-score: 0.5455 | AUC ROC: 0.5835 | Accuracy: 0.5625\n",
      "new best model 29\n",
      "Epoch 30/299\n",
      "----------\n",
      "train: Loss: 0.5288 | F1-score: 0.6416 | AUC ROC: 0.7235 | Accuracy: 0.6556\n",
      "test: Loss: 0.9612 | F1-score: 0.5128 | AUC ROC: 0.5722 | Accuracy: 0.5250\n",
      "Epoch 31/299\n",
      "----------\n",
      "train: Loss: 0.4085 | F1-score: 0.6611 | AUC ROC: 0.7377 | Accuracy: 0.6625\n",
      "test: Loss: 0.9893 | F1-score: 0.5455 | AUC ROC: 0.5735 | Accuracy: 0.5625\n",
      "Epoch 32/299\n",
      "----------\n",
      "train: Loss: 0.6219 | F1-score: 0.6697 | AUC ROC: 0.7524 | Accuracy: 0.6944\n",
      "test: Loss: 0.8980 | F1-score: 0.5070 | AUC ROC: 0.5791 | Accuracy: 0.5625\n",
      "Epoch 33/299\n",
      "----------\n",
      "train: Loss: 0.4479 | F1-score: 0.6415 | AUC ROC: 0.7308 | Accuracy: 0.6708\n",
      "test: Loss: 0.9173 | F1-score: 0.5455 | AUC ROC: 0.5866 | Accuracy: 0.5625\n",
      "new best model 33\n",
      "Epoch 34/299\n",
      "----------\n",
      "train: Loss: 0.5603 | F1-score: 0.6617 | AUC ROC: 0.7358 | Accuracy: 0.6833\n",
      "test: Loss: 0.9153 | F1-score: 0.5333 | AUC ROC: 0.5929 | Accuracy: 0.5625\n",
      "new best model 34\n",
      "Epoch 35/299\n",
      "----------\n",
      "train: Loss: 0.7911 | F1-score: 0.6878 | AUC ROC: 0.7603 | Accuracy: 0.6986\n",
      "test: Loss: 0.9705 | F1-score: 0.5570 | AUC ROC: 0.5910 | Accuracy: 0.5625\n",
      "Epoch 36/299\n",
      "----------\n",
      "train: Loss: 0.5898 | F1-score: 0.6912 | AUC ROC: 0.7573 | Accuracy: 0.6972\n",
      "test: Loss: 0.9917 | F1-score: 0.5750 | AUC ROC: 0.6160 | Accuracy: 0.5750\n",
      "new best model 36\n",
      "Epoch 37/299\n",
      "----------\n",
      "train: Loss: 0.5645 | F1-score: 0.6767 | AUC ROC: 0.7547 | Accuracy: 0.7028\n",
      "test: Loss: 1.0014 | F1-score: 0.5750 | AUC ROC: 0.6048 | Accuracy: 0.5750\n",
      "Epoch 38/299\n",
      "----------\n",
      "train: Loss: 0.4591 | F1-score: 0.6715 | AUC ROC: 0.7573 | Accuracy: 0.6833\n",
      "test: Loss: 0.9771 | F1-score: 0.5750 | AUC ROC: 0.5922 | Accuracy: 0.5750\n",
      "Epoch 39/299\n",
      "----------\n",
      "train: Loss: 0.4808 | F1-score: 0.6676 | AUC ROC: 0.7488 | Accuracy: 0.6833\n",
      "test: Loss: 0.9952 | F1-score: 0.4932 | AUC ROC: 0.5766 | Accuracy: 0.5375\n",
      "Epoch 40/299\n",
      "----------\n",
      "train: Loss: 0.8145 | F1-score: 0.6845 | AUC ROC: 0.7683 | Accuracy: 0.7056\n",
      "test: Loss: 1.0040 | F1-score: 0.5641 | AUC ROC: 0.5847 | Accuracy: 0.5750\n",
      "Epoch 41/299\n",
      "----------\n",
      "train: Loss: 0.6174 | F1-score: 0.6784 | AUC ROC: 0.7697 | Accuracy: 0.6958\n",
      "test: Loss: 0.9876 | F1-score: 0.5205 | AUC ROC: 0.6060 | Accuracy: 0.5625\n",
      "Epoch 42/299\n",
      "----------\n",
      "train: Loss: 0.4839 | F1-score: 0.7151 | AUC ROC: 0.7711 | Accuracy: 0.7278\n",
      "test: Loss: 0.9856 | F1-score: 0.4857 | AUC ROC: 0.6173 | Accuracy: 0.5500\n",
      "new best model 42\n",
      "Epoch 43/299\n",
      "----------\n",
      "train: Loss: 0.4740 | F1-score: 0.6986 | AUC ROC: 0.7677 | Accuracy: 0.7111\n",
      "test: Loss: 1.0094 | F1-score: 0.5405 | AUC ROC: 0.6160 | Accuracy: 0.5750\n",
      "Epoch 44/299\n",
      "----------\n",
      "train: Loss: 0.5903 | F1-score: 0.6785 | AUC ROC: 0.7684 | Accuracy: 0.6972\n",
      "test: Loss: 1.0095 | F1-score: 0.5600 | AUC ROC: 0.6048 | Accuracy: 0.5875\n",
      "Epoch 45/299\n",
      "----------\n",
      "train: Loss: 0.3888 | F1-score: 0.7182 | AUC ROC: 0.7818 | Accuracy: 0.7167\n",
      "test: Loss: 0.9971 | F1-score: 0.5333 | AUC ROC: 0.6198 | Accuracy: 0.5625\n",
      "new best model 45\n",
      "Epoch 46/299\n",
      "----------\n",
      "train: Loss: 0.6748 | F1-score: 0.7233 | AUC ROC: 0.7992 | Accuracy: 0.7375\n",
      "test: Loss: 1.0072 | F1-score: 0.5405 | AUC ROC: 0.6323 | Accuracy: 0.5750\n",
      "new best model 46\n",
      "Epoch 47/299\n",
      "----------\n",
      "train: Loss: 0.3169 | F1-score: 0.7311 | AUC ROC: 0.7909 | Accuracy: 0.7333\n",
      "test: Loss: 1.0113 | F1-score: 0.5352 | AUC ROC: 0.6379 | Accuracy: 0.5875\n",
      "new best model 47\n",
      "Epoch 48/299\n",
      "----------\n",
      "train: Loss: 0.3241 | F1-score: 0.7106 | AUC ROC: 0.7911 | Accuracy: 0.7319\n",
      "test: Loss: 0.9571 | F1-score: 0.5143 | AUC ROC: 0.6279 | Accuracy: 0.5750\n",
      "Epoch 49/299\n",
      "----------\n",
      "train: Loss: 0.8656 | F1-score: 0.7105 | AUC ROC: 0.7779 | Accuracy: 0.7250\n",
      "test: Loss: 1.0207 | F1-score: 0.5676 | AUC ROC: 0.6035 | Accuracy: 0.6000\n",
      "Epoch 50/299\n",
      "----------\n",
      "train: Loss: 0.7167 | F1-score: 0.7312 | AUC ROC: 0.7933 | Accuracy: 0.7417\n",
      "test: Loss: 1.0187 | F1-score: 0.5479 | AUC ROC: 0.6166 | Accuracy: 0.5875\n",
      "Epoch 51/299\n",
      "----------\n",
      "train: Loss: 1.0186 | F1-score: 0.7364 | AUC ROC: 0.8137 | Accuracy: 0.7444\n",
      "test: Loss: 0.9973 | F1-score: 0.5641 | AUC ROC: 0.6141 | Accuracy: 0.5750\n",
      "Epoch 52/299\n",
      "----------\n",
      "train: Loss: 0.4456 | F1-score: 0.7309 | AUC ROC: 0.7910 | Accuracy: 0.7361\n",
      "test: Loss: 1.0037 | F1-score: 0.5278 | AUC ROC: 0.6241 | Accuracy: 0.5750\n",
      "Epoch 53/299\n",
      "----------\n",
      "train: Loss: 0.4609 | F1-score: 0.7094 | AUC ROC: 0.7707 | Accuracy: 0.7292\n",
      "test: Loss: 1.0051 | F1-score: 0.5600 | AUC ROC: 0.6348 | Accuracy: 0.5875\n",
      "Epoch 54/299\n",
      "----------\n",
      "train: Loss: 0.6431 | F1-score: 0.7230 | AUC ROC: 0.7888 | Accuracy: 0.7361\n",
      "test: Loss: 1.0115 | F1-score: 0.5405 | AUC ROC: 0.6085 | Accuracy: 0.5750\n",
      "Epoch 55/299\n",
      "----------\n",
      "train: Loss: 0.3260 | F1-score: 0.7590 | AUC ROC: 0.8223 | Accuracy: 0.7681\n",
      "test: Loss: 0.9863 | F1-score: 0.5352 | AUC ROC: 0.6223 | Accuracy: 0.5875\n",
      "Epoch 56/299\n",
      "----------\n",
      "train: Loss: 0.3435 | F1-score: 0.7539 | AUC ROC: 0.8097 | Accuracy: 0.7569\n",
      "test: Loss: 0.9760 | F1-score: 0.5600 | AUC ROC: 0.6216 | Accuracy: 0.5875\n",
      "Epoch 57/299\n",
      "----------\n",
      "train: Loss: 0.7056 | F1-score: 0.7207 | AUC ROC: 0.7836 | Accuracy: 0.7319\n",
      "test: Loss: 0.9757 | F1-score: 0.5676 | AUC ROC: 0.6360 | Accuracy: 0.6000\n",
      "Epoch 58/299\n",
      "----------\n",
      "train: Loss: 0.4508 | F1-score: 0.7430 | AUC ROC: 0.8168 | Accuracy: 0.7569\n",
      "test: Loss: 0.8929 | F1-score: 0.5479 | AUC ROC: 0.6266 | Accuracy: 0.5875\n",
      "Epoch 59/299\n",
      "----------\n",
      "train: Loss: 0.6109 | F1-score: 0.7496 | AUC ROC: 0.8284 | Accuracy: 0.7625\n",
      "test: Loss: 0.9509 | F1-score: 0.5000 | AUC ROC: 0.6129 | Accuracy: 0.5750\n",
      "Epoch 60/299\n",
      "----------\n",
      "train: Loss: 0.7881 | F1-score: 0.7619 | AUC ROC: 0.8385 | Accuracy: 0.7778\n",
      "test: Loss: 1.0324 | F1-score: 0.5479 | AUC ROC: 0.6273 | Accuracy: 0.5875\n",
      "Epoch 61/299\n",
      "----------\n",
      "train: Loss: 0.7730 | F1-score: 0.7544 | AUC ROC: 0.8257 | Accuracy: 0.7667\n",
      "test: Loss: 1.0057 | F1-score: 0.5429 | AUC ROC: 0.6248 | Accuracy: 0.6000\n",
      "Epoch 62/299\n",
      "----------\n",
      "train: Loss: 0.8073 | F1-score: 0.7315 | AUC ROC: 0.8277 | Accuracy: 0.7583\n",
      "test: Loss: 1.0183 | F1-score: 0.5143 | AUC ROC: 0.6310 | Accuracy: 0.5750\n",
      "Epoch 63/299\n",
      "----------\n",
      "train: Loss: 0.5794 | F1-score: 0.7868 | AUC ROC: 0.8591 | Accuracy: 0.7931\n",
      "test: Loss: 1.0193 | F1-score: 0.5676 | AUC ROC: 0.6423 | Accuracy: 0.6000\n",
      "new best model 63\n",
      "Epoch 64/299\n",
      "----------\n",
      "train: Loss: 0.3189 | F1-score: 0.7637 | AUC ROC: 0.8372 | Accuracy: 0.7722\n",
      "test: Loss: 1.0578 | F1-score: 0.5479 | AUC ROC: 0.6198 | Accuracy: 0.5875\n",
      "Epoch 65/299\n",
      "----------\n",
      "train: Loss: 0.4857 | F1-score: 0.7592 | AUC ROC: 0.8303 | Accuracy: 0.7736\n",
      "test: Loss: 1.0324 | F1-score: 0.4928 | AUC ROC: 0.6329 | Accuracy: 0.5625\n",
      "Epoch 66/299\n",
      "----------\n",
      "train: Loss: 0.5473 | F1-score: 0.7870 | AUC ROC: 0.8363 | Accuracy: 0.8000\n",
      "test: Loss: 1.0487 | F1-score: 0.5429 | AUC ROC: 0.6604 | Accuracy: 0.6000\n",
      "new best model 66\n",
      "Epoch 67/299\n",
      "----------\n",
      "train: Loss: 0.3853 | F1-score: 0.7644 | AUC ROC: 0.8299 | Accuracy: 0.7792\n",
      "test: Loss: 1.0507 | F1-score: 0.6234 | AUC ROC: 0.6654 | Accuracy: 0.6375\n",
      "new best model 67\n",
      "Epoch 68/299\n",
      "----------\n",
      "train: Loss: 0.5619 | F1-score: 0.7430 | AUC ROC: 0.8305 | Accuracy: 0.7569\n",
      "test: Loss: 1.2073 | F1-score: 0.5556 | AUC ROC: 0.6573 | Accuracy: 0.6000\n",
      "Epoch 69/299\n",
      "----------\n",
      "train: Loss: 0.4002 | F1-score: 0.7875 | AUC ROC: 0.8276 | Accuracy: 0.7917\n",
      "test: Loss: 1.0389 | F1-score: 0.6494 | AUC ROC: 0.6654 | Accuracy: 0.6625\n",
      "Epoch 70/299\n",
      "----------\n",
      "train: Loss: 0.5654 | F1-score: 0.7670 | AUC ROC: 0.8235 | Accuracy: 0.7722\n",
      "test: Loss: 1.1678 | F1-score: 0.5556 | AUC ROC: 0.6654 | Accuracy: 0.6000\n",
      "Epoch 71/299\n",
      "----------\n",
      "train: Loss: 0.4527 | F1-score: 0.7680 | AUC ROC: 0.8395 | Accuracy: 0.7903\n",
      "test: Loss: 1.1553 | F1-score: 0.5352 | AUC ROC: 0.6629 | Accuracy: 0.5875\n",
      "Epoch 72/299\n",
      "----------\n",
      "train: Loss: 0.6291 | F1-score: 0.7599 | AUC ROC: 0.8443 | Accuracy: 0.7736\n",
      "test: Loss: 1.0275 | F1-score: 0.5753 | AUC ROC: 0.6604 | Accuracy: 0.6125\n",
      "Epoch 73/299\n",
      "----------\n",
      "train: Loss: 0.5521 | F1-score: 0.7869 | AUC ROC: 0.8535 | Accuracy: 0.7917\n",
      "test: Loss: 1.0206 | F1-score: 0.5974 | AUC ROC: 0.6623 | Accuracy: 0.6125\n",
      "Epoch 74/299\n",
      "----------\n",
      "train: Loss: 0.3213 | F1-score: 0.7863 | AUC ROC: 0.8376 | Accuracy: 0.7917\n",
      "test: Loss: 0.8666 | F1-score: 0.5714 | AUC ROC: 0.6510 | Accuracy: 0.6250\n",
      "Epoch 75/299\n",
      "----------\n",
      "train: Loss: 0.5501 | F1-score: 0.7818 | AUC ROC: 0.8319 | Accuracy: 0.7931\n",
      "test: Loss: 0.9455 | F1-score: 0.5946 | AUC ROC: 0.6648 | Accuracy: 0.6250\n",
      "Epoch 76/299\n",
      "----------\n",
      "train: Loss: 0.7600 | F1-score: 0.7734 | AUC ROC: 0.8394 | Accuracy: 0.7819\n",
      "test: Loss: 0.9179 | F1-score: 0.6133 | AUC ROC: 0.6685 | Accuracy: 0.6375\n",
      "new best model 76\n",
      "Epoch 77/299\n",
      "----------\n",
      "train: Loss: 1.0327 | F1-score: 0.7565 | AUC ROC: 0.8322 | Accuracy: 0.7667\n",
      "test: Loss: 0.8140 | F1-score: 0.5915 | AUC ROC: 0.6610 | Accuracy: 0.6375\n",
      "Epoch 78/299\n",
      "----------\n",
      "train: Loss: 0.3239 | F1-score: 0.7801 | AUC ROC: 0.8498 | Accuracy: 0.7917\n",
      "test: Loss: 0.8165 | F1-score: 0.6197 | AUC ROC: 0.6604 | Accuracy: 0.6625\n",
      "Epoch 79/299\n",
      "----------\n",
      "train: Loss: 0.5854 | F1-score: 0.7861 | AUC ROC: 0.8601 | Accuracy: 0.8028\n",
      "test: Loss: 0.8466 | F1-score: 0.6216 | AUC ROC: 0.6685 | Accuracy: 0.6500\n",
      "new best model 79\n",
      "Epoch 80/299\n",
      "----------\n",
      "train: Loss: 0.3328 | F1-score: 0.7912 | AUC ROC: 0.8557 | Accuracy: 0.8014\n",
      "test: Loss: 0.8210 | F1-score: 0.6087 | AUC ROC: 0.6673 | Accuracy: 0.6625\n",
      "Epoch 81/299\n",
      "----------\n",
      "train: Loss: 0.3166 | F1-score: 0.7815 | AUC ROC: 0.8446 | Accuracy: 0.7903\n",
      "test: Loss: 0.9045 | F1-score: 0.6400 | AUC ROC: 0.6660 | Accuracy: 0.6625\n",
      "Epoch 82/299\n",
      "----------\n",
      "train: Loss: 0.6443 | F1-score: 0.7830 | AUC ROC: 0.8481 | Accuracy: 0.7875\n",
      "test: Loss: 0.9068 | F1-score: 0.6316 | AUC ROC: 0.6610 | Accuracy: 0.6500\n",
      "Epoch 83/299\n",
      "----------\n",
      "train: Loss: 0.3147 | F1-score: 0.7942 | AUC ROC: 0.8646 | Accuracy: 0.8014\n",
      "test: Loss: 0.8693 | F1-score: 0.6133 | AUC ROC: 0.6829 | Accuracy: 0.6375\n",
      "new best model 83\n",
      "Epoch 84/299\n",
      "----------\n",
      "train: Loss: 0.3209 | F1-score: 0.7866 | AUC ROC: 0.8603 | Accuracy: 0.7958\n",
      "test: Loss: 0.9306 | F1-score: 0.6486 | AUC ROC: 0.6823 | Accuracy: 0.6750\n",
      "Epoch 85/299\n",
      "----------\n",
      "train: Loss: 0.5917 | F1-score: 0.7953 | AUC ROC: 0.8709 | Accuracy: 0.8069\n",
      "test: Loss: 0.8475 | F1-score: 0.6286 | AUC ROC: 0.6792 | Accuracy: 0.6750\n",
      "Epoch 86/299\n",
      "----------\n",
      "train: Loss: 0.6248 | F1-score: 0.7971 | AUC ROC: 0.8595 | Accuracy: 0.8083\n",
      "test: Loss: 0.8328 | F1-score: 0.5672 | AUC ROC: 0.6563 | Accuracy: 0.6375\n",
      "Epoch 87/299\n",
      "----------\n",
      "train: Loss: 0.7900 | F1-score: 0.7768 | AUC ROC: 0.8449 | Accuracy: 0.7861\n",
      "test: Loss: 1.0014 | F1-score: 0.5867 | AUC ROC: 0.6798 | Accuracy: 0.6125\n",
      "Epoch 88/299\n",
      "----------\n",
      "train: Loss: 0.7567 | F1-score: 0.8165 | AUC ROC: 0.8798 | Accuracy: 0.8208\n",
      "test: Loss: 1.0316 | F1-score: 0.6133 | AUC ROC: 0.6823 | Accuracy: 0.6375\n",
      "Epoch 89/299\n",
      "----------\n",
      "train: Loss: 0.5384 | F1-score: 0.8006 | AUC ROC: 0.8459 | Accuracy: 0.8000\n",
      "test: Loss: 1.0292 | F1-score: 0.6216 | AUC ROC: 0.6861 | Accuracy: 0.6500\n",
      "new best model 89\n",
      "Epoch 90/299\n",
      "----------\n",
      "train: Loss: 0.3217 | F1-score: 0.8228 | AUC ROC: 0.8841 | Accuracy: 0.8319\n",
      "test: Loss: 1.0461 | F1-score: 0.6301 | AUC ROC: 0.6767 | Accuracy: 0.6625\n",
      "Epoch 91/299\n",
      "----------\n",
      "train: Loss: 1.0250 | F1-score: 0.8092 | AUC ROC: 0.8609 | Accuracy: 0.8153\n",
      "test: Loss: 1.0180 | F1-score: 0.6053 | AUC ROC: 0.6948 | Accuracy: 0.6250\n",
      "new best model 91\n",
      "Epoch 92/299\n",
      "----------\n",
      "train: Loss: 0.3149 | F1-score: 0.8183 | AUC ROC: 0.8761 | Accuracy: 0.8292\n",
      "test: Loss: 1.0091 | F1-score: 0.6133 | AUC ROC: 0.6748 | Accuracy: 0.6375\n",
      "Epoch 93/299\n",
      "----------\n",
      "train: Loss: 0.5493 | F1-score: 0.8115 | AUC ROC: 0.8612 | Accuracy: 0.8181\n",
      "test: Loss: 0.8292 | F1-score: 0.5915 | AUC ROC: 0.6961 | Accuracy: 0.6375\n",
      "new best model 93\n",
      "Epoch 94/299\n",
      "----------\n",
      "train: Loss: 0.5536 | F1-score: 0.8319 | AUC ROC: 0.8719 | Accuracy: 0.8389\n",
      "test: Loss: 0.9089 | F1-score: 0.6053 | AUC ROC: 0.6998 | Accuracy: 0.6250\n",
      "new best model 94\n",
      "Epoch 95/299\n",
      "----------\n",
      "train: Loss: 0.5683 | F1-score: 0.8050 | AUC ROC: 0.8528 | Accuracy: 0.8056\n",
      "test: Loss: 1.0261 | F1-score: 0.6316 | AUC ROC: 0.6954 | Accuracy: 0.6500\n",
      "Epoch 96/299\n",
      "----------\n",
      "train: Loss: 0.3822 | F1-score: 0.8198 | AUC ROC: 0.8880 | Accuracy: 0.8278\n",
      "test: Loss: 0.9173 | F1-score: 0.5714 | AUC ROC: 0.6923 | Accuracy: 0.6250\n",
      "Epoch 97/299\n",
      "----------\n",
      "train: Loss: 0.6565 | F1-score: 0.8105 | AUC ROC: 0.8700 | Accuracy: 0.8194\n",
      "test: Loss: 1.0376 | F1-score: 0.5714 | AUC ROC: 0.6873 | Accuracy: 0.6250\n",
      "Epoch 98/299\n",
      "----------\n",
      "train: Loss: 0.5529 | F1-score: 0.8196 | AUC ROC: 0.8762 | Accuracy: 0.8264\n",
      "test: Loss: 0.9683 | F1-score: 0.5507 | AUC ROC: 0.6792 | Accuracy: 0.6125\n",
      "Epoch 99/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.8348 | AUC ROC: 0.8863 | Accuracy: 0.8417\n",
      "test: Loss: 1.0391 | F1-score: 0.5714 | AUC ROC: 0.6986 | Accuracy: 0.6250\n",
      "Epoch 100/299\n",
      "----------\n",
      "train: Loss: 0.7519 | F1-score: 0.7806 | AUC ROC: 0.8472 | Accuracy: 0.7931\n",
      "test: Loss: 0.9502 | F1-score: 0.5294 | AUC ROC: 0.6942 | Accuracy: 0.6000\n",
      "Epoch 101/299\n",
      "----------\n",
      "train: Loss: 0.7830 | F1-score: 0.8225 | AUC ROC: 0.8799 | Accuracy: 0.8375\n",
      "test: Loss: 1.0084 | F1-score: 0.5294 | AUC ROC: 0.6886 | Accuracy: 0.6000\n",
      "Epoch 102/299\n",
      "----------\n",
      "train: Loss: 0.8232 | F1-score: 0.7897 | AUC ROC: 0.8582 | Accuracy: 0.8069\n",
      "test: Loss: 1.0234 | F1-score: 0.5294 | AUC ROC: 0.6723 | Accuracy: 0.6000\n",
      "Epoch 103/299\n",
      "----------\n",
      "train: Loss: 0.3348 | F1-score: 0.8182 | AUC ROC: 0.8742 | Accuracy: 0.8278\n",
      "test: Loss: 1.0356 | F1-score: 0.5507 | AUC ROC: 0.6773 | Accuracy: 0.6125\n",
      "Epoch 104/299\n",
      "----------\n",
      "train: Loss: 0.3152 | F1-score: 0.8152 | AUC ROC: 0.8811 | Accuracy: 0.8250\n",
      "test: Loss: 1.0305 | F1-score: 0.5373 | AUC ROC: 0.6735 | Accuracy: 0.6125\n",
      "Epoch 105/299\n",
      "----------\n",
      "train: Loss: 0.6663 | F1-score: 0.7946 | AUC ROC: 0.8644 | Accuracy: 0.8083\n",
      "test: Loss: 1.0175 | F1-score: 0.5373 | AUC ROC: 0.6585 | Accuracy: 0.6125\n",
      "Epoch 106/299\n",
      "----------\n",
      "train: Loss: 0.3410 | F1-score: 0.8034 | AUC ROC: 0.8473 | Accuracy: 0.8097\n",
      "test: Loss: 1.0359 | F1-score: 0.5714 | AUC ROC: 0.6892 | Accuracy: 0.6250\n",
      "Epoch 107/299\n",
      "----------\n",
      "train: Loss: 0.5632 | F1-score: 0.8131 | AUC ROC: 0.8779 | Accuracy: 0.8181\n",
      "test: Loss: 1.0793 | F1-score: 0.5882 | AUC ROC: 0.6967 | Accuracy: 0.6500\n",
      "Epoch 108/299\n",
      "----------\n",
      "train: Loss: 0.6539 | F1-score: 0.7994 | AUC ROC: 0.8586 | Accuracy: 0.8097\n",
      "test: Loss: 1.0505 | F1-score: 0.6216 | AUC ROC: 0.7048 | Accuracy: 0.6500\n",
      "new best model 108\n",
      "Epoch 109/299\n",
      "----------\n",
      "train: Loss: 0.4785 | F1-score: 0.8157 | AUC ROC: 0.8812 | Accuracy: 0.8236\n",
      "test: Loss: 1.0195 | F1-score: 0.5915 | AUC ROC: 0.6948 | Accuracy: 0.6375\n",
      "Epoch 110/299\n",
      "----------\n",
      "train: Loss: 0.5714 | F1-score: 0.8355 | AUC ROC: 0.8996 | Accuracy: 0.8431\n",
      "test: Loss: 1.0804 | F1-score: 0.5915 | AUC ROC: 0.6917 | Accuracy: 0.6375\n",
      "Epoch 111/299\n",
      "----------\n",
      "train: Loss: 0.3139 | F1-score: 0.8144 | AUC ROC: 0.8717 | Accuracy: 0.8278\n",
      "test: Loss: 1.0223 | F1-score: 0.6133 | AUC ROC: 0.7086 | Accuracy: 0.6375\n",
      "new best model 111\n",
      "Epoch 112/299\n",
      "----------\n",
      "train: Loss: 0.3900 | F1-score: 0.8326 | AUC ROC: 0.8862 | Accuracy: 0.8347\n",
      "test: Loss: 0.9766 | F1-score: 0.6027 | AUC ROC: 0.6792 | Accuracy: 0.6375\n",
      "Epoch 113/299\n",
      "----------\n",
      "train: Loss: 0.4362 | F1-score: 0.8191 | AUC ROC: 0.8713 | Accuracy: 0.8208\n",
      "test: Loss: 0.9938 | F1-score: 0.5507 | AUC ROC: 0.6567 | Accuracy: 0.6125\n",
      "Epoch 114/299\n",
      "----------\n",
      "train: Loss: 0.8249 | F1-score: 0.8276 | AUC ROC: 0.8824 | Accuracy: 0.8333\n",
      "test: Loss: 1.0167 | F1-score: 0.5352 | AUC ROC: 0.6341 | Accuracy: 0.5875\n",
      "Epoch 115/299\n",
      "----------\n",
      "train: Loss: 0.5791 | F1-score: 0.8333 | AUC ROC: 0.8883 | Accuracy: 0.8389\n",
      "test: Loss: 0.9919 | F1-score: 0.5507 | AUC ROC: 0.6410 | Accuracy: 0.6125\n",
      "Epoch 116/299\n",
      "----------\n",
      "train: Loss: 0.3655 | F1-score: 0.8204 | AUC ROC: 0.8920 | Accuracy: 0.8292\n",
      "test: Loss: 1.0430 | F1-score: 0.5634 | AUC ROC: 0.6467 | Accuracy: 0.6125\n",
      "Epoch 117/299\n",
      "----------\n",
      "train: Loss: 0.3159 | F1-score: 0.8409 | AUC ROC: 0.9078 | Accuracy: 0.8486\n",
      "test: Loss: 1.0493 | F1-score: 0.5217 | AUC ROC: 0.6298 | Accuracy: 0.5875\n",
      "Epoch 118/299\n",
      "----------\n",
      "train: Loss: 0.5695 | F1-score: 0.8370 | AUC ROC: 0.8894 | Accuracy: 0.8458\n",
      "test: Loss: 1.0578 | F1-score: 0.5714 | AUC ROC: 0.6404 | Accuracy: 0.6250\n",
      "Epoch 119/299\n",
      "----------\n",
      "train: Loss: 0.6520 | F1-score: 0.8365 | AUC ROC: 0.9097 | Accuracy: 0.8458\n",
      "test: Loss: 1.1290 | F1-score: 0.5634 | AUC ROC: 0.6379 | Accuracy: 0.6125\n",
      "Epoch 120/299\n",
      "----------\n",
      "train: Loss: 0.7862 | F1-score: 0.8415 | AUC ROC: 0.8988 | Accuracy: 0.8472\n",
      "test: Loss: 1.0560 | F1-score: 0.5634 | AUC ROC: 0.6498 | Accuracy: 0.6125\n",
      "Epoch 121/299\n",
      "----------\n",
      "train: Loss: 0.6008 | F1-score: 0.8029 | AUC ROC: 0.8669 | Accuracy: 0.8139\n",
      "test: Loss: 1.0455 | F1-score: 0.5753 | AUC ROC: 0.6623 | Accuracy: 0.6125\n",
      "Epoch 122/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8470 | AUC ROC: 0.8981 | Accuracy: 0.8569\n",
      "test: Loss: 1.0296 | F1-score: 0.5429 | AUC ROC: 0.6573 | Accuracy: 0.6000\n",
      "Epoch 123/299\n",
      "----------\n",
      "train: Loss: 0.3141 | F1-score: 0.8427 | AUC ROC: 0.9087 | Accuracy: 0.8486\n",
      "test: Loss: 1.0472 | F1-score: 0.5714 | AUC ROC: 0.6610 | Accuracy: 0.6250\n",
      "Epoch 124/299\n",
      "----------\n",
      "train: Loss: 0.3135 | F1-score: 0.8456 | AUC ROC: 0.8977 | Accuracy: 0.8514\n",
      "test: Loss: 1.0525 | F1-score: 0.6053 | AUC ROC: 0.6829 | Accuracy: 0.6250\n",
      "Epoch 125/299\n",
      "----------\n",
      "train: Loss: 0.5347 | F1-score: 0.8555 | AUC ROC: 0.8973 | Accuracy: 0.8611\n",
      "test: Loss: 1.0526 | F1-score: 0.6133 | AUC ROC: 0.6785 | Accuracy: 0.6375\n",
      "Epoch 126/299\n",
      "----------\n",
      "train: Loss: 0.3145 | F1-score: 0.8473 | AUC ROC: 0.9040 | Accuracy: 0.8528\n",
      "test: Loss: 1.0527 | F1-score: 0.6316 | AUC ROC: 0.6867 | Accuracy: 0.6500\n",
      "Epoch 127/299\n",
      "----------\n",
      "train: Loss: 0.3154 | F1-score: 0.8446 | AUC ROC: 0.9077 | Accuracy: 0.8472\n",
      "test: Loss: 1.0523 | F1-score: 0.5915 | AUC ROC: 0.6629 | Accuracy: 0.6375\n",
      "Epoch 128/299\n",
      "----------\n",
      "train: Loss: 0.5529 | F1-score: 0.8217 | AUC ROC: 0.8874 | Accuracy: 0.8403\n",
      "test: Loss: 1.0525 | F1-score: 0.6027 | AUC ROC: 0.6704 | Accuracy: 0.6375\n",
      "Epoch 129/299\n",
      "----------\n",
      "train: Loss: 0.3222 | F1-score: 0.8326 | AUC ROC: 0.8988 | Accuracy: 0.8458\n",
      "test: Loss: 1.0525 | F1-score: 0.6027 | AUC ROC: 0.6735 | Accuracy: 0.6375\n",
      "Epoch 130/299\n",
      "----------\n",
      "train: Loss: 0.3474 | F1-score: 0.8309 | AUC ROC: 0.8926 | Accuracy: 0.8389\n",
      "test: Loss: 1.0511 | F1-score: 0.5833 | AUC ROC: 0.6742 | Accuracy: 0.6250\n",
      "Epoch 131/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8496 | AUC ROC: 0.9025 | Accuracy: 0.8569\n",
      "test: Loss: 1.0521 | F1-score: 0.5946 | AUC ROC: 0.6754 | Accuracy: 0.6250\n",
      "Epoch 132/299\n",
      "----------\n",
      "train: Loss: 0.3182 | F1-score: 0.8500 | AUC ROC: 0.9093 | Accuracy: 0.8583\n",
      "test: Loss: 1.0525 | F1-score: 0.6133 | AUC ROC: 0.6717 | Accuracy: 0.6375\n",
      "Epoch 133/299\n",
      "----------\n",
      "train: Loss: 0.5505 | F1-score: 0.8547 | AUC ROC: 0.9132 | Accuracy: 0.8597\n",
      "test: Loss: 1.0527 | F1-score: 0.6494 | AUC ROC: 0.6767 | Accuracy: 0.6625\n",
      "Epoch 134/299\n",
      "----------\n",
      "train: Loss: 0.5412 | F1-score: 0.8531 | AUC ROC: 0.9062 | Accuracy: 0.8569\n",
      "test: Loss: 1.0529 | F1-score: 0.6133 | AUC ROC: 0.6604 | Accuracy: 0.6375\n",
      "Epoch 135/299\n",
      "----------\n",
      "train: Loss: 0.4147 | F1-score: 0.8472 | AUC ROC: 0.9104 | Accuracy: 0.8542\n",
      "test: Loss: 1.0552 | F1-score: 0.5946 | AUC ROC: 0.6523 | Accuracy: 0.6250\n",
      "Epoch 136/299\n",
      "----------\n",
      "train: Loss: 0.3540 | F1-score: 0.8308 | AUC ROC: 0.8900 | Accuracy: 0.8444\n",
      "test: Loss: 1.0525 | F1-score: 0.5833 | AUC ROC: 0.6507 | Accuracy: 0.6250\n",
      "Epoch 137/299\n",
      "----------\n",
      "train: Loss: 0.3141 | F1-score: 0.8296 | AUC ROC: 0.8803 | Accuracy: 0.8431\n",
      "test: Loss: 1.0526 | F1-score: 0.5833 | AUC ROC: 0.6673 | Accuracy: 0.6250\n",
      "Epoch 138/299\n",
      "----------\n",
      "train: Loss: 0.5705 | F1-score: 0.8533 | AUC ROC: 0.8974 | Accuracy: 0.8639\n",
      "test: Loss: 1.0527 | F1-score: 0.5946 | AUC ROC: 0.6654 | Accuracy: 0.6250\n",
      "Epoch 139/299\n",
      "----------\n",
      "train: Loss: 0.5623 | F1-score: 0.8526 | AUC ROC: 0.9035 | Accuracy: 0.8569\n",
      "test: Loss: 1.0527 | F1-score: 0.6053 | AUC ROC: 0.6867 | Accuracy: 0.6250\n",
      "Epoch 140/299\n",
      "----------\n",
      "train: Loss: 0.8056 | F1-score: 0.8438 | AUC ROC: 0.8979 | Accuracy: 0.8472\n",
      "test: Loss: 1.0527 | F1-score: 0.6053 | AUC ROC: 0.6867 | Accuracy: 0.6250\n",
      "Epoch 141/299\n",
      "----------\n",
      "train: Loss: 0.5614 | F1-score: 0.8432 | AUC ROC: 0.8932 | Accuracy: 0.8486\n",
      "test: Loss: 1.0526 | F1-score: 0.6154 | AUC ROC: 0.6904 | Accuracy: 0.6250\n",
      "Epoch 142/299\n",
      "----------\n",
      "train: Loss: 0.3750 | F1-score: 0.8430 | AUC ROC: 0.8977 | Accuracy: 0.8500\n",
      "test: Loss: 1.0501 | F1-score: 0.6027 | AUC ROC: 0.6785 | Accuracy: 0.6375\n",
      "Epoch 143/299\n",
      "----------\n",
      "train: Loss: 0.3139 | F1-score: 0.8710 | AUC ROC: 0.9197 | Accuracy: 0.8778\n",
      "test: Loss: 1.0482 | F1-score: 0.5946 | AUC ROC: 0.6745 | Accuracy: 0.6250\n",
      "Epoch 144/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.8478 | AUC ROC: 0.8936 | Accuracy: 0.8583\n",
      "test: Loss: 1.0525 | F1-score: 0.6133 | AUC ROC: 0.6876 | Accuracy: 0.6375\n",
      "Epoch 145/299\n",
      "----------\n",
      "train: Loss: 0.3868 | F1-score: 0.8646 | AUC ROC: 0.9124 | Accuracy: 0.8708\n",
      "test: Loss: 1.1252 | F1-score: 0.6133 | AUC ROC: 0.6954 | Accuracy: 0.6375\n",
      "Epoch 146/299\n",
      "----------\n",
      "train: Loss: 0.5072 | F1-score: 0.8687 | AUC ROC: 0.9280 | Accuracy: 0.8736\n",
      "test: Loss: 1.3070 | F1-score: 0.5600 | AUC ROC: 0.6895 | Accuracy: 0.5875\n",
      "Epoch 147/299\n",
      "----------\n",
      "train: Loss: 0.4021 | F1-score: 0.8696 | AUC ROC: 0.9277 | Accuracy: 0.8750\n",
      "test: Loss: 1.2946 | F1-score: 0.6027 | AUC ROC: 0.6667 | Accuracy: 0.6375\n",
      "Epoch 148/299\n",
      "----------\n",
      "train: Loss: 0.5565 | F1-score: 0.8563 | AUC ROC: 0.9088 | Accuracy: 0.8611\n",
      "test: Loss: 1.0535 | F1-score: 0.6329 | AUC ROC: 0.6807 | Accuracy: 0.6375\n",
      "Epoch 149/299\n",
      "----------\n",
      "train: Loss: 1.0296 | F1-score: 0.8448 | AUC ROC: 0.9092 | Accuracy: 0.8500\n",
      "test: Loss: 1.0528 | F1-score: 0.6027 | AUC ROC: 0.6667 | Accuracy: 0.6375\n",
      "Epoch 150/299\n",
      "----------\n",
      "train: Loss: 0.5732 | F1-score: 0.8571 | AUC ROC: 0.9109 | Accuracy: 0.8639\n",
      "test: Loss: 1.0524 | F1-score: 0.6133 | AUC ROC: 0.6882 | Accuracy: 0.6375\n",
      "Epoch 151/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.8671 | AUC ROC: 0.9092 | Accuracy: 0.8681\n",
      "test: Loss: 1.0524 | F1-score: 0.6582 | AUC ROC: 0.6998 | Accuracy: 0.6625\n",
      "Epoch 152/299\n",
      "----------\n",
      "train: Loss: 0.6869 | F1-score: 0.8617 | AUC ROC: 0.9097 | Accuracy: 0.8667\n",
      "test: Loss: 1.0499 | F1-score: 0.5915 | AUC ROC: 0.6823 | Accuracy: 0.6375\n",
      "Epoch 153/299\n",
      "----------\n",
      "train: Loss: 0.8025 | F1-score: 0.8696 | AUC ROC: 0.9090 | Accuracy: 0.8750\n",
      "test: Loss: 1.2046 | F1-score: 0.5915 | AUC ROC: 0.7001 | Accuracy: 0.6375\n",
      "Epoch 154/299\n",
      "----------\n",
      "train: Loss: 0.3136 | F1-score: 0.8638 | AUC ROC: 0.9171 | Accuracy: 0.8694\n",
      "test: Loss: 1.1128 | F1-score: 0.6027 | AUC ROC: 0.6920 | Accuracy: 0.6375\n",
      "Epoch 155/299\n",
      "----------\n",
      "train: Loss: 0.3675 | F1-score: 0.8596 | AUC ROC: 0.9057 | Accuracy: 0.8667\n",
      "test: Loss: 0.8613 | F1-score: 0.6027 | AUC ROC: 0.6904 | Accuracy: 0.6375\n",
      "Epoch 156/299\n",
      "----------\n",
      "train: Loss: 0.3399 | F1-score: 0.8682 | AUC ROC: 0.9088 | Accuracy: 0.8722\n",
      "test: Loss: 0.9931 | F1-score: 0.6667 | AUC ROC: 0.7095 | Accuracy: 0.6625\n",
      "new best model 156\n",
      "Epoch 157/299\n",
      "----------\n",
      "train: Loss: 0.5232 | F1-score: 0.8567 | AUC ROC: 0.9117 | Accuracy: 0.8583\n",
      "test: Loss: 0.8141 | F1-score: 0.6389 | AUC ROC: 0.7011 | Accuracy: 0.6750\n",
      "Epoch 158/299\n",
      "----------\n",
      "train: Loss: 0.5670 | F1-score: 0.8739 | AUC ROC: 0.9234 | Accuracy: 0.8778\n",
      "test: Loss: 1.0322 | F1-score: 0.5915 | AUC ROC: 0.6814 | Accuracy: 0.6375\n",
      "Epoch 159/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8612 | AUC ROC: 0.9183 | Accuracy: 0.8653\n",
      "test: Loss: 0.8159 | F1-score: 0.6216 | AUC ROC: 0.6901 | Accuracy: 0.6500\n",
      "Epoch 160/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.8645 | AUC ROC: 0.9022 | Accuracy: 0.8681\n",
      "test: Loss: 0.8142 | F1-score: 0.6000 | AUC ROC: 0.6954 | Accuracy: 0.6500\n",
      "Epoch 161/299\n",
      "----------\n",
      "train: Loss: 0.3172 | F1-score: 0.8873 | AUC ROC: 0.9348 | Accuracy: 0.8917\n",
      "test: Loss: 0.8133 | F1-score: 0.6486 | AUC ROC: 0.6967 | Accuracy: 0.6750\n",
      "Epoch 162/299\n",
      "----------\n",
      "train: Loss: 0.3135 | F1-score: 0.8453 | AUC ROC: 0.9058 | Accuracy: 0.8500\n",
      "test: Loss: 0.8137 | F1-score: 0.6286 | AUC ROC: 0.6798 | Accuracy: 0.6750\n",
      "Epoch 163/299\n",
      "----------\n",
      "train: Loss: 0.5684 | F1-score: 0.8605 | AUC ROC: 0.9185 | Accuracy: 0.8681\n",
      "test: Loss: 0.8248 | F1-score: 0.6087 | AUC ROC: 0.6923 | Accuracy: 0.6625\n",
      "Epoch 164/299\n",
      "----------\n",
      "train: Loss: 0.3154 | F1-score: 0.8484 | AUC ROC: 0.9238 | Accuracy: 0.8556\n",
      "test: Loss: 0.9568 | F1-score: 0.6667 | AUC ROC: 0.6864 | Accuracy: 0.7000\n",
      "Epoch 165/299\n",
      "----------\n",
      "train: Loss: 0.5737 | F1-score: 0.8905 | AUC ROC: 0.9238 | Accuracy: 0.8958\n",
      "test: Loss: 1.0584 | F1-score: 0.6571 | AUC ROC: 0.6892 | Accuracy: 0.7000\n",
      "Epoch 166/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.8779 | AUC ROC: 0.9206 | Accuracy: 0.8833\n",
      "test: Loss: 1.0464 | F1-score: 0.6667 | AUC ROC: 0.6773 | Accuracy: 0.6875\n",
      "Epoch 167/299\n",
      "----------\n",
      "train: Loss: 0.5577 | F1-score: 0.8721 | AUC ROC: 0.9130 | Accuracy: 0.8778\n",
      "test: Loss: 1.1548 | F1-score: 0.6111 | AUC ROC: 0.6698 | Accuracy: 0.6500\n",
      "Epoch 168/299\n",
      "----------\n",
      "train: Loss: 0.6831 | F1-score: 0.8681 | AUC ROC: 0.9298 | Accuracy: 0.8764\n",
      "test: Loss: 1.0516 | F1-score: 0.6053 | AUC ROC: 0.6692 | Accuracy: 0.6250\n",
      "Epoch 169/299\n",
      "----------\n",
      "train: Loss: 0.5580 | F1-score: 0.8842 | AUC ROC: 0.9266 | Accuracy: 0.8861\n",
      "test: Loss: 1.0528 | F1-score: 0.6154 | AUC ROC: 0.6751 | Accuracy: 0.6250\n",
      "Epoch 170/299\n",
      "----------\n",
      "train: Loss: 0.4422 | F1-score: 0.8571 | AUC ROC: 0.9072 | Accuracy: 0.8542\n",
      "test: Loss: 1.0525 | F1-score: 0.6250 | AUC ROC: 0.6861 | Accuracy: 0.6250\n",
      "Epoch 171/299\n",
      "----------\n",
      "train: Loss: 0.3435 | F1-score: 0.8680 | AUC ROC: 0.9193 | Accuracy: 0.8694\n",
      "test: Loss: 1.0503 | F1-score: 0.6316 | AUC ROC: 0.6801 | Accuracy: 0.6500\n",
      "Epoch 172/299\n",
      "----------\n",
      "train: Loss: 0.8232 | F1-score: 0.8674 | AUC ROC: 0.9203 | Accuracy: 0.8722\n",
      "test: Loss: 1.0076 | F1-score: 0.6027 | AUC ROC: 0.6792 | Accuracy: 0.6375\n",
      "Epoch 173/299\n",
      "----------\n",
      "train: Loss: 0.5520 | F1-score: 0.8850 | AUC ROC: 0.9333 | Accuracy: 0.8903\n",
      "test: Loss: 1.0290 | F1-score: 0.6316 | AUC ROC: 0.7011 | Accuracy: 0.6500\n",
      "Epoch 174/299\n",
      "----------\n",
      "train: Loss: 0.3148 | F1-score: 0.8832 | AUC ROC: 0.9182 | Accuracy: 0.8861\n",
      "test: Loss: 1.0429 | F1-score: 0.6389 | AUC ROC: 0.7023 | Accuracy: 0.6750\n",
      "Epoch 175/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8921 | AUC ROC: 0.9426 | Accuracy: 0.8972\n",
      "test: Loss: 1.0428 | F1-score: 0.6216 | AUC ROC: 0.7161 | Accuracy: 0.6500\n",
      "new best model 175\n",
      "Epoch 176/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.8895 | AUC ROC: 0.9348 | Accuracy: 0.8931\n",
      "test: Loss: 0.9743 | F1-score: 0.6575 | AUC ROC: 0.7336 | Accuracy: 0.6875\n",
      "new best model 176\n",
      "Epoch 177/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8974 | AUC ROC: 0.9409 | Accuracy: 0.9028\n",
      "test: Loss: 1.0227 | F1-score: 0.6579 | AUC ROC: 0.7205 | Accuracy: 0.6750\n",
      "Epoch 178/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8686 | AUC ROC: 0.9202 | Accuracy: 0.8722\n",
      "test: Loss: 1.0496 | F1-score: 0.6667 | AUC ROC: 0.7283 | Accuracy: 0.6875\n",
      "Epoch 179/299\n",
      "----------\n",
      "train: Loss: 0.5618 | F1-score: 0.8883 | AUC ROC: 0.9293 | Accuracy: 0.8903\n",
      "test: Loss: 1.0218 | F1-score: 0.6753 | AUC ROC: 0.7367 | Accuracy: 0.6875\n",
      "new best model 179\n",
      "Epoch 180/299\n",
      "----------\n",
      "train: Loss: 0.5719 | F1-score: 0.8776 | AUC ROC: 0.9268 | Accuracy: 0.8833\n",
      "test: Loss: 1.0081 | F1-score: 0.6579 | AUC ROC: 0.7330 | Accuracy: 0.6750\n",
      "Epoch 181/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.8950 | AUC ROC: 0.9392 | Accuracy: 0.8986\n",
      "test: Loss: 0.8638 | F1-score: 0.6486 | AUC ROC: 0.7292 | Accuracy: 0.6750\n",
      "Epoch 182/299\n",
      "----------\n",
      "train: Loss: 0.3143 | F1-score: 0.8686 | AUC ROC: 0.9151 | Accuracy: 0.8722\n",
      "test: Loss: 0.9790 | F1-score: 0.6316 | AUC ROC: 0.7283 | Accuracy: 0.6500\n",
      "Epoch 183/299\n",
      "----------\n",
      "train: Loss: 0.3377 | F1-score: 0.8961 | AUC ROC: 0.9334 | Accuracy: 0.8972\n",
      "test: Loss: 0.8501 | F1-score: 0.6389 | AUC ROC: 0.7236 | Accuracy: 0.6750\n",
      "Epoch 184/299\n",
      "----------\n",
      "train: Loss: 0.3565 | F1-score: 0.9023 | AUC ROC: 0.9448 | Accuracy: 0.9056\n",
      "test: Loss: 0.8669 | F1-score: 0.6197 | AUC ROC: 0.7192 | Accuracy: 0.6625\n",
      "Epoch 185/299\n",
      "----------\n",
      "train: Loss: 0.5725 | F1-score: 0.8944 | AUC ROC: 0.9432 | Accuracy: 0.9000\n",
      "test: Loss: 0.9629 | F1-score: 0.6494 | AUC ROC: 0.7183 | Accuracy: 0.6625\n",
      "Epoch 186/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8725 | AUC ROC: 0.9154 | Accuracy: 0.8750\n",
      "test: Loss: 0.9655 | F1-score: 0.6579 | AUC ROC: 0.7167 | Accuracy: 0.6750\n",
      "Epoch 187/299\n",
      "----------\n",
      "train: Loss: 0.5706 | F1-score: 0.8835 | AUC ROC: 0.9274 | Accuracy: 0.8861\n",
      "test: Loss: 0.8942 | F1-score: 0.6579 | AUC ROC: 0.7280 | Accuracy: 0.6750\n",
      "Epoch 188/299\n",
      "----------\n",
      "train: Loss: 0.3144 | F1-score: 0.8947 | AUC ROC: 0.9371 | Accuracy: 0.8986\n",
      "test: Loss: 0.8142 | F1-score: 0.6757 | AUC ROC: 0.7123 | Accuracy: 0.7000\n",
      "Epoch 189/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8953 | AUC ROC: 0.9317 | Accuracy: 0.8986\n",
      "test: Loss: 0.9851 | F1-score: 0.6486 | AUC ROC: 0.7070 | Accuracy: 0.6750\n",
      "Epoch 190/299\n",
      "----------\n",
      "train: Loss: 0.7183 | F1-score: 0.8899 | AUC ROC: 0.9374 | Accuracy: 0.8944\n",
      "test: Loss: 0.8546 | F1-score: 0.6761 | AUC ROC: 0.7280 | Accuracy: 0.7125\n",
      "Epoch 191/299\n",
      "----------\n",
      "train: Loss: 0.3980 | F1-score: 0.9007 | AUC ROC: 0.9391 | Accuracy: 0.9042\n",
      "test: Loss: 0.8133 | F1-score: 0.6000 | AUC ROC: 0.7248 | Accuracy: 0.6500\n",
      "Epoch 192/299\n",
      "----------\n",
      "train: Loss: 0.3393 | F1-score: 0.9073 | AUC ROC: 0.9452 | Accuracy: 0.9097\n",
      "test: Loss: 0.8133 | F1-score: 0.6197 | AUC ROC: 0.7123 | Accuracy: 0.6625\n",
      "Epoch 193/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9138 | AUC ROC: 0.9519 | Accuracy: 0.9167\n",
      "test: Loss: 0.8133 | F1-score: 0.6389 | AUC ROC: 0.6967 | Accuracy: 0.6750\n",
      "Epoch 194/299\n",
      "----------\n",
      "train: Loss: 0.3142 | F1-score: 0.8856 | AUC ROC: 0.9343 | Accuracy: 0.8917\n",
      "test: Loss: 0.8134 | F1-score: 0.5758 | AUC ROC: 0.7020 | Accuracy: 0.6500\n",
      "Epoch 195/299\n",
      "----------\n",
      "train: Loss: 0.3150 | F1-score: 0.9003 | AUC ROC: 0.9458 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.5312 | AUC ROC: 0.6998 | Accuracy: 0.6250\n",
      "Epoch 196/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.8938 | AUC ROC: 0.9220 | Accuracy: 0.9000\n",
      "test: Loss: 0.8133 | F1-score: 0.5231 | AUC ROC: 0.6973 | Accuracy: 0.6125\n",
      "Epoch 197/299\n",
      "----------\n",
      "train: Loss: 0.4556 | F1-score: 0.8915 | AUC ROC: 0.9434 | Accuracy: 0.8972\n",
      "test: Loss: 0.8133 | F1-score: 0.5312 | AUC ROC: 0.6992 | Accuracy: 0.6250\n",
      "Epoch 198/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8889 | AUC ROC: 0.9225 | Accuracy: 0.8958\n",
      "test: Loss: 0.8133 | F1-score: 0.5455 | AUC ROC: 0.7039 | Accuracy: 0.6250\n",
      "Epoch 199/299\n",
      "----------\n",
      "train: Loss: 0.3324 | F1-score: 0.8873 | AUC ROC: 0.9373 | Accuracy: 0.8931\n",
      "test: Loss: 0.8133 | F1-score: 0.5625 | AUC ROC: 0.7026 | Accuracy: 0.6500\n",
      "Epoch 200/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.8991 | AUC ROC: 0.9382 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.5397 | AUC ROC: 0.7051 | Accuracy: 0.6375\n",
      "Epoch 201/299\n",
      "----------\n",
      "train: Loss: 0.3199 | F1-score: 0.9101 | AUC ROC: 0.9488 | Accuracy: 0.9139\n",
      "test: Loss: 0.8133 | F1-score: 0.5758 | AUC ROC: 0.7114 | Accuracy: 0.6500\n",
      "Epoch 202/299\n",
      "----------\n",
      "train: Loss: 0.3260 | F1-score: 0.8978 | AUC ROC: 0.9393 | Accuracy: 0.9014\n",
      "test: Loss: 0.8133 | F1-score: 0.5625 | AUC ROC: 0.7083 | Accuracy: 0.6500\n",
      "Epoch 203/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9064 | AUC ROC: 0.9405 | Accuracy: 0.9111\n",
      "test: Loss: 0.8133 | F1-score: 0.5397 | AUC ROC: 0.7161 | Accuracy: 0.6375\n",
      "Epoch 204/299\n",
      "----------\n",
      "train: Loss: 0.6210 | F1-score: 0.9006 | AUC ROC: 0.9464 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.5397 | AUC ROC: 0.7208 | Accuracy: 0.6375\n",
      "Epoch 205/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8941 | AUC ROC: 0.9271 | Accuracy: 0.9000\n",
      "test: Loss: 0.8136 | F1-score: 0.5625 | AUC ROC: 0.7173 | Accuracy: 0.6500\n",
      "Epoch 206/299\n",
      "----------\n",
      "train: Loss: 0.3146 | F1-score: 0.8713 | AUC ROC: 0.9185 | Accuracy: 0.8806\n",
      "test: Loss: 0.8135 | F1-score: 0.5882 | AUC ROC: 0.7108 | Accuracy: 0.6500\n",
      "Epoch 207/299\n",
      "----------\n",
      "train: Loss: 0.4474 | F1-score: 0.8860 | AUC ROC: 0.9321 | Accuracy: 0.8889\n",
      "test: Loss: 0.8133 | F1-score: 0.6479 | AUC ROC: 0.7186 | Accuracy: 0.6875\n",
      "Epoch 208/299\n",
      "----------\n",
      "train: Loss: 0.3193 | F1-score: 0.8927 | AUC ROC: 0.9430 | Accuracy: 0.8944\n",
      "test: Loss: 0.8133 | F1-score: 0.6176 | AUC ROC: 0.7173 | Accuracy: 0.6750\n",
      "Epoch 209/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.9034 | AUC ROC: 0.9425 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.6377 | AUC ROC: 0.7267 | Accuracy: 0.6875\n",
      "Epoch 210/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8971 | AUC ROC: 0.9362 | Accuracy: 0.9000\n",
      "test: Loss: 0.8133 | F1-score: 0.5970 | AUC ROC: 0.7114 | Accuracy: 0.6625\n",
      "Epoch 211/299\n",
      "----------\n",
      "train: Loss: 0.8119 | F1-score: 0.9083 | AUC ROC: 0.9347 | Accuracy: 0.9139\n",
      "test: Loss: 0.8133 | F1-score: 0.6087 | AUC ROC: 0.7195 | Accuracy: 0.6625\n",
      "Epoch 212/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9199 | AUC ROC: 0.9517 | Accuracy: 0.9236\n",
      "test: Loss: 0.8133 | F1-score: 0.5758 | AUC ROC: 0.7164 | Accuracy: 0.6500\n",
      "Epoch 213/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8886 | AUC ROC: 0.9211 | Accuracy: 0.8917\n",
      "test: Loss: 0.8133 | F1-score: 0.6667 | AUC ROC: 0.7111 | Accuracy: 0.6875\n",
      "Epoch 214/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8992 | AUC ROC: 0.9497 | Accuracy: 0.9000\n",
      "test: Loss: 0.8133 | F1-score: 0.6197 | AUC ROC: 0.7151 | Accuracy: 0.6625\n",
      "Epoch 215/299\n",
      "----------\n",
      "train: Loss: 0.7939 | F1-score: 0.9042 | AUC ROC: 0.9370 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.6667 | AUC ROC: 0.7186 | Accuracy: 0.6875\n",
      "Epoch 216/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8979 | AUC ROC: 0.9457 | Accuracy: 0.8986\n",
      "test: Loss: 0.8133 | F1-score: 0.7013 | AUC ROC: 0.7258 | Accuracy: 0.7125\n",
      "Epoch 217/299\n",
      "----------\n",
      "train: Loss: 0.3159 | F1-score: 0.8833 | AUC ROC: 0.9344 | Accuracy: 0.8847\n",
      "test: Loss: 0.8133 | F1-score: 0.5758 | AUC ROC: 0.7114 | Accuracy: 0.6500\n",
      "Epoch 218/299\n",
      "----------\n",
      "train: Loss: 0.3172 | F1-score: 0.8997 | AUC ROC: 0.9421 | Accuracy: 0.9028\n",
      "test: Loss: 0.8133 | F1-score: 0.6579 | AUC ROC: 0.7189 | Accuracy: 0.6750\n",
      "Epoch 219/299\n",
      "----------\n",
      "train: Loss: 0.5536 | F1-score: 0.9043 | AUC ROC: 0.9406 | Accuracy: 0.9083\n",
      "test: Loss: 0.8133 | F1-score: 0.6389 | AUC ROC: 0.7283 | Accuracy: 0.6750\n",
      "Epoch 220/299\n",
      "----------\n",
      "train: Loss: 0.7473 | F1-score: 0.9023 | AUC ROC: 0.9465 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.6301 | AUC ROC: 0.7283 | Accuracy: 0.6625\n",
      "Epoch 221/299\n",
      "----------\n",
      "train: Loss: 0.5165 | F1-score: 0.8936 | AUC ROC: 0.9359 | Accuracy: 0.8944\n",
      "test: Loss: 0.8133 | F1-score: 0.6582 | AUC ROC: 0.7255 | Accuracy: 0.6625\n",
      "Epoch 222/299\n",
      "----------\n",
      "train: Loss: 0.5603 | F1-score: 0.9070 | AUC ROC: 0.9430 | Accuracy: 0.9083\n",
      "test: Loss: 0.8133 | F1-score: 0.6582 | AUC ROC: 0.7289 | Accuracy: 0.6625\n",
      "Epoch 223/299\n",
      "----------\n",
      "train: Loss: 0.3560 | F1-score: 0.9038 | AUC ROC: 0.9386 | Accuracy: 0.9042\n",
      "test: Loss: 0.8133 | F1-score: 0.6575 | AUC ROC: 0.7317 | Accuracy: 0.6875\n",
      "Epoch 224/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.8990 | AUC ROC: 0.9387 | Accuracy: 0.9042\n",
      "test: Loss: 0.8133 | F1-score: 0.6269 | AUC ROC: 0.7652 | Accuracy: 0.6875\n",
      "new best model 224\n",
      "Epoch 225/299\n",
      "----------\n",
      "train: Loss: 0.7841 | F1-score: 0.8851 | AUC ROC: 0.9306 | Accuracy: 0.8889\n",
      "test: Loss: 0.8133 | F1-score: 0.7027 | AUC ROC: 0.7517 | Accuracy: 0.7250\n",
      "Epoch 226/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9229 | AUC ROC: 0.9468 | Accuracy: 0.9236\n",
      "test: Loss: 0.8133 | F1-score: 0.6842 | AUC ROC: 0.7380 | Accuracy: 0.7000\n",
      "Epoch 227/299\n",
      "----------\n",
      "train: Loss: 0.3189 | F1-score: 0.9132 | AUC ROC: 0.9389 | Accuracy: 0.9139\n",
      "test: Loss: 0.8133 | F1-score: 0.7027 | AUC ROC: 0.7527 | Accuracy: 0.7250\n",
      "Epoch 228/299\n",
      "----------\n",
      "train: Loss: 0.5779 | F1-score: 0.9042 | AUC ROC: 0.9400 | Accuracy: 0.9056\n",
      "test: Loss: 0.8133 | F1-score: 0.6667 | AUC ROC: 0.7383 | Accuracy: 0.6625\n",
      "Epoch 229/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.8997 | AUC ROC: 0.9437 | Accuracy: 0.9000\n",
      "test: Loss: 0.8133 | F1-score: 0.6494 | AUC ROC: 0.7367 | Accuracy: 0.6625\n",
      "Epoch 230/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.8927 | AUC ROC: 0.9387 | Accuracy: 0.8958\n",
      "test: Loss: 0.8133 | F1-score: 0.6486 | AUC ROC: 0.7458 | Accuracy: 0.6750\n",
      "Epoch 231/299\n",
      "----------\n",
      "train: Loss: 0.3137 | F1-score: 0.9060 | AUC ROC: 0.9434 | Accuracy: 0.9083\n",
      "test: Loss: 0.8133 | F1-score: 0.6761 | AUC ROC: 0.7373 | Accuracy: 0.7125\n",
      "Epoch 232/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9140 | AUC ROC: 0.9536 | Accuracy: 0.9167\n",
      "test: Loss: 0.8133 | F1-score: 0.6571 | AUC ROC: 0.7498 | Accuracy: 0.7000\n",
      "Epoch 233/299\n",
      "----------\n",
      "train: Loss: 0.3989 | F1-score: 0.8922 | AUC ROC: 0.9304 | Accuracy: 0.8986\n",
      "test: Loss: 0.8133 | F1-score: 0.6849 | AUC ROC: 0.7608 | Accuracy: 0.7125\n",
      "Epoch 234/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.8960 | AUC ROC: 0.9289 | Accuracy: 0.9000\n",
      "test: Loss: 0.8133 | F1-score: 0.7105 | AUC ROC: 0.7642 | Accuracy: 0.7250\n",
      "Epoch 235/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9158 | AUC ROC: 0.9439 | Accuracy: 0.9181\n",
      "test: Loss: 0.8133 | F1-score: 0.6944 | AUC ROC: 0.7799 | Accuracy: 0.7250\n",
      "new best model 235\n",
      "Epoch 236/299\n",
      "----------\n",
      "train: Loss: 0.5666 | F1-score: 0.9112 | AUC ROC: 0.9443 | Accuracy: 0.9153\n",
      "test: Loss: 0.8133 | F1-score: 0.6944 | AUC ROC: 0.7799 | Accuracy: 0.7250\n",
      "Epoch 237/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9162 | AUC ROC: 0.9457 | Accuracy: 0.9194\n",
      "test: Loss: 0.8133 | F1-score: 0.6944 | AUC ROC: 0.7861 | Accuracy: 0.7250\n",
      "new best model 237\n",
      "Epoch 238/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.9054 | AUC ROC: 0.9493 | Accuracy: 0.9097\n",
      "test: Loss: 0.8133 | F1-score: 0.6667 | AUC ROC: 0.7783 | Accuracy: 0.7000\n",
      "Epoch 239/299\n",
      "----------\n",
      "train: Loss: 0.5686 | F1-score: 0.8921 | AUC ROC: 0.9407 | Accuracy: 0.8972\n",
      "test: Loss: 0.8133 | F1-score: 0.6286 | AUC ROC: 0.7677 | Accuracy: 0.6750\n",
      "Epoch 240/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9130 | AUC ROC: 0.9576 | Accuracy: 0.9167\n",
      "test: Loss: 0.8133 | F1-score: 0.6087 | AUC ROC: 0.7567 | Accuracy: 0.6625\n",
      "Epoch 241/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9057 | AUC ROC: 0.9482 | Accuracy: 0.9097\n",
      "test: Loss: 0.8133 | F1-score: 0.6087 | AUC ROC: 0.7467 | Accuracy: 0.6625\n",
      "Epoch 242/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9291 | AUC ROC: 0.9581 | Accuracy: 0.9319\n",
      "test: Loss: 0.8133 | F1-score: 0.6087 | AUC ROC: 0.7617 | Accuracy: 0.6625\n",
      "Epoch 243/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9004 | AUC ROC: 0.9441 | Accuracy: 0.9042\n",
      "test: Loss: 0.8133 | F1-score: 0.6286 | AUC ROC: 0.7733 | Accuracy: 0.6750\n",
      "Epoch 244/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9157 | AUC ROC: 0.9514 | Accuracy: 0.9194\n",
      "test: Loss: 0.8133 | F1-score: 0.6087 | AUC ROC: 0.7705 | Accuracy: 0.6625\n",
      "Epoch 245/299\n",
      "----------\n",
      "train: Loss: 0.3170 | F1-score: 0.9188 | AUC ROC: 0.9442 | Accuracy: 0.9236\n",
      "test: Loss: 0.8133 | F1-score: 0.6944 | AUC ROC: 0.7817 | Accuracy: 0.7250\n",
      "Epoch 246/299\n",
      "----------\n",
      "train: Loss: 0.5149 | F1-score: 0.9099 | AUC ROC: 0.9445 | Accuracy: 0.9125\n",
      "test: Loss: 0.8133 | F1-score: 0.7595 | AUC ROC: 0.7877 | Accuracy: 0.7625\n",
      "new best model 246\n",
      "Epoch 247/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9140 | AUC ROC: 0.9537 | Accuracy: 0.9167\n",
      "test: Loss: 0.8133 | F1-score: 0.7500 | AUC ROC: 0.7880 | Accuracy: 0.7500\n",
      "new best model 247\n",
      "Epoch 248/299\n",
      "----------\n",
      "train: Loss: 0.4131 | F1-score: 0.9222 | AUC ROC: 0.9514 | Accuracy: 0.9236\n",
      "test: Loss: 0.8133 | F1-score: 0.7273 | AUC ROC: 0.7877 | Accuracy: 0.7375\n",
      "Epoch 249/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.9209 | AUC ROC: 0.9513 | Accuracy: 0.9222\n",
      "test: Loss: 0.8133 | F1-score: 0.7105 | AUC ROC: 0.7899 | Accuracy: 0.7250\n",
      "new best model 249\n",
      "Epoch 250/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9198 | AUC ROC: 0.9624 | Accuracy: 0.9222\n",
      "test: Loss: 0.8133 | F1-score: 0.7105 | AUC ROC: 0.7905 | Accuracy: 0.7250\n",
      "new best model 250\n",
      "Epoch 251/299\n",
      "----------\n",
      "train: Loss: 0.5741 | F1-score: 0.9112 | AUC ROC: 0.9539 | Accuracy: 0.9139\n",
      "test: Loss: 0.8133 | F1-score: 0.6933 | AUC ROC: 0.7877 | Accuracy: 0.7125\n",
      "Epoch 252/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9242 | AUC ROC: 0.9506 | Accuracy: 0.9264\n",
      "test: Loss: 0.8133 | F1-score: 0.6849 | AUC ROC: 0.7774 | Accuracy: 0.7125\n",
      "Epoch 253/299\n",
      "----------\n",
      "train: Loss: 0.5847 | F1-score: 0.9290 | AUC ROC: 0.9542 | Accuracy: 0.9306\n",
      "test: Loss: 0.8133 | F1-score: 0.7179 | AUC ROC: 0.7814 | Accuracy: 0.7250\n",
      "Epoch 254/299\n",
      "----------\n",
      "train: Loss: 0.3206 | F1-score: 0.9091 | AUC ROC: 0.9507 | Accuracy: 0.9111\n",
      "test: Loss: 0.8133 | F1-score: 0.6757 | AUC ROC: 0.7802 | Accuracy: 0.7000\n",
      "Epoch 255/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.9244 | AUC ROC: 0.9527 | Accuracy: 0.9264\n",
      "test: Loss: 0.8133 | F1-score: 0.7123 | AUC ROC: 0.7814 | Accuracy: 0.7375\n",
      "Epoch 256/299\n",
      "----------\n",
      "train: Loss: 0.3138 | F1-score: 0.9253 | AUC ROC: 0.9547 | Accuracy: 0.9278\n",
      "test: Loss: 0.8133 | F1-score: 0.7436 | AUC ROC: 0.8030 | Accuracy: 0.7500\n",
      "new best model 256\n",
      "Epoch 257/299\n",
      "----------\n",
      "train: Loss: 0.3347 | F1-score: 0.9167 | AUC ROC: 0.9517 | Accuracy: 0.9194\n",
      "test: Loss: 0.8133 | F1-score: 0.6944 | AUC ROC: 0.8039 | Accuracy: 0.7250\n",
      "new best model 257\n",
      "Epoch 258/299\n",
      "----------\n",
      "train: Loss: 0.3138 | F1-score: 0.9386 | AUC ROC: 0.9588 | Accuracy: 0.9417\n",
      "test: Loss: 0.8133 | F1-score: 0.6471 | AUC ROC: 0.7986 | Accuracy: 0.7000\n",
      "Epoch 259/299\n",
      "----------\n",
      "train: Loss: 0.3186 | F1-score: 0.9269 | AUC ROC: 0.9503 | Accuracy: 0.9306\n",
      "test: Loss: 0.8133 | F1-score: 0.6667 | AUC ROC: 0.8080 | Accuracy: 0.7000\n",
      "new best model 259\n",
      "Epoch 260/299\n",
      "----------\n",
      "train: Loss: 0.5528 | F1-score: 0.9186 | AUC ROC: 0.9482 | Accuracy: 0.9222\n",
      "test: Loss: 0.8133 | F1-score: 0.6667 | AUC ROC: 0.8083 | Accuracy: 0.7250\n",
      "new best model 260\n",
      "Epoch 261/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9242 | AUC ROC: 0.9576 | Accuracy: 0.9292\n",
      "test: Loss: 0.8133 | F1-score: 0.6364 | AUC ROC: 0.7958 | Accuracy: 0.7000\n",
      "Epoch 262/299\n",
      "----------\n",
      "train: Loss: 0.5133 | F1-score: 0.9262 | AUC ROC: 0.9505 | Accuracy: 0.9292\n",
      "test: Loss: 0.8133 | F1-score: 0.6575 | AUC ROC: 0.7877 | Accuracy: 0.6875\n",
      "Epoch 263/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9292 | AUC ROC: 0.9586 | Accuracy: 0.9306\n",
      "test: Loss: 0.8133 | F1-score: 0.6571 | AUC ROC: 0.7874 | Accuracy: 0.7000\n",
      "Epoch 264/299\n",
      "----------\n",
      "train: Loss: 0.8234 | F1-score: 0.9207 | AUC ROC: 0.9561 | Accuracy: 0.9222\n",
      "test: Loss: 0.8133 | F1-score: 0.6154 | AUC ROC: 0.7836 | Accuracy: 0.6875\n",
      "Epoch 265/299\n",
      "----------\n",
      "train: Loss: 0.5738 | F1-score: 0.9314 | AUC ROC: 0.9582 | Accuracy: 0.9347\n",
      "test: Loss: 0.8133 | F1-score: 0.6061 | AUC ROC: 0.7767 | Accuracy: 0.6750\n",
      "Epoch 266/299\n",
      "----------\n",
      "train: Loss: 0.3135 | F1-score: 0.9242 | AUC ROC: 0.9607 | Accuracy: 0.9264\n",
      "test: Loss: 0.8133 | F1-score: 0.7027 | AUC ROC: 0.7739 | Accuracy: 0.7250\n",
      "Epoch 267/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9151 | AUC ROC: 0.9487 | Accuracy: 0.9181\n",
      "test: Loss: 0.8133 | F1-score: 0.7123 | AUC ROC: 0.7858 | Accuracy: 0.7375\n",
      "Epoch 268/299\n",
      "----------\n",
      "train: Loss: 0.5737 | F1-score: 0.9353 | AUC ROC: 0.9607 | Accuracy: 0.9375\n",
      "test: Loss: 0.8133 | F1-score: 0.6571 | AUC ROC: 0.7833 | Accuracy: 0.7000\n",
      "Epoch 269/299\n",
      "----------\n",
      "train: Loss: 0.3174 | F1-score: 0.9373 | AUC ROC: 0.9665 | Accuracy: 0.9417\n",
      "test: Loss: 0.8133 | F1-score: 0.6761 | AUC ROC: 0.7767 | Accuracy: 0.7125\n",
      "Epoch 270/299\n",
      "----------\n",
      "train: Loss: 0.3180 | F1-score: 0.9144 | AUC ROC: 0.9520 | Accuracy: 0.9181\n",
      "test: Loss: 0.8133 | F1-score: 0.6761 | AUC ROC: 0.7780 | Accuracy: 0.7125\n",
      "Epoch 271/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9366 | AUC ROC: 0.9599 | Accuracy: 0.9389\n",
      "test: Loss: 0.8133 | F1-score: 0.7027 | AUC ROC: 0.7742 | Accuracy: 0.7250\n",
      "Epoch 272/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.9235 | AUC ROC: 0.9505 | Accuracy: 0.9250\n",
      "test: Loss: 0.8133 | F1-score: 0.6849 | AUC ROC: 0.7724 | Accuracy: 0.7125\n",
      "Epoch 273/299\n",
      "----------\n",
      "train: Loss: 0.3141 | F1-score: 0.9293 | AUC ROC: 0.9495 | Accuracy: 0.9319\n",
      "test: Loss: 0.8133 | F1-score: 0.6377 | AUC ROC: 0.7692 | Accuracy: 0.6875\n",
      "Epoch 274/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9129 | AUC ROC: 0.9485 | Accuracy: 0.9181\n",
      "test: Loss: 0.8133 | F1-score: 0.6286 | AUC ROC: 0.7674 | Accuracy: 0.6750\n",
      "Epoch 275/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9188 | AUC ROC: 0.9522 | Accuracy: 0.9222\n",
      "test: Loss: 0.8133 | F1-score: 0.6087 | AUC ROC: 0.7636 | Accuracy: 0.6625\n",
      "Epoch 276/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9201 | AUC ROC: 0.9484 | Accuracy: 0.9250\n",
      "test: Loss: 0.8133 | F1-score: 0.6571 | AUC ROC: 0.7692 | Accuracy: 0.7000\n",
      "Epoch 277/299\n",
      "----------\n",
      "train: Loss: 0.3134 | F1-score: 0.9208 | AUC ROC: 0.9539 | Accuracy: 0.9250\n",
      "test: Loss: 0.8133 | F1-score: 0.6761 | AUC ROC: 0.7739 | Accuracy: 0.7125\n",
      "Epoch 278/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9251 | AUC ROC: 0.9491 | Accuracy: 0.9292\n",
      "test: Loss: 0.8133 | F1-score: 0.6761 | AUC ROC: 0.7883 | Accuracy: 0.7125\n",
      "Epoch 279/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9242 | AUC ROC: 0.9552 | Accuracy: 0.9292\n",
      "test: Loss: 0.8133 | F1-score: 0.7532 | AUC ROC: 0.7946 | Accuracy: 0.7625\n",
      "Epoch 280/299\n",
      "----------\n",
      "train: Loss: 0.5588 | F1-score: 0.9158 | AUC ROC: 0.9556 | Accuracy: 0.9181\n",
      "test: Loss: 0.8133 | F1-score: 0.7273 | AUC ROC: 0.7880 | Accuracy: 0.7375\n",
      "Epoch 281/299\n",
      "----------\n",
      "train: Loss: 0.3180 | F1-score: 0.9429 | AUC ROC: 0.9627 | Accuracy: 0.9458\n",
      "test: Loss: 0.8133 | F1-score: 0.6944 | AUC ROC: 0.7877 | Accuracy: 0.7250\n",
      "Epoch 282/299\n",
      "----------\n",
      "train: Loss: 0.4898 | F1-score: 0.9112 | AUC ROC: 0.9463 | Accuracy: 0.9167\n",
      "test: Loss: 0.8133 | F1-score: 0.7436 | AUC ROC: 0.8058 | Accuracy: 0.7500\n",
      "Epoch 283/299\n",
      "----------\n",
      "train: Loss: 0.5528 | F1-score: 0.9122 | AUC ROC: 0.9442 | Accuracy: 0.9153\n",
      "test: Loss: 0.8133 | F1-score: 0.7529 | AUC ROC: 0.7989 | Accuracy: 0.7375\n",
      "Epoch 284/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9299 | AUC ROC: 0.9617 | Accuracy: 0.9319\n",
      "test: Loss: 0.8133 | F1-score: 0.7250 | AUC ROC: 0.8064 | Accuracy: 0.7250\n",
      "Epoch 285/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9187 | AUC ROC: 0.9579 | Accuracy: 0.9208\n",
      "test: Loss: 0.8133 | F1-score: 0.7532 | AUC ROC: 0.8099 | Accuracy: 0.7625\n",
      "new best model 285\n",
      "Epoch 286/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9335 | AUC ROC: 0.9627 | Accuracy: 0.9361\n",
      "test: Loss: 0.8133 | F1-score: 0.7467 | AUC ROC: 0.8089 | Accuracy: 0.7625\n",
      "Epoch 287/299\n",
      "----------\n",
      "train: Loss: 0.5737 | F1-score: 0.9370 | AUC ROC: 0.9643 | Accuracy: 0.9389\n",
      "test: Loss: 0.8133 | F1-score: 0.7467 | AUC ROC: 0.8008 | Accuracy: 0.7625\n",
      "Epoch 288/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9199 | AUC ROC: 0.9577 | Accuracy: 0.9236\n",
      "test: Loss: 0.8133 | F1-score: 0.7467 | AUC ROC: 0.8033 | Accuracy: 0.7625\n",
      "Epoch 289/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9272 | AUC ROC: 0.9547 | Accuracy: 0.9292\n",
      "test: Loss: 0.8133 | F1-score: 0.7470 | AUC ROC: 0.7999 | Accuracy: 0.7375\n",
      "Epoch 290/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9345 | AUC ROC: 0.9553 | Accuracy: 0.9361\n",
      "test: Loss: 0.8133 | F1-score: 0.7250 | AUC ROC: 0.7983 | Accuracy: 0.7250\n",
      "Epoch 291/299\n",
      "----------\n",
      "train: Loss: 0.5555 | F1-score: 0.9293 | AUC ROC: 0.9583 | Accuracy: 0.9319\n",
      "test: Loss: 0.8133 | F1-score: 0.7027 | AUC ROC: 0.8018 | Accuracy: 0.7250\n",
      "Epoch 292/299\n",
      "----------\n",
      "train: Loss: 0.5684 | F1-score: 0.9368 | AUC ROC: 0.9571 | Accuracy: 0.9389\n",
      "test: Loss: 0.8133 | F1-score: 0.7368 | AUC ROC: 0.8036 | Accuracy: 0.7500\n",
      "Epoch 293/299\n",
      "----------\n",
      "train: Loss: 0.3136 | F1-score: 0.9310 | AUC ROC: 0.9585 | Accuracy: 0.9333\n",
      "test: Loss: 0.8133 | F1-score: 0.7160 | AUC ROC: 0.8018 | Accuracy: 0.7125\n",
      "Epoch 294/299\n",
      "----------\n",
      "train: Loss: 0.5800 | F1-score: 0.9375 | AUC ROC: 0.9638 | Accuracy: 0.9389\n",
      "test: Loss: 0.8133 | F1-score: 0.7250 | AUC ROC: 0.7936 | Accuracy: 0.7250\n",
      "Epoch 295/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9425 | AUC ROC: 0.9725 | Accuracy: 0.9444\n",
      "test: Loss: 0.8133 | F1-score: 0.7397 | AUC ROC: 0.8018 | Accuracy: 0.7625\n",
      "Epoch 296/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9233 | AUC ROC: 0.9497 | Accuracy: 0.9264\n",
      "test: Loss: 0.8133 | F1-score: 0.7042 | AUC ROC: 0.8093 | Accuracy: 0.7375\n",
      "Epoch 297/299\n",
      "----------\n",
      "train: Loss: 0.5579 | F1-score: 0.9140 | AUC ROC: 0.9408 | Accuracy: 0.9208\n",
      "test: Loss: 0.8133 | F1-score: 0.7324 | AUC ROC: 0.8139 | Accuracy: 0.7625\n",
      "new best model 297\n",
      "Epoch 298/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9201 | AUC ROC: 0.9511 | Accuracy: 0.9250\n",
      "test: Loss: 0.8133 | F1-score: 0.7297 | AUC ROC: 0.8049 | Accuracy: 0.7500\n",
      "Epoch 299/299\n",
      "----------\n",
      "train: Loss: 0.3133 | F1-score: 0.9410 | AUC ROC: 0.9673 | Accuracy: 0.9444\n",
      "test: Loss: 0.8133 | F1-score: 0.7297 | AUC ROC: 0.7983 | Accuracy: 0.7500\n",
      "Evaluating 20240613_0044_None__imdb_text_ann_0.001_auc_roc_0.81.pt\n",
      "Best model: 20240613_0044_None__imdb_text_ann_0.001_auc_roc_0.81.pt\n",
      "Vocabulary size: 2595\n",
      "F1-score: 0.7324 | Accuracy: 0.7625 | AUC-ROC: 0.8139\n",
      "Proportion of ones in val set: 0.512\n",
      "Proportion of ones predicted in val set:  0.367\n",
      "Proportion of ones in train set: 0.479\n",
      "Proportion of ones predicted in train set:  0.478 \n"
     ]
    }
   ],
   "source": [
    "device = 'mps' #'mps'\n",
    "dim_per_layer_per_MLP = {'ann_s':  [16, 2],\n",
    "                         'ann_m':  [32, 16, 2],\n",
    "                         'ann_l':  [64, 32, 16, 2],\n",
    "                         'ann_xl': [256, 128, 64, 32, 16, 2],\n",
    "                         'ann_xxl': [512, 256, 128, 64, 32, 16, 8, 2], \n",
    "                         'lr':     [2],\n",
    "                         'text_ann': [None]\n",
    "                         }  # dimension for each layer for each network to train, ignoring input layer size\n",
    "activation_per_layer_per_MLP = {'ann_s':  [nn.ReLU(), None],\n",
    "                                'ann_m':  [nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_l':  [nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_xl': [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_xxl': [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'lr':     [None],\n",
    "                                'text_ann': [None]\n",
    "                                } # ignore input layer size\n",
    "\n",
    "data_names          = ['imdb'] # 'yelp', 'amazon_1000', 'imdb', 'adult', 'compas', 'credit', 'german', 'heloc', 'credit']#, 'rcdv', 'student'] # 'lending-club',\n",
    "model_names         = ['text_ann'] #'ann_l', 'ann_xl', 'ann_xxl']#['lr', 'ann_s', 'ann_m', 'ann_l', 'ann_xl']\n",
    "epochs              = 300\n",
    "learning_rate       = 0.001\n",
    "use_class_weighting = True\n",
    "embedding_dim       = 256\n",
    "batch_size          = 4\n",
    "\n",
    "for data_name in data_names:\n",
    "    if data_name == 'beauty' or data_name == 'amazon_1000' or data_name == 'imdb' or data_name == 'yelp':\n",
    "        modality = 'text'\n",
    "    else:\n",
    "        modality = 'tabular'\n",
    "    for model_name in model_names:\n",
    "        print(\"Training:\", model_name, \"on\", data_name)\n",
    "        # Define hyperparameters\n",
    "        exp_id   = getExperimentID()\n",
    "        dir_name = model_name.upper()\n",
    "\n",
    "        # Get the data for training and evaluation\n",
    "        if data_name in ['compas', 'blood', 'beauty', 'amazon_1000', 'imdb', 'yelp']:\n",
    "            download_data = False\n",
    "        else:\n",
    "            download_data = True\n",
    "\n",
    "        loader_train, loader_val, loader_test = return_loaders(data_name=data_name, download=download_data, batch_size=batch_size, scaler='minmax')\n",
    "\n",
    "        if data_name == 'amazon_1000' or data_name == 'imdb' or data_name == 'yelp':\n",
    "            X_train = [data[0] for data in loader_train.dataset]\n",
    "            y_train = np.array([data[1] for data in loader_train.dataset])\n",
    "            X_val   = [data[0] for data in loader_val.dataset]\n",
    "            y_val   = np.array([data[1] for data in loader_val.dataset])\n",
    "            X_test  = [data[0] for data in loader_test.dataset]\n",
    "            y_test  = np.array([data[1] for data in loader_test.dataset])\n",
    "        else:\n",
    "            X_train, y_train = loader_train.dataset.data, loader_train.dataset.targets\n",
    "            X_val, y_val     = loader_val.dataset.data, loader_val.dataset.targets\n",
    "            X_test, y_test   = loader_test.dataset.data, loader_test.dataset.targets\n",
    "        \n",
    "        # if y_train isn't numpy, convert it to numpy\n",
    "        if not isinstance(y_train, np.ndarray):\n",
    "            y_train = y_train.to_numpy()\n",
    "            y_val   = y_val.to_numpy()\n",
    "            y_test  = y_test.to_numpy()\n",
    "\n",
    "        # Define the model\n",
    "        layer_info_str = '' #empty for lr, fill for ann\n",
    "        for d in dim_per_layer_per_MLP[model_name]:\n",
    "            layer_info_str += str(d) + '_'\n",
    "\n",
    "        if 'text' in model_name:\n",
    "            tokenizer, voc = get_tokenizer_and_vocab(X_train, y_train)\n",
    "            \n",
    "            model = DefineModel(model_name, vocab_size=len(voc))\n",
    "        else:\n",
    "            model = DefineModel(model_name, dim_per_layer_per_MLP[model_name], activation_per_layer_per_MLP[model_name])\n",
    "        print(model_name)\n",
    "        # print('num params', count_parameters(model))\n",
    "\n",
    "        # Train the model\n",
    "        best_model_name = training(model, loader_train, loader_val, model_name, dir_name,\n",
    "                                   learning_rate, epochs, data_name, exp_id, layer_info_str, use_class_weighting, device, y_train, modality=modality)\n",
    "\n",
    "        # Evaluate the model\n",
    "        total_acc, total_f1, total_auc_roc, y_preds_test_flat, y_preds_train_flat = \\\n",
    "            EvaluateNetwork(best_model_name, model_name, dim_per_layer_per_MLP[model_name],\n",
    "                            activation_per_layer_per_MLP[model_name], loader_train, loader_val, use_class_weighting, device, modality=modality)\n",
    "\n",
    "        # Save model info\n",
    "        SaveModelInfo(model_name, data_name, model, exp_id, epochs, learning_rate,\n",
    "                      X_train, y_train, X_val, y_val, X_test, y_test, total_f1, total_acc, total_auc_roc,\n",
    "                      loader_val, y_preds_test_flat, loader_train, y_preds_train_flat, layer_info_str,\n",
    "                      use_class_weighting, dim_per_layer_per_MLP[model_name], activation_per_layer_per_MLP[model_name], modality=modality)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T07:50:49.462378Z",
     "start_time": "2024-06-13T07:44:59.451373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "151234"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the number of trainable parameters in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model whose parameters are to be counted.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:40:25.427216Z",
     "start_time": "2024-06-12T06:40:25.423705Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.5113e-03, 9.9849e-01],\n        [5.3622e-06, 9.9999e-01],\n        [1.4531e-03, 9.9855e-01]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor([\n",
    "    [4, 22, 15, 0, 0],  # First sentence, with two padding tokens\n",
    "    [14, 65, 30, 21, 3],  # Second sentence, no padding\n",
    "    [73, 12, 0, 0, 0]    # Third sentence, with three padding tokens\n",
    "], dtype=torch.long)\n",
    "model(input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T22:16:50.709928Z",
     "start_time": "2024-06-11T22:16:50.657046Z"
    }
   },
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "ref = torch.tensor(\n",
    "    [[0, 0, 0, 0, 0]], dtype=torch.long\n",
    ")\n",
    "\n",
    "x = input_ids[0].unsqueeze(0)\n",
    "ref = ref\n",
    "\n",
    "base_class = 1\n",
    "model = model.to('cpu')\n",
    "lig = LayerIntegratedGradients(model, model.embeddings.embedding)\n",
    "\n",
    "attributions_ig, delta = lig.attribute(\n",
    "    x.float(), ref, n_steps=500, return_convergence_delta=True, target=base_class\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:57.307335Z",
     "start_time": "2024-06-11T23:24:53.829089Z"
    }
   },
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.9779,  0.0447, -0.2044,  0.0000,  0.0000], dtype=torch.float64)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "attributions = attributions / torch.norm(attributions)\n",
    "attributions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:57.345572Z",
     "start_time": "2024-06-11T23:24:57.311879Z"
    }
   },
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 4, 22, 15,  0,  0]])"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T22:39:51.192410Z",
     "start_time": "2024-06-11T22:39:51.169998Z"
    }
   },
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "412770"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:42:24.317418Z",
     "start_time": "2024-06-11T06:42:24.297088Z"
    }
   },
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T06:42:24.350887Z",
     "start_time": "2024-06-11T06:42:24.332802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasets:\n",
    "# LR, ANN_S, ANN_M, ANN_L Compas\n",
    "# LR, ANN_S, ANN_M, ANN_L german\n",
    "# LR, ANN_S, ANN_M, ANN_L heloc\n",
    "# LR, ANN_S, ANN_M, ANN_L adult income\n",
    "# synthetic dataset\n",
    "# LR, ANN_S, ANN_M, ANN_L give me some credit (credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T06:42:24.388431Z",
     "start_time": "2024-06-11T06:42:24.352027Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/ClassWeighted/TEXT_ANN/'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m parsed_values \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Iterate over the text files in the folder\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder_path\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m filename\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.txt\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# Process only text files\u001B[39;00m\n\u001B[1;32m     20\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder_path, filename), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './models/ClassWeighted/TEXT_ANN/'"
     ]
    }
   ],
   "source": [
    "# gather all the scores and save them\n",
    "import os\n",
    "import csv\n",
    "\n",
    "for model_name in model_names:\n",
    "    folder_path = './models/ClassWeighted/' + model_name.upper() +'/' # Replace with the actual folder path containing the text files\n",
    "    output_file = 'parsed_values.csv'  # Replace with the desired output file name\n",
    "        \n",
    "    # Define the fieldnames for the CSV file\n",
    "    fieldnames = ['data_name', 'F1-score', 'Accuracy', 'AUC-ROC', 'Proportion of ones in test set',\n",
    "                  'Proportion of ones predicted in test set', 'Proportion of ones in train set',\n",
    "                  'Proportion of ones predicted in train set']\n",
    "    \n",
    "    # Create a list to store the parsed values\n",
    "    parsed_values = []\n",
    "    \n",
    "    # Iterate over the text files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):  # Process only text files\n",
    "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "                content = file.read()\n",
    "    \n",
    "                # Extract the required values using string manipulation or regular expressions\n",
    "                data_name = content.split('data_name:')[1].split('\\n')[0]\n",
    "                f1_score = content.split('F1-score: ')[1].split(' |')[0]\n",
    "                accuracy = content.split('Accuracy: ')[1].split(' |')[0]\n",
    "                auc_roc = content.split('AUC-ROC: ')[1].split('\\n')[0]\n",
    "                ones_test = content.split('Proportion of ones in test set: ')[1].split('\\n')[0]\n",
    "                ones_predicted_test = content.split('Proportion of ones predicted in test set: ')[1].split('\\n')[0]\n",
    "                ones_train = content.split('Proportion of ones in train set: ')[1].split('\\n')[0]\n",
    "                ones_predicted_train = content.split('Proportion of ones predicted in train set: ')[1].split('\\n')[0]\n",
    "    \n",
    "                # Append the parsed values to the list\n",
    "                parsed_values.append({\n",
    "                    'data_name': data_name,\n",
    "                    'F1-score': f1_score,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'AUC-ROC': auc_roc,\n",
    "                    'Proportion of ones in test set': ones_test,\n",
    "                    'Proportion of ones predicted in test set': ones_predicted_test,\n",
    "                    'Proportion of ones in train set': ones_train,\n",
    "                    'Proportion of ones predicted in train set': ones_predicted_train\n",
    "                })\n",
    "    \n",
    "            # sort the rows by data_name\n",
    "            parsed_values = sorted(parsed_values, key=lambda k: k['data_name'])\n",
    "            # Write the parsed values to the CSV file\n",
    "            with open(folder_path+output_file, 'w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(parsed_values)\n",
    "            \n",
    "            print(f\"Parsed values saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T06:42:24.389533Z",
     "start_time": "2024-06-11T06:42:24.389472Z"
    }
   },
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm_explainer",
   "language": "python",
   "display_name": "LLM_Explainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
