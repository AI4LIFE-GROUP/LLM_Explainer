{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T07:51:13.615186Z",
     "start_time": "2024-03-29T07:51:13.608733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train a set of models on different OpenXAI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:55.206294Z",
     "start_time": "2024-03-28T22:25:55.203312Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# go up a directory\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:57.946044Z",
     "start_time": "2024-03-28T22:25:56.477839Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import datetime\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "# Data loaders\n",
    "from openxai.dataloader import return_loaders\n",
    "from openxai.ML_Models.LR.model import LogisticRegression\n",
    "import openxai.ML_Models.ANN.MLP as model_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.127480Z",
     "start_time": "2024-03-28T22:25:58.121107Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11085b8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('default')\n",
    "SEED = 3407\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.402042Z",
     "start_time": "2024-03-28T22:25:58.398909Z"
    }
   },
   "outputs": [],
   "source": [
    "def getExperimentID():\n",
    "    date_info = datetime.datetime.now()\n",
    "    testID    = '%d%02d%02d_%02d%02d' % (date_info.year, date_info.month, date_info.day, date_info.hour, date_info.minute)\n",
    "    return testID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.584195Z",
     "start_time": "2024-03-28T22:25:58.575010Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model, loader_train, loader_test, ml_model, dir_name, learning_rate, epochs, dataset, exp_id, layer_info_str, use_class_weighting, modality='tabular'):\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = 'mps'\n",
    "    loaders = {'train': loader_train, 'test': loader_test}\n",
    "\n",
    "    if use_class_weighting: \n",
    "        # Compute class weights\n",
    "        class_counts  = torch.bincount(torch.tensor(loader_train.dataset.targets.to_numpy().astype(np.compat.long)))\n",
    "        total_samples = len(loader_train.dataset)\n",
    "        class_weights = total_samples / (class_counts.float())\n",
    "        class_weights = class_weights.to(device)\n",
    "\n",
    "    # model collector\n",
    "    best_auc_roc = 0\n",
    "\n",
    "    model  = model.to(device)\n",
    "\n",
    "    # declaring optimizer and loss\n",
    "    if use_class_weighting:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # training\n",
    "    for e in range(epochs):\n",
    "        print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluation mode\n",
    "\n",
    "            all_preds  = []\n",
    "            all_labels = []\n",
    "            for i, input_tuple in enumerate(loaders[phase]):\n",
    "                if modality == 'tabular':\n",
    "                    inputs = input_tuple[0].float()\n",
    "                    labels = input_tuple[1]\n",
    "                elif modality == 'text':\n",
    "                    inputs = input_tuple[0]\n",
    "                    # text   = input_tuple[1]  # don't need for training!\n",
    "                    labels = input_tuple[2]\n",
    "                    \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).type(torch.long)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    y_pred = model(inputs)\n",
    "                    loss   = criterion(y_pred.float(), labels.long())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                all_preds.append(y_pred)\n",
    "                all_labels.append(labels)\n",
    "            # statistics\n",
    "            preds = torch.cat(all_preds, dim=0)\n",
    "            labels = torch.cat(all_labels, dim=0).cpu()\n",
    "            \n",
    "            raw_preds      = preds.data[:, 1]\n",
    "            raw_preds_np   = raw_preds.view(-1).cpu().numpy()\n",
    "            class_preds    = raw_preds >= 0.5\n",
    "            class_preds_np = class_preds.view(-1).long().cpu().numpy()\n",
    "            \n",
    "            epoch_loss     = loss.item()\n",
    "            epoch_acc      = accuracy_score(labels.numpy(), class_preds_np)\n",
    "            epoch_f1       = f1_score(labels.numpy(), class_preds_np)\n",
    "            epoch_auc_roc  = roc_auc_score(labels.numpy(), raw_preds_np)\n",
    "\n",
    "            print(f'{phase}: Loss: {epoch_loss:.4f} | F1-score: {epoch_f1:.4f} | AUC ROC: {epoch_auc_roc:.4f} | Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_auc_roc > best_auc_roc:\n",
    "                best_auc_roc = epoch_auc_roc\n",
    "                best_model_name = '{}_{}_{}_{}_{}_auc_roc_{:.2f}.pt'.format(exp_id, layer_info_str, dataset, ml_model, learning_rate, best_auc_roc)\n",
    "                print('new best model', e)\n",
    "                if use_class_weighting:\n",
    "                    fpth = 'models/ClassWeighted/' + dir_name\n",
    "                else:\n",
    "                    fpth = 'models/NotClassWeighted/' + dir_name\n",
    "                if not os.path.isdir(fpth):  # If folder doesn't exist, then create it.\n",
    "                    os.makedirs(fpth)\n",
    "                output_file_path = fpth + '/' + best_model_name\n",
    "                torch.save(model.state_dict(), output_file_path)\n",
    "\n",
    "    return best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.747671Z",
     "start_time": "2024-03-28T22:25:58.743310Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotROC(output_dir, labels, preds, addtlNameInfo=''):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)\n",
    "    auc         = roc_auc_score(labels, preds)\n",
    "    plt.figure(dpi=100)\n",
    "    plt.plot([0,1],[0,1], color='k')\n",
    "    plt.plot([0,0],[0,1], color='k', linestyle='dashed')\n",
    "    plt.plot([0,1],[1,1], color='k', linestyle='dashed')\n",
    "    plt.plot([1,1],[1,0], color='k', linestyle='dashed')\n",
    "    plt.plot([1,0],[0,0], color='k', linestyle='dashed')\n",
    "    plt.plot(fpr, tpr, color='b', label=\"AUC: \" + str(round(auc,2)))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('ROC Curve - ' + addtlNameInfo)\n",
    "    plt.savefig(output_dir + 'ROC_'+addtlNameInfo+'.png', bbox_inches='tight')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:46.231966Z",
     "start_time": "2024-03-28T23:00:46.223416Z"
    }
   },
   "outputs": [],
   "source": [
    "def EvaluateNetwork(best_model_name, model_name, dim_per_layer, activation_per_layer, loader_train, loader_val, \n",
    "                    use_class_weighting, modality='tabular'):\n",
    "    print('Evaluating', best_model_name)\n",
    "\n",
    "    model = DefineModel(model_name, dim_per_layer, activation_per_layer)\n",
    "\n",
    "    if use_class_weighting:\n",
    "        fpth = 'models/ClassWeighted/'\n",
    "    else:\n",
    "        fpth = 'models/NotClassWeighted/'\n",
    "        \n",
    "    model.load_state_dict(torch.load(fpth + model_name.upper() + '/' + best_model_name))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = 'mps'\n",
    "    model  = model.to(device)\n",
    "    model.eval()   # Set model to evaluation mode\n",
    "\n",
    "    all_preds  = []\n",
    "    all_labels = []\n",
    "    for i, input_tuple in enumerate(loader_val):\n",
    "        if modality == 'tabular':\n",
    "            inputs = input_tuple[0].float()\n",
    "            labels = input_tuple[1]\n",
    "        elif modality == 'text':\n",
    "            inputs = input_tuple[0]\n",
    "            # text   = input_tuple[1]  # don't need for evaluation!\n",
    "            labels = input_tuple[2]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).type(torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            y_pred = model(inputs.float())\n",
    "        all_preds.append(y_pred)\n",
    "        all_labels.append(labels)\n",
    "    # statistics\n",
    "    preds  = torch.cat(all_preds, dim=0)\n",
    "    labels = torch.cat(all_labels, dim=0).cpu()\n",
    "    \n",
    "    raw_preds      = preds.data[:, 1]\n",
    "    raw_preds_np   = raw_preds.view(-1).cpu().numpy()\n",
    "    class_preds    = raw_preds >= 0.5\n",
    "    class_preds_np = class_preds.view(-1).long().cpu().numpy()\n",
    "    \n",
    "    total_acc     = accuracy_score(labels.numpy(), class_preds_np)\n",
    "    total_f1      = f1_score(labels.numpy(), class_preds_np)\n",
    "    total_auc_roc = roc_auc_score(labels.numpy(), raw_preds_np)\n",
    "    \n",
    "    y_preds_test = []\n",
    "    for i, input_tuple in enumerate(loader_val):\n",
    "        inputs = input_tuple[0].float().to(device)\n",
    "        y_pred = model(inputs).data\n",
    "        y_pred = y_pred[:, 1]# >= 0.5  # True if bigger than 0.5\n",
    "        y_preds_test.append(y_pred.cpu())  # convert true and false to 1 and 0, respectively.\n",
    "    y_preds_test_flat = np.array([item for sublist in y_preds_test for item in sublist])\n",
    "\n",
    "    y_preds_train = []\n",
    "    for i, input_tuple in enumerate(loader_train):\n",
    "        inputs = input_tuple[0].float().to(device)\n",
    "        y_pred = model(inputs).data\n",
    "        y_pred = y_pred[:, 1]# >= 0.5  # True if bigger than 0.5\n",
    "        y_preds_train.append(y_pred.cpu())  # convert true and false to 1 and 0, respectively.\n",
    "    y_preds_train_flat = np.array([item for sublist in y_preds_train for item in sublist])\n",
    "\n",
    "    return total_acc, total_f1, total_auc_roc, y_preds_test_flat, y_preds_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:46.848682Z",
     "start_time": "2024-03-28T23:00:46.845386Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotConfusionMatrix(labels, preds, num_of_classes, output_dir, addtlNameInfo=''):\n",
    "    preds      = preds >= 0.5\n",
    "    conf_mat   = confusion_matrix(labels, preds, normalize=None)\n",
    "    pathToSave = os.path.join(output_dir + 'ConfusionMatrix_'+addtlNameInfo+'.png')\n",
    "    df_cm      = pd.DataFrame(conf_mat, range(num_of_classes), range(num_of_classes))\n",
    "    \n",
    "    plt.figure(figsize=(12, 9), dpi=100)\n",
    "    plt.title('Confusion Matrix - ' + addtlNameInfo)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    # sn.set(font_scale=2) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 18}, cmap=\"Blues\", fmt='d') # font size\n",
    "    plt.savefig(pathToSave, format = 'png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:47.044359Z",
     "start_time": "2024-03-28T23:00:47.036834Z"
    }
   },
   "outputs": [],
   "source": [
    "def SaveModelInfo(model_name, data_name, model, exp_id, epochs, learning_rate, X_train, y_train, X_val, y_val, X_test, y_test, total_f1, total_acc, total_auc_roc, loader_val, y_preds_test_flat, loader_train, y_preds_train_flat, layer_info_str, use_class_weighting, dim_per_layer='', activation_per_layer=''):\n",
    "    # Save to .txt\n",
    "    if use_class_weighting:\n",
    "        output_dir = 'models/ClassWeighted/' + model_name.upper() + '/'\n",
    "    else:\n",
    "        output_dir = 'models/NotClassWeighted/' + model_name.upper() + '/'\n",
    "    file_name  =  exp_id + '_' + layer_info_str + model_name.upper() + '_' + data_name + '_summary'\n",
    "\n",
    "    fpth = os.path.join(output_dir, file_name+'.txt')\n",
    "    paramTxt = open(fpth, 'w')\n",
    "\n",
    "    paramTxt.write(file_name)\n",
    "    paramTxt.write('Hyperparameters')\n",
    "    paramTxt.write('exp_id:\\t' + exp_id + '\\n')\n",
    "    paramTxt.write('data_name:\\t' + data_name + '\\n')\n",
    "    paramTxt.write('model_name:\\t' + model_name + '\\n')\n",
    "    paramTxt.write('epochs:\\t\\t' + str(epochs) + '\\n')\n",
    "    paramTxt.write('learning_rate:\\t' + str(learning_rate) + '\\n\\n')\n",
    "    paramTxt.write('X_train.shape:\\t' + str(X_train.shape) + '\\n')\n",
    "    paramTxt.write('y_train.shape:\\t' + str(y_train.shape) + '\\n\\n')\n",
    "    paramTxt.write('X_val.shape:\\t' + str(X_val.shape) + '\\n')\n",
    "    paramTxt.write('y_val.shape:\\t' + str(y_val.shape) + '\\n\\n')\n",
    "    paramTxt.write('X_test.shape:\\t' + str(X_test.shape) + '\\n')\n",
    "    paramTxt.write('y_test.shape:\\t' + str(y_test.shape) + '\\n\\n')\n",
    "    paramTxt.write('dim_per_layer:\\t' + str(dim_per_layer) + '\\n')\n",
    "    if 'ann' in model_name:\n",
    "        paramTxt.write('activation_per_layer:\\t' + str(activation_per_layer) + '\\n')\n",
    "    paramTxt.write('\\nF1-score: '+ str(round(total_f1,4)) +' | Accuracy: ' + str(round(total_acc, 4)) + ' | AUC-ROC: ' + str(round(total_auc_roc, 4)) + '\\n\\n')\n",
    "    paramTxt.write(\"Proportion of ones in test set: \" + str(round(np.mean(loader_val.dataset.targets),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones predicted in test set: \" + str(round(np.mean(y_preds_test_flat),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones in train set: \" + str(round(np.mean(loader_train.dataset.targets),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones predicted in train set: \" + str(round(np.mean(y_preds_train_flat),3)) + '\\n')\n",
    "    paramTxt.write('\\nArchitecture:\\n')\n",
    "    paramTxt.write(str(model.__dict__['_modules']))\n",
    "    paramTxt.close()\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    PlotROC(fpth, y_val, y_preds_test_flat, addtlNameInfo = model_name.upper() + '_' + data_name)\n",
    "    \n",
    "    PlotConfusionMatrix(y_val, y_preds_test_flat, 2, output_dir, addtlNameInfo = model_name.upper() + '_' + data_name)\n",
    "\n",
    "    print(f'F1-score: {total_f1:.4f} | Accuracy: {total_acc:.4f} | AUC-ROC: {total_auc_roc:.4f}')\n",
    "    print(\"Proportion of ones in test set:\", round(np.mean(loader_val.dataset.targets),3))\n",
    "    print(\"Proportion of ones predicted in test set: \", round(np.mean(y_preds_test_flat),3))\n",
    "    print(\"Proportion of ones in train set:\", round(np.mean(loader_train.dataset.targets),3))\n",
    "    print(\"Proportion of ones predicted in train set: \", round(np.mean(y_preds_train_flat),3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:47.206902Z",
     "start_time": "2024-03-28T23:00:47.204455Z"
    }
   },
   "outputs": [],
   "source": [
    "def DefineModel(model_name, dim_per_layer=None, activation_per_layer=None):\n",
    "    input_size = loader_train.dataset.get_number_of_features()\n",
    "\n",
    "    if 'ann' in model_name:\n",
    "        dim_per_layer = [input_size] + dim_per_layer\n",
    "        model         = model_MLP.MLP(dim_per_layer, activation_per_layer)\n",
    "    elif model_name == 'lr':\n",
    "        dim_per_layer = [input_size] + dim_per_layer\n",
    "        model         = LogisticRegression(dim_per_layer[0], dim_per_layer[1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T01:38:35.640880Z",
     "start_time": "2024-03-29T01:38:35.629600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#get number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T01:39:23.942521Z",
     "start_time": "2024-03-29T01:39:23.890086Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: lr on blood\n",
      "lr\n",
      "num params 10\n",
      "Epoch 0/99\n",
      "----------\n",
      "train: Loss: 0.6983 | F1-score: 0.2675 | AUC ROC: 0.4298 | Accuracy: 0.4969\n",
      "test: Loss: 0.7045 | F1-score: 0.2069 | AUC ROC: 0.3934 | Accuracy: 0.4202\n",
      "new best model 0\n",
      "Epoch 1/99\n",
      "----------\n",
      "train: Loss: 0.6997 | F1-score: 0.2708 | AUC ROC: 0.4311 | Accuracy: 0.5052\n",
      "test: Loss: 0.7043 | F1-score: 0.2069 | AUC ROC: 0.3917 | Accuracy: 0.4202\n",
      "Epoch 2/99\n",
      "----------\n",
      "train: Loss: 0.7028 | F1-score: 0.2699 | AUC ROC: 0.4348 | Accuracy: 0.5031\n",
      "test: Loss: 0.7042 | F1-score: 0.2069 | AUC ROC: 0.3917 | Accuracy: 0.4202\n",
      "Epoch 3/99\n",
      "----------\n",
      "train: Loss: 0.7026 | F1-score: 0.2699 | AUC ROC: 0.4366 | Accuracy: 0.5031\n",
      "test: Loss: 0.7041 | F1-score: 0.2069 | AUC ROC: 0.3921 | Accuracy: 0.4202\n",
      "Epoch 4/99\n",
      "----------\n",
      "train: Loss: 0.6983 | F1-score: 0.2699 | AUC ROC: 0.4379 | Accuracy: 0.5031\n",
      "test: Loss: 0.7039 | F1-score: 0.2118 | AUC ROC: 0.3930 | Accuracy: 0.4370\n",
      "Epoch 5/99\n",
      "----------\n",
      "train: Loss: 0.6921 | F1-score: 0.2646 | AUC ROC: 0.4389 | Accuracy: 0.5010\n",
      "test: Loss: 0.7038 | F1-score: 0.2169 | AUC ROC: 0.3934 | Accuracy: 0.4538\n",
      "Epoch 6/99\n",
      "----------\n",
      "train: Loss: 0.6995 | F1-score: 0.2609 | AUC ROC: 0.4401 | Accuracy: 0.5031\n",
      "test: Loss: 0.7037 | F1-score: 0.2169 | AUC ROC: 0.3947 | Accuracy: 0.4538\n",
      "new best model 6\n",
      "Epoch 7/99\n",
      "----------\n",
      "train: Loss: 0.6991 | F1-score: 0.2609 | AUC ROC: 0.4411 | Accuracy: 0.5031\n",
      "test: Loss: 0.7035 | F1-score: 0.2169 | AUC ROC: 0.3961 | Accuracy: 0.4538\n",
      "new best model 7\n",
      "Epoch 8/99\n",
      "----------\n",
      "train: Loss: 0.7010 | F1-score: 0.2609 | AUC ROC: 0.4420 | Accuracy: 0.5031\n",
      "test: Loss: 0.7034 | F1-score: 0.2169 | AUC ROC: 0.3956 | Accuracy: 0.4538\n",
      "Epoch 9/99\n",
      "----------\n",
      "train: Loss: 0.6966 | F1-score: 0.2609 | AUC ROC: 0.4433 | Accuracy: 0.5031\n",
      "test: Loss: 0.7033 | F1-score: 0.2169 | AUC ROC: 0.3969 | Accuracy: 0.4538\n",
      "new best model 9\n",
      "Epoch 10/99\n",
      "----------\n",
      "train: Loss: 0.7044 | F1-score: 0.2625 | AUC ROC: 0.4446 | Accuracy: 0.5073\n",
      "test: Loss: 0.7031 | F1-score: 0.2195 | AUC ROC: 0.3978 | Accuracy: 0.4622\n",
      "new best model 10\n",
      "Epoch 11/99\n",
      "----------\n",
      "train: Loss: 0.6997 | F1-score: 0.2679 | AUC ROC: 0.4461 | Accuracy: 0.5094\n",
      "test: Loss: 0.7030 | F1-score: 0.2195 | AUC ROC: 0.3991 | Accuracy: 0.4622\n",
      "new best model 11\n",
      "Epoch 12/99\n",
      "----------\n",
      "train: Loss: 0.6985 | F1-score: 0.2733 | AUC ROC: 0.4474 | Accuracy: 0.5115\n",
      "test: Loss: 0.7029 | F1-score: 0.2195 | AUC ROC: 0.4009 | Accuracy: 0.4622\n",
      "new best model 12\n",
      "Epoch 13/99\n",
      "----------\n",
      "train: Loss: 0.7024 | F1-score: 0.2741 | AUC ROC: 0.4481 | Accuracy: 0.5136\n",
      "test: Loss: 0.7027 | F1-score: 0.2195 | AUC ROC: 0.4013 | Accuracy: 0.4622\n",
      "new best model 13\n",
      "Epoch 14/99\n",
      "----------\n",
      "train: Loss: 0.6988 | F1-score: 0.2741 | AUC ROC: 0.4489 | Accuracy: 0.5136\n",
      "test: Loss: 0.7026 | F1-score: 0.2195 | AUC ROC: 0.4018 | Accuracy: 0.4622\n",
      "new best model 14\n",
      "Epoch 15/99\n",
      "----------\n",
      "train: Loss: 0.6970 | F1-score: 0.2741 | AUC ROC: 0.4503 | Accuracy: 0.5136\n",
      "test: Loss: 0.7024 | F1-score: 0.1975 | AUC ROC: 0.4026 | Accuracy: 0.4538\n",
      "new best model 15\n",
      "Epoch 16/99\n",
      "----------\n",
      "train: Loss: 0.6938 | F1-score: 0.2741 | AUC ROC: 0.4509 | Accuracy: 0.5136\n",
      "test: Loss: 0.7023 | F1-score: 0.1975 | AUC ROC: 0.4057 | Accuracy: 0.4538\n",
      "new best model 16\n",
      "Epoch 17/99\n",
      "----------\n",
      "train: Loss: 0.6959 | F1-score: 0.2741 | AUC ROC: 0.4525 | Accuracy: 0.5136\n",
      "test: Loss: 0.7022 | F1-score: 0.1975 | AUC ROC: 0.4061 | Accuracy: 0.4538\n",
      "new best model 17\n",
      "Epoch 18/99\n",
      "----------\n",
      "train: Loss: 0.6941 | F1-score: 0.2750 | AUC ROC: 0.4532 | Accuracy: 0.5157\n",
      "test: Loss: 0.7020 | F1-score: 0.1975 | AUC ROC: 0.4079 | Accuracy: 0.4538\n",
      "new best model 18\n",
      "Epoch 19/99\n",
      "----------\n",
      "train: Loss: 0.6970 | F1-score: 0.2696 | AUC ROC: 0.4542 | Accuracy: 0.5136\n",
      "test: Loss: 0.7019 | F1-score: 0.1975 | AUC ROC: 0.4092 | Accuracy: 0.4538\n",
      "new best model 19\n",
      "Epoch 20/99\n",
      "----------\n",
      "train: Loss: 0.6996 | F1-score: 0.2713 | AUC ROC: 0.4554 | Accuracy: 0.5177\n",
      "test: Loss: 0.7018 | F1-score: 0.1975 | AUC ROC: 0.4105 | Accuracy: 0.4538\n",
      "new best model 20\n",
      "Epoch 21/99\n",
      "----------\n",
      "train: Loss: 0.6961 | F1-score: 0.2767 | AUC ROC: 0.4582 | Accuracy: 0.5198\n",
      "test: Loss: 0.7016 | F1-score: 0.1975 | AUC ROC: 0.4127 | Accuracy: 0.4538\n",
      "new best model 21\n",
      "Epoch 22/99\n",
      "----------\n",
      "train: Loss: 0.6977 | F1-score: 0.2767 | AUC ROC: 0.4601 | Accuracy: 0.5198\n",
      "test: Loss: 0.7015 | F1-score: 0.1975 | AUC ROC: 0.4132 | Accuracy: 0.4538\n",
      "new best model 22\n",
      "Epoch 23/99\n",
      "----------\n",
      "train: Loss: 0.6986 | F1-score: 0.2767 | AUC ROC: 0.4605 | Accuracy: 0.5198\n",
      "test: Loss: 0.7014 | F1-score: 0.1975 | AUC ROC: 0.4145 | Accuracy: 0.4538\n",
      "new best model 23\n",
      "Epoch 24/99\n",
      "----------\n",
      "train: Loss: 0.6928 | F1-score: 0.2767 | AUC ROC: 0.4620 | Accuracy: 0.5198\n",
      "test: Loss: 0.7012 | F1-score: 0.2000 | AUC ROC: 0.4145 | Accuracy: 0.4622\n",
      "Epoch 25/99\n",
      "----------\n",
      "train: Loss: 0.6948 | F1-score: 0.2767 | AUC ROC: 0.4622 | Accuracy: 0.5198\n",
      "test: Loss: 0.7011 | F1-score: 0.2000 | AUC ROC: 0.4154 | Accuracy: 0.4622\n",
      "new best model 25\n",
      "Epoch 26/99\n",
      "----------\n",
      "train: Loss: 0.6998 | F1-score: 0.2767 | AUC ROC: 0.4635 | Accuracy: 0.5198\n",
      "test: Loss: 0.7010 | F1-score: 0.2025 | AUC ROC: 0.4167 | Accuracy: 0.4706\n",
      "new best model 26\n",
      "Epoch 27/99\n",
      "----------\n",
      "train: Loss: 0.6997 | F1-score: 0.2767 | AUC ROC: 0.4658 | Accuracy: 0.5198\n",
      "test: Loss: 0.7008 | F1-score: 0.2025 | AUC ROC: 0.4171 | Accuracy: 0.4706\n",
      "new best model 27\n",
      "Epoch 28/99\n",
      "----------\n",
      "train: Loss: 0.6957 | F1-score: 0.2767 | AUC ROC: 0.4679 | Accuracy: 0.5198\n",
      "test: Loss: 0.7007 | F1-score: 0.2025 | AUC ROC: 0.4184 | Accuracy: 0.4706\n",
      "new best model 28\n",
      "Epoch 29/99\n",
      "----------\n",
      "train: Loss: 0.6983 | F1-score: 0.2767 | AUC ROC: 0.4695 | Accuracy: 0.5198\n",
      "test: Loss: 0.7006 | F1-score: 0.2025 | AUC ROC: 0.4180 | Accuracy: 0.4706\n",
      "Epoch 30/99\n",
      "----------\n",
      "train: Loss: 0.6977 | F1-score: 0.2776 | AUC ROC: 0.4701 | Accuracy: 0.5219\n",
      "test: Loss: 0.7004 | F1-score: 0.2250 | AUC ROC: 0.4206 | Accuracy: 0.4790\n",
      "new best model 30\n",
      "Epoch 31/99\n",
      "----------\n",
      "train: Loss: 0.6973 | F1-score: 0.2785 | AUC ROC: 0.4724 | Accuracy: 0.5240\n",
      "test: Loss: 0.7003 | F1-score: 0.2250 | AUC ROC: 0.4197 | Accuracy: 0.4790\n",
      "Epoch 32/99\n",
      "----------\n",
      "train: Loss: 0.6975 | F1-score: 0.2803 | AUC ROC: 0.4737 | Accuracy: 0.5282\n",
      "test: Loss: 0.7002 | F1-score: 0.2250 | AUC ROC: 0.4211 | Accuracy: 0.4790\n",
      "new best model 32\n",
      "Epoch 33/99\n",
      "----------\n",
      "train: Loss: 0.6979 | F1-score: 0.2821 | AUC ROC: 0.4748 | Accuracy: 0.5324\n",
      "test: Loss: 0.7000 | F1-score: 0.2250 | AUC ROC: 0.4211 | Accuracy: 0.4790\n",
      "Epoch 34/99\n",
      "----------\n",
      "train: Loss: 0.6948 | F1-score: 0.2821 | AUC ROC: 0.4768 | Accuracy: 0.5324\n",
      "test: Loss: 0.6999 | F1-score: 0.2250 | AUC ROC: 0.4224 | Accuracy: 0.4790\n",
      "new best model 34\n",
      "Epoch 35/99\n",
      "----------\n",
      "train: Loss: 0.6978 | F1-score: 0.2894 | AUC ROC: 0.4773 | Accuracy: 0.5386\n",
      "test: Loss: 0.6998 | F1-score: 0.2278 | AUC ROC: 0.4232 | Accuracy: 0.4874\n",
      "new best model 35\n",
      "Epoch 36/99\n",
      "----------\n",
      "train: Loss: 0.6965 | F1-score: 0.2913 | AUC ROC: 0.4785 | Accuracy: 0.5428\n",
      "test: Loss: 0.6996 | F1-score: 0.2278 | AUC ROC: 0.4254 | Accuracy: 0.4874\n",
      "new best model 36\n",
      "Epoch 37/99\n",
      "----------\n",
      "train: Loss: 0.6943 | F1-score: 0.2922 | AUC ROC: 0.4800 | Accuracy: 0.5449\n",
      "test: Loss: 0.6995 | F1-score: 0.2278 | AUC ROC: 0.4263 | Accuracy: 0.4874\n",
      "new best model 37\n",
      "Epoch 38/99\n",
      "----------\n",
      "train: Loss: 0.6922 | F1-score: 0.2866 | AUC ROC: 0.4813 | Accuracy: 0.5428\n",
      "test: Loss: 0.6993 | F1-score: 0.2278 | AUC ROC: 0.4268 | Accuracy: 0.4874\n",
      "new best model 38\n",
      "Epoch 39/99\n",
      "----------\n",
      "train: Loss: 0.6943 | F1-score: 0.2866 | AUC ROC: 0.4819 | Accuracy: 0.5428\n",
      "test: Loss: 0.6992 | F1-score: 0.2278 | AUC ROC: 0.4281 | Accuracy: 0.4874\n",
      "new best model 39\n",
      "Epoch 40/99\n",
      "----------\n",
      "train: Loss: 0.6917 | F1-score: 0.2876 | AUC ROC: 0.4837 | Accuracy: 0.5449\n",
      "test: Loss: 0.6991 | F1-score: 0.2278 | AUC ROC: 0.4303 | Accuracy: 0.4874\n",
      "new best model 40\n",
      "Epoch 41/99\n",
      "----------\n",
      "train: Loss: 0.6958 | F1-score: 0.2876 | AUC ROC: 0.4853 | Accuracy: 0.5449\n",
      "test: Loss: 0.6989 | F1-score: 0.2278 | AUC ROC: 0.4298 | Accuracy: 0.4874\n",
      "Epoch 42/99\n",
      "----------\n",
      "train: Loss: 0.6977 | F1-score: 0.2885 | AUC ROC: 0.4878 | Accuracy: 0.5470\n",
      "test: Loss: 0.6988 | F1-score: 0.2278 | AUC ROC: 0.4298 | Accuracy: 0.4874\n",
      "Epoch 43/99\n",
      "----------\n",
      "train: Loss: 0.6912 | F1-score: 0.2904 | AUC ROC: 0.4892 | Accuracy: 0.5511\n",
      "test: Loss: 0.6987 | F1-score: 0.2308 | AUC ROC: 0.4325 | Accuracy: 0.4958\n",
      "new best model 43\n",
      "Epoch 44/99\n",
      "----------\n",
      "train: Loss: 0.6992 | F1-score: 0.2904 | AUC ROC: 0.4910 | Accuracy: 0.5511\n",
      "test: Loss: 0.6986 | F1-score: 0.2308 | AUC ROC: 0.4316 | Accuracy: 0.4958\n",
      "Epoch 45/99\n",
      "----------\n",
      "train: Loss: 0.6930 | F1-score: 0.2914 | AUC ROC: 0.4920 | Accuracy: 0.5532\n",
      "test: Loss: 0.6984 | F1-score: 0.2308 | AUC ROC: 0.4322 | Accuracy: 0.4958\n",
      "Epoch 46/99\n",
      "----------\n",
      "train: Loss: 0.6954 | F1-score: 0.2914 | AUC ROC: 0.4929 | Accuracy: 0.5532\n",
      "test: Loss: 0.6983 | F1-score: 0.2338 | AUC ROC: 0.4342 | Accuracy: 0.5042\n",
      "new best model 46\n",
      "Epoch 47/99\n",
      "----------\n",
      "train: Loss: 0.6935 | F1-score: 0.2914 | AUC ROC: 0.4936 | Accuracy: 0.5532\n",
      "test: Loss: 0.6982 | F1-score: 0.2338 | AUC ROC: 0.4346 | Accuracy: 0.5042\n",
      "new best model 47\n",
      "Epoch 48/99\n",
      "----------\n",
      "train: Loss: 0.6918 | F1-score: 0.2914 | AUC ROC: 0.4951 | Accuracy: 0.5532\n",
      "test: Loss: 0.6981 | F1-score: 0.2338 | AUC ROC: 0.4368 | Accuracy: 0.5042\n",
      "new best model 48\n",
      "Epoch 49/99\n",
      "----------\n",
      "train: Loss: 0.6961 | F1-score: 0.2914 | AUC ROC: 0.4960 | Accuracy: 0.5532\n",
      "test: Loss: 0.6979 | F1-score: 0.2338 | AUC ROC: 0.4377 | Accuracy: 0.5042\n",
      "new best model 49\n",
      "Epoch 50/99\n",
      "----------\n",
      "train: Loss: 0.6945 | F1-score: 0.2914 | AUC ROC: 0.4965 | Accuracy: 0.5532\n",
      "test: Loss: 0.6978 | F1-score: 0.2338 | AUC ROC: 0.4390 | Accuracy: 0.5042\n",
      "new best model 50\n",
      "Epoch 51/99\n",
      "----------\n",
      "train: Loss: 0.6982 | F1-score: 0.2914 | AUC ROC: 0.4979 | Accuracy: 0.5532\n",
      "test: Loss: 0.6977 | F1-score: 0.2338 | AUC ROC: 0.4408 | Accuracy: 0.5042\n",
      "new best model 51\n",
      "Epoch 52/99\n",
      "----------\n",
      "train: Loss: 0.6910 | F1-score: 0.2933 | AUC ROC: 0.4996 | Accuracy: 0.5574\n",
      "test: Loss: 0.6975 | F1-score: 0.2368 | AUC ROC: 0.4430 | Accuracy: 0.5126\n",
      "new best model 52\n",
      "Epoch 53/99\n",
      "----------\n",
      "train: Loss: 0.6973 | F1-score: 0.2876 | AUC ROC: 0.5006 | Accuracy: 0.5553\n",
      "test: Loss: 0.6974 | F1-score: 0.2400 | AUC ROC: 0.4447 | Accuracy: 0.5210\n",
      "new best model 53\n",
      "Epoch 54/99\n",
      "----------\n",
      "train: Loss: 0.6930 | F1-score: 0.2828 | AUC ROC: 0.5017 | Accuracy: 0.5553\n",
      "test: Loss: 0.6973 | F1-score: 0.2432 | AUC ROC: 0.4447 | Accuracy: 0.5294\n",
      "Epoch 55/99\n",
      "----------\n",
      "train: Loss: 0.6949 | F1-score: 0.2847 | AUC ROC: 0.5029 | Accuracy: 0.5595\n",
      "test: Loss: 0.6971 | F1-score: 0.2432 | AUC ROC: 0.4452 | Accuracy: 0.5294\n",
      "new best model 55\n",
      "Epoch 56/99\n",
      "----------\n",
      "train: Loss: 0.6976 | F1-score: 0.2847 | AUC ROC: 0.5037 | Accuracy: 0.5595\n",
      "test: Loss: 0.6970 | F1-score: 0.2432 | AUC ROC: 0.4452 | Accuracy: 0.5294\n",
      "Epoch 57/99\n",
      "----------\n",
      "train: Loss: 0.6964 | F1-score: 0.2857 | AUC ROC: 0.5050 | Accuracy: 0.5616\n",
      "test: Loss: 0.6969 | F1-score: 0.2400 | AUC ROC: 0.4461 | Accuracy: 0.5210\n",
      "new best model 57\n",
      "Epoch 58/99\n",
      "----------\n",
      "train: Loss: 0.6930 | F1-score: 0.2877 | AUC ROC: 0.5062 | Accuracy: 0.5658\n",
      "test: Loss: 0.6967 | F1-score: 0.2400 | AUC ROC: 0.4474 | Accuracy: 0.5210\n",
      "new best model 58\n",
      "Epoch 59/99\n",
      "----------\n",
      "train: Loss: 0.6934 | F1-score: 0.2897 | AUC ROC: 0.5079 | Accuracy: 0.5699\n",
      "test: Loss: 0.6966 | F1-score: 0.2400 | AUC ROC: 0.4478 | Accuracy: 0.5210\n",
      "new best model 59\n",
      "Epoch 60/99\n",
      "----------\n",
      "train: Loss: 0.6916 | F1-score: 0.2897 | AUC ROC: 0.5087 | Accuracy: 0.5699\n",
      "test: Loss: 0.6965 | F1-score: 0.2432 | AUC ROC: 0.4482 | Accuracy: 0.5294\n",
      "new best model 60\n",
      "Epoch 61/99\n",
      "----------\n",
      "train: Loss: 0.6940 | F1-score: 0.2907 | AUC ROC: 0.5098 | Accuracy: 0.5720\n",
      "test: Loss: 0.6964 | F1-score: 0.2432 | AUC ROC: 0.4496 | Accuracy: 0.5294\n",
      "new best model 61\n",
      "Epoch 62/99\n",
      "----------\n",
      "train: Loss: 0.6937 | F1-score: 0.2917 | AUC ROC: 0.5107 | Accuracy: 0.5741\n",
      "test: Loss: 0.6962 | F1-score: 0.2432 | AUC ROC: 0.4500 | Accuracy: 0.5294\n",
      "new best model 62\n",
      "Epoch 63/99\n",
      "----------\n",
      "train: Loss: 0.6938 | F1-score: 0.2917 | AUC ROC: 0.5123 | Accuracy: 0.5741\n",
      "test: Loss: 0.6961 | F1-score: 0.2432 | AUC ROC: 0.4513 | Accuracy: 0.5294\n",
      "new best model 63\n",
      "Epoch 64/99\n",
      "----------\n",
      "train: Loss: 0.6924 | F1-score: 0.2937 | AUC ROC: 0.5139 | Accuracy: 0.5783\n",
      "test: Loss: 0.6960 | F1-score: 0.2432 | AUC ROC: 0.4526 | Accuracy: 0.5294\n",
      "new best model 64\n",
      "Epoch 65/99\n",
      "----------\n",
      "train: Loss: 0.6903 | F1-score: 0.2937 | AUC ROC: 0.5148 | Accuracy: 0.5783\n",
      "test: Loss: 0.6959 | F1-score: 0.2500 | AUC ROC: 0.4539 | Accuracy: 0.5462\n",
      "new best model 65\n",
      "Epoch 66/99\n",
      "----------\n",
      "train: Loss: 0.6900 | F1-score: 0.2937 | AUC ROC: 0.5161 | Accuracy: 0.5783\n",
      "test: Loss: 0.6958 | F1-score: 0.2500 | AUC ROC: 0.4557 | Accuracy: 0.5462\n",
      "new best model 66\n",
      "Epoch 67/99\n",
      "----------\n",
      "train: Loss: 0.6934 | F1-score: 0.2947 | AUC ROC: 0.5175 | Accuracy: 0.5804\n",
      "test: Loss: 0.6957 | F1-score: 0.2500 | AUC ROC: 0.4561 | Accuracy: 0.5462\n",
      "new best model 67\n",
      "Epoch 68/99\n",
      "----------\n",
      "train: Loss: 0.6911 | F1-score: 0.2947 | AUC ROC: 0.5195 | Accuracy: 0.5804\n",
      "test: Loss: 0.6955 | F1-score: 0.2500 | AUC ROC: 0.4583 | Accuracy: 0.5462\n",
      "new best model 68\n",
      "Epoch 69/99\n",
      "----------\n",
      "train: Loss: 0.6927 | F1-score: 0.2887 | AUC ROC: 0.5207 | Accuracy: 0.5783\n",
      "test: Loss: 0.6954 | F1-score: 0.2500 | AUC ROC: 0.4583 | Accuracy: 0.5462\n",
      "Epoch 70/99\n",
      "----------\n",
      "train: Loss: 0.6932 | F1-score: 0.2887 | AUC ROC: 0.5206 | Accuracy: 0.5783\n",
      "test: Loss: 0.6953 | F1-score: 0.2500 | AUC ROC: 0.4588 | Accuracy: 0.5462\n",
      "new best model 70\n",
      "Epoch 71/99\n",
      "----------\n",
      "train: Loss: 0.6909 | F1-score: 0.2887 | AUC ROC: 0.5227 | Accuracy: 0.5783\n",
      "test: Loss: 0.6952 | F1-score: 0.2500 | AUC ROC: 0.4601 | Accuracy: 0.5462\n",
      "new best model 71\n",
      "Epoch 72/99\n",
      "----------\n",
      "train: Loss: 0.6900 | F1-score: 0.2887 | AUC ROC: 0.5239 | Accuracy: 0.5783\n",
      "test: Loss: 0.6950 | F1-score: 0.2500 | AUC ROC: 0.4614 | Accuracy: 0.5462\n",
      "new best model 72\n",
      "Epoch 73/99\n",
      "----------\n",
      "train: Loss: 0.6892 | F1-score: 0.2887 | AUC ROC: 0.5248 | Accuracy: 0.5783\n",
      "test: Loss: 0.6949 | F1-score: 0.2500 | AUC ROC: 0.4636 | Accuracy: 0.5462\n",
      "new best model 73\n",
      "Epoch 74/99\n",
      "----------\n",
      "train: Loss: 0.6960 | F1-score: 0.2887 | AUC ROC: 0.5272 | Accuracy: 0.5783\n",
      "test: Loss: 0.6948 | F1-score: 0.2500 | AUC ROC: 0.4645 | Accuracy: 0.5462\n",
      "new best model 74\n",
      "Epoch 75/99\n",
      "----------\n",
      "train: Loss: 0.6913 | F1-score: 0.2898 | AUC ROC: 0.5283 | Accuracy: 0.5804\n",
      "test: Loss: 0.6947 | F1-score: 0.2500 | AUC ROC: 0.4654 | Accuracy: 0.5462\n",
      "new best model 75\n",
      "Epoch 76/99\n",
      "----------\n",
      "train: Loss: 0.6900 | F1-score: 0.2898 | AUC ROC: 0.5292 | Accuracy: 0.5804\n",
      "test: Loss: 0.6946 | F1-score: 0.2500 | AUC ROC: 0.4658 | Accuracy: 0.5462\n",
      "new best model 76\n",
      "Epoch 77/99\n",
      "----------\n",
      "train: Loss: 0.6895 | F1-score: 0.2898 | AUC ROC: 0.5299 | Accuracy: 0.5804\n",
      "test: Loss: 0.6945 | F1-score: 0.2500 | AUC ROC: 0.4667 | Accuracy: 0.5462\n",
      "new best model 77\n",
      "Epoch 78/99\n",
      "----------\n",
      "train: Loss: 0.6897 | F1-score: 0.2947 | AUC ROC: 0.5302 | Accuracy: 0.5804\n",
      "test: Loss: 0.6943 | F1-score: 0.2500 | AUC ROC: 0.4675 | Accuracy: 0.5462\n",
      "new best model 78\n",
      "Epoch 79/99\n",
      "----------\n",
      "train: Loss: 0.6942 | F1-score: 0.2947 | AUC ROC: 0.5319 | Accuracy: 0.5804\n",
      "test: Loss: 0.6942 | F1-score: 0.2500 | AUC ROC: 0.4680 | Accuracy: 0.5462\n",
      "new best model 79\n",
      "Epoch 80/99\n",
      "----------\n",
      "train: Loss: 0.6928 | F1-score: 0.2947 | AUC ROC: 0.5330 | Accuracy: 0.5804\n",
      "test: Loss: 0.6941 | F1-score: 0.2500 | AUC ROC: 0.4689 | Accuracy: 0.5462\n",
      "new best model 80\n",
      "Epoch 81/99\n",
      "----------\n",
      "train: Loss: 0.6879 | F1-score: 0.2947 | AUC ROC: 0.5345 | Accuracy: 0.5804\n",
      "test: Loss: 0.6940 | F1-score: 0.2500 | AUC ROC: 0.4706 | Accuracy: 0.5462\n",
      "new best model 81\n",
      "Epoch 82/99\n",
      "----------\n",
      "train: Loss: 0.6897 | F1-score: 0.2947 | AUC ROC: 0.5369 | Accuracy: 0.5804\n",
      "test: Loss: 0.6939 | F1-score: 0.2500 | AUC ROC: 0.4732 | Accuracy: 0.5462\n",
      "new best model 82\n",
      "Epoch 83/99\n",
      "----------\n",
      "train: Loss: 0.6932 | F1-score: 0.2947 | AUC ROC: 0.5369 | Accuracy: 0.5804\n",
      "test: Loss: 0.6938 | F1-score: 0.2500 | AUC ROC: 0.4746 | Accuracy: 0.5462\n",
      "new best model 83\n",
      "Epoch 84/99\n",
      "----------\n",
      "train: Loss: 0.6900 | F1-score: 0.2968 | AUC ROC: 0.5382 | Accuracy: 0.5846\n",
      "test: Loss: 0.6937 | F1-score: 0.2500 | AUC ROC: 0.4746 | Accuracy: 0.5462\n",
      "Epoch 85/99\n",
      "----------\n",
      "train: Loss: 0.6871 | F1-score: 0.2979 | AUC ROC: 0.5393 | Accuracy: 0.5866\n",
      "test: Loss: 0.6936 | F1-score: 0.2466 | AUC ROC: 0.4754 | Accuracy: 0.5378\n",
      "new best model 85\n",
      "Epoch 86/99\n",
      "----------\n",
      "train: Loss: 0.6876 | F1-score: 0.2979 | AUC ROC: 0.5412 | Accuracy: 0.5866\n",
      "test: Loss: 0.6934 | F1-score: 0.2466 | AUC ROC: 0.4768 | Accuracy: 0.5378\n",
      "new best model 86\n",
      "Epoch 87/99\n",
      "----------\n",
      "train: Loss: 0.6921 | F1-score: 0.2979 | AUC ROC: 0.5432 | Accuracy: 0.5866\n",
      "test: Loss: 0.6933 | F1-score: 0.2466 | AUC ROC: 0.4781 | Accuracy: 0.5378\n",
      "new best model 87\n",
      "Epoch 88/99\n",
      "----------\n",
      "train: Loss: 0.6910 | F1-score: 0.2979 | AUC ROC: 0.5440 | Accuracy: 0.5866\n",
      "test: Loss: 0.6932 | F1-score: 0.2466 | AUC ROC: 0.4798 | Accuracy: 0.5378\n",
      "new best model 88\n",
      "Epoch 89/99\n",
      "----------\n",
      "train: Loss: 0.6903 | F1-score: 0.2979 | AUC ROC: 0.5453 | Accuracy: 0.5866\n",
      "test: Loss: 0.6931 | F1-score: 0.2466 | AUC ROC: 0.4811 | Accuracy: 0.5378\n",
      "new best model 89\n",
      "Epoch 90/99\n",
      "----------\n",
      "train: Loss: 0.6850 | F1-score: 0.2979 | AUC ROC: 0.5468 | Accuracy: 0.5866\n",
      "test: Loss: 0.6930 | F1-score: 0.2466 | AUC ROC: 0.4820 | Accuracy: 0.5378\n",
      "new best model 90\n",
      "Epoch 91/99\n",
      "----------\n",
      "train: Loss: 0.6925 | F1-score: 0.2989 | AUC ROC: 0.5476 | Accuracy: 0.5887\n",
      "test: Loss: 0.6928 | F1-score: 0.2466 | AUC ROC: 0.4820 | Accuracy: 0.5378\n",
      "Epoch 92/99\n",
      "----------\n",
      "train: Loss: 0.6922 | F1-score: 0.3050 | AUC ROC: 0.5491 | Accuracy: 0.5908\n",
      "test: Loss: 0.6927 | F1-score: 0.2466 | AUC ROC: 0.4829 | Accuracy: 0.5378\n",
      "new best model 92\n",
      "Epoch 93/99\n",
      "----------\n",
      "train: Loss: 0.6869 | F1-score: 0.3180 | AUC ROC: 0.5504 | Accuracy: 0.5971\n",
      "test: Loss: 0.6926 | F1-score: 0.2466 | AUC ROC: 0.4855 | Accuracy: 0.5378\n",
      "new best model 93\n",
      "Epoch 94/99\n",
      "----------\n",
      "train: Loss: 0.6901 | F1-score: 0.3298 | AUC ROC: 0.5525 | Accuracy: 0.6013\n",
      "test: Loss: 0.6925 | F1-score: 0.2466 | AUC ROC: 0.4864 | Accuracy: 0.5378\n",
      "new best model 94\n",
      "Epoch 95/99\n",
      "----------\n",
      "train: Loss: 0.6885 | F1-score: 0.3298 | AUC ROC: 0.5534 | Accuracy: 0.6013\n",
      "test: Loss: 0.6924 | F1-score: 0.2500 | AUC ROC: 0.4864 | Accuracy: 0.5462\n",
      "Epoch 96/99\n",
      "----------\n",
      "train: Loss: 0.6909 | F1-score: 0.3298 | AUC ROC: 0.5534 | Accuracy: 0.6013\n",
      "test: Loss: 0.6922 | F1-score: 0.2535 | AUC ROC: 0.4873 | Accuracy: 0.5546\n",
      "new best model 96\n",
      "Epoch 97/99\n",
      "----------\n",
      "train: Loss: 0.6887 | F1-score: 0.3310 | AUC ROC: 0.5556 | Accuracy: 0.6033\n",
      "test: Loss: 0.6921 | F1-score: 0.2535 | AUC ROC: 0.4882 | Accuracy: 0.5546\n",
      "new best model 97\n",
      "Epoch 98/99\n",
      "----------\n",
      "train: Loss: 0.6872 | F1-score: 0.3310 | AUC ROC: 0.5567 | Accuracy: 0.6033\n",
      "test: Loss: 0.6920 | F1-score: 0.2535 | AUC ROC: 0.4895 | Accuracy: 0.5546\n",
      "new best model 98\n",
      "Epoch 99/99\n",
      "----------\n",
      "train: Loss: 0.6843 | F1-score: 0.3310 | AUC ROC: 0.5573 | Accuracy: 0.6033\n",
      "test: Loss: 0.6919 | F1-score: 0.2535 | AUC ROC: 0.4886 | Accuracy: 0.5546\n",
      "Evaluating 20240603_1716_2__blood_lr_0.001_auc_roc_0.49.pt\n",
      "F1-score: 0.2535 | Accuracy: 0.5546 | AUC-ROC: 0.4895\n",
      "Proportion of ones in test set: 0.202\n",
      "Proportion of ones predicted in test set:  0.495\n",
      "Proportion of ones in train set: 0.246\n",
      "Proportion of ones predicted in train set:  0.49 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_per_layer_per_MLP = {'ann_s':  [16, 2],\n",
    "                         'ann_m':  [32, 16, 2],\n",
    "                         'ann_l':  [64, 32, 16, 2],\n",
    "                         'ann_xl': [256, 128, 64, 32, 16, 2],\n",
    "                         'ann_xxl': [512, 256, 128, 64, 32, 16, 8, 2], \n",
    "                         'lr':     [2]\n",
    "                         }  # dimension for each layer for each network to train, ignoring input layer size\n",
    "activation_per_layer_per_MLP = {'ann_s':  [nn.ReLU(), None],\n",
    "                                'ann_m':  [nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_l':  [nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_xl': [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_xxl': [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'lr':     [None]\n",
    "                                } # ignore input layer size\n",
    "\n",
    "data_names          = ['blood'] #'adult', 'compas', 'credit', 'german', 'heloc', 'credit']#, 'rcdv', 'student'] # 'lending-club',\n",
    "model_names         = ['lr'] #, 'ann_xxl']#['lr', 'ann_s', 'ann_m', 'ann_l', 'ann_xl']\n",
    "epochs              = 100\n",
    "learning_rate       = 0.001\n",
    "use_class_weighting = True\n",
    "\n",
    "for data_name in data_names:\n",
    "    if data_name == 'beauty':\n",
    "        modality = 'text'\n",
    "    else:\n",
    "        modality = 'tabular'\n",
    "    for model_name in model_names:\n",
    "        print(\"Training:\", model_name, \"on\", data_name)\n",
    "        # Define hyperparameters\n",
    "        exp_id   = getExperimentID()\n",
    "        dir_name = model_name.upper()\n",
    "\n",
    "        # Get the data for training and evaluation\n",
    "        if data_name in ['compas', 'blood', 'beauty']:\n",
    "            download_data = False\n",
    "        else:\n",
    "            download_data = True\n",
    "\n",
    "        loader_train, loader_val, loader_test = return_loaders(data_name=data_name, download=download_data, batch_size=256, scaler='minmax')\n",
    "\n",
    "        X_train, y_train = loader_train.dataset.data, loader_train.dataset.targets.to_numpy()\n",
    "        X_val, y_val     = loader_val.dataset.data, loader_val.dataset.targets.to_numpy()\n",
    "        X_test, y_test   = loader_test.dataset.data, loader_test.dataset.targets.to_numpy()\n",
    "\n",
    "        # Define the model\n",
    "        layer_info_str = '' #empty for lr, fill for ann\n",
    "        for d in dim_per_layer_per_MLP[model_name]:\n",
    "            layer_info_str += str(d) + '_'\n",
    "\n",
    "        model = DefineModel(model_name, dim_per_layer_per_MLP[model_name], activation_per_layer_per_MLP[model_name])\n",
    "        print(model_name)\n",
    "        print('num params', count_parameters(model))\n",
    "        # \n",
    "        # Train the model\n",
    "        best_model_name = training(model, loader_train, loader_val, model_name, dir_name,\n",
    "                                   learning_rate, epochs, data_name, exp_id, layer_info_str, use_class_weighting, modality=modality)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        total_acc, total_f1, total_auc_roc, y_preds_test_flat, y_preds_train_flat = \\\n",
    "            EvaluateNetwork(best_model_name, model_name, dim_per_layer_per_MLP[model_name],\n",
    "                            activation_per_layer_per_MLP[model_name], loader_train, loader_val, use_class_weighting, modality=modality)\n",
    "        \n",
    "        # Save model info\n",
    "        SaveModelInfo(model_name, data_name, model, exp_id, epochs, learning_rate,\n",
    "                      X_train, y_train, X_val, y_val, X_test, y_test, total_f1, total_acc, total_auc_roc,\n",
    "                      loader_val, y_preds_test_flat, loader_train, y_preds_train_flat, layer_info_str,\n",
    "                      use_class_weighting, dim_per_layer_per_MLP[model_name], activation_per_layer_per_MLP[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets:\n",
    "# LR, ANN_S, ANN_M, ANN_L Compas\n",
    "# LR, ANN_S, ANN_M, ANN_L german\n",
    "# LR, ANN_S, ANN_M, ANN_L heloc\n",
    "# LR, ANN_S, ANN_M, ANN_L adult income\n",
    "# synthetic dataset\n",
    "# LR, ANN_S, ANN_M, ANN_L give me some credit (credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T16:46:53.273803Z",
     "start_time": "2023-06-29T16:46:53.195361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed values saved to parsed_values.csv.\n",
      "Parsed values saved to parsed_values.csv.\n",
      "Parsed values saved to parsed_values.csv.\n"
     ]
    }
   ],
   "source": [
    "# gather all the scores and save them\n",
    "import os\n",
    "import csv\n",
    "\n",
    "for model_name in model_names:\n",
    "    folder_path = './models/ClassWeighted/' + model_name.upper() +'/' # Replace with the actual folder path containing the text files\n",
    "    output_file = 'parsed_values.csv'  # Replace with the desired output file name\n",
    "        \n",
    "    # Define the fieldnames for the CSV file\n",
    "    fieldnames = ['data_name', 'F1-score', 'Accuracy', 'AUC-ROC', 'Proportion of ones in test set',\n",
    "                  'Proportion of ones predicted in test set', 'Proportion of ones in train set',\n",
    "                  'Proportion of ones predicted in train set']\n",
    "    \n",
    "    # Create a list to store the parsed values\n",
    "    parsed_values = []\n",
    "    \n",
    "    # Iterate over the text files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):  # Process only text files\n",
    "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "                content = file.read()\n",
    "    \n",
    "                # Extract the required values using string manipulation or regular expressions\n",
    "                data_name = content.split('data_name:')[1].split('\\n')[0]\n",
    "                f1_score = content.split('F1-score: ')[1].split(' |')[0]\n",
    "                accuracy = content.split('Accuracy: ')[1].split(' |')[0]\n",
    "                auc_roc = content.split('AUC-ROC: ')[1].split('\\n')[0]\n",
    "                ones_test = content.split('Proportion of ones in test set: ')[1].split('\\n')[0]\n",
    "                ones_predicted_test = content.split('Proportion of ones predicted in test set: ')[1].split('\\n')[0]\n",
    "                ones_train = content.split('Proportion of ones in train set: ')[1].split('\\n')[0]\n",
    "                ones_predicted_train = content.split('Proportion of ones predicted in train set: ')[1].split('\\n')[0]\n",
    "    \n",
    "                # Append the parsed values to the list\n",
    "                parsed_values.append({\n",
    "                    'data_name': data_name,\n",
    "                    'F1-score': f1_score,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'AUC-ROC': auc_roc,\n",
    "                    'Proportion of ones in test set': ones_test,\n",
    "                    'Proportion of ones predicted in test set': ones_predicted_test,\n",
    "                    'Proportion of ones in train set': ones_train,\n",
    "                    'Proportion of ones predicted in train set': ones_predicted_train\n",
    "                })\n",
    "    \n",
    "            # sort the rows by data_name\n",
    "            parsed_values = sorted(parsed_values, key=lambda k: k['data_name'])\n",
    "            # Write the parsed values to the CSV file\n",
    "            with open(folder_path+output_file, 'w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(parsed_values)\n",
    "            \n",
    "            print(f\"Parsed values saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T16:20:26.642727Z",
     "start_time": "2023-06-29T16:20:26.604427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"20240328_1621_256_128_64_32_16_2_ANN_XL_compas_summaryHyperparametersexp_id:\\t20240328_1621\\ndata_name:\\tcompas\\nmodel_name:\\tann_xl\\nepochs:\\t\\t100\\nlearning_rate:\\t0.001\\n\\nX_train.shape:\\t(3950, 6)\\ny_train.shape:\\t(3950,)\\n\\nX_val.shape:\\t(987, 6)\\ny_val.shape:\\t(987,)\\n\\nX_test.shape:\\t(1235, 6)\\ny_test.shape:\\t(1235,)\\n\\ndim_per_layer:\\t[256, 128, 64, 32, 16, 2]\\nactivation_per_layer:\\t[ReLU(), ReLU(), ReLU(), ReLU(), ReLU(), None]\\n\\nF1-score: 0.8458 | Accuracy: 0.771 | AUC-ROC: 0.828\\n\\nProportion of ones in test set: 0.785\\nProportion of ones predicted in test set: 0.683\\nProportion of ones in train set: 0.822\\nProportion of ones predicted in train set: 0.63\\n\\nArchitecture:\\nOrderedDict([('layers', ModuleList(\\n  (0): Linear(in_features=6, out_features=256, bias=True)\\n  (1): ReLU()\\n  (2): Linear(in_features=256, out_features=128, bias=True)\\n  (3): ReLU()\\n  (4): Linear(in_features=128, out_features=64, bias=True)\\n  (5): ReLU()\\n  (6): Linear(in_features=64, out_features=32, bias=True)\\n  (7): ReLU()\\n  (8): Linear(in_features=32, out_features=16, bias=True)\\n  (9): ReLU()\\n  (10): Linear(in_features=16, out_features=2, bias=True)\\n))])\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
