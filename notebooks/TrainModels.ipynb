{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T07:51:13.615186Z",
     "start_time": "2024-03-29T07:51:13.608733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train a set of models on different OpenXAI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:55.206294Z",
     "start_time": "2024-03-28T22:25:55.203312Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# go up a directory\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:57.946044Z",
     "start_time": "2024-03-28T22:25:56.477839Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import datetime\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "# Data loaders\n",
    "from openxai.dataloader import return_loaders\n",
    "from openxai.ML_Models.LR.model import LogisticRegression\n",
    "import openxai.ML_Models.ANN.MLP as model_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.127480Z",
     "start_time": "2024-03-28T22:25:58.121107Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x106d5b8b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('default')\n",
    "SEED = 3407\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.402042Z",
     "start_time": "2024-03-28T22:25:58.398909Z"
    }
   },
   "outputs": [],
   "source": [
    "def getExperimentID():\n",
    "    date_info = datetime.datetime.now()\n",
    "    testID    = '%d%02d%02d_%02d%02d' % (date_info.year, date_info.month, date_info.day, date_info.hour, date_info.minute)\n",
    "    return testID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.584195Z",
     "start_time": "2024-03-28T22:25:58.575010Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model, loader_train, loader_test, ml_model, dir_name, learning_rate, epochs, dataset, exp_id, layer_info_str, use_class_weighting, modality='tabular'):\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = 'mps'\n",
    "    loaders = {'train': loader_train, 'test': loader_test}\n",
    "\n",
    "    if use_class_weighting: \n",
    "        # Compute class weights\n",
    "        class_counts  = torch.bincount(torch.tensor(loader_train.dataset.targets.to_numpy().astype(np.compat.long)))\n",
    "        total_samples = len(loader_train.dataset)\n",
    "        class_weights = total_samples / (class_counts.float())\n",
    "        class_weights = class_weights.to(device)\n",
    "\n",
    "    # model collector\n",
    "    best_auc_roc = 0\n",
    "\n",
    "    model  = model.to(device)\n",
    "\n",
    "    # declaring optimizer and loss\n",
    "    if use_class_weighting:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # training\n",
    "    for e in range(epochs):\n",
    "        print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluation mode\n",
    "\n",
    "            all_preds  = []\n",
    "            all_labels = []\n",
    "            for i, input_tuple in enumerate(loaders[phase]):\n",
    "                if modality == 'tabular':\n",
    "                    inputs = input_tuple[0].float()\n",
    "                    labels = input_tuple[1]\n",
    "                elif modality == 'text':\n",
    "                    inputs = input_tuple[0]\n",
    "                    # text   = input_tuple[1]  # don't need for training!\n",
    "                    labels = input_tuple[2]\n",
    "                    \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).type(torch.long)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    y_pred = model(inputs)\n",
    "                    loss   = criterion(y_pred.float(), labels.long())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                all_preds.append(y_pred)\n",
    "                all_labels.append(labels)\n",
    "            # statistics\n",
    "            preds = torch.cat(all_preds, dim=0)\n",
    "            labels = torch.cat(all_labels, dim=0).cpu()\n",
    "            \n",
    "            raw_preds      = preds.data[:, 1]\n",
    "            raw_preds_np   = raw_preds.view(-1).cpu().numpy()\n",
    "            class_preds    = raw_preds >= 0.5\n",
    "            class_preds_np = class_preds.view(-1).long().cpu().numpy()\n",
    "            \n",
    "            epoch_loss     = loss.item()\n",
    "            epoch_acc      = accuracy_score(labels.numpy(), class_preds_np)\n",
    "            epoch_f1       = f1_score(labels.numpy(), class_preds_np)\n",
    "            epoch_auc_roc  = roc_auc_score(labels.numpy(), raw_preds_np)\n",
    "\n",
    "            print(f'{phase}: Loss: {epoch_loss:.4f} | F1-score: {epoch_f1:.4f} | AUC ROC: {epoch_auc_roc:.4f} | Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_auc_roc > best_auc_roc:\n",
    "                best_auc_roc = epoch_auc_roc\n",
    "                best_model_name = '{}_{}_{}_{}_{}_auc_roc_{:.2f}.pt'.format(exp_id, layer_info_str, dataset, ml_model, learning_rate, best_auc_roc)\n",
    "                print('new best model', e)\n",
    "                if use_class_weighting:\n",
    "                    fpth = 'models/ClassWeighted/' + dir_name\n",
    "                else:\n",
    "                    fpth = 'models/NotClassWeighted/' + dir_name\n",
    "                if not os.path.isdir(fpth):  # If folder doesn't exist, then create it.\n",
    "                    os.makedirs(fpth)\n",
    "                output_file_path = fpth + '/' + best_model_name\n",
    "                torch.save(model.state_dict(), output_file_path)\n",
    "\n",
    "    return best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T22:25:58.747671Z",
     "start_time": "2024-03-28T22:25:58.743310Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotROC(output_dir, labels, preds, addtlNameInfo=''):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)\n",
    "    auc         = roc_auc_score(labels, preds)\n",
    "    plt.figure(dpi=100)\n",
    "    plt.plot([0,1],[0,1], color='k')\n",
    "    plt.plot([0,0],[0,1], color='k', linestyle='dashed')\n",
    "    plt.plot([0,1],[1,1], color='k', linestyle='dashed')\n",
    "    plt.plot([1,1],[1,0], color='k', linestyle='dashed')\n",
    "    plt.plot([1,0],[0,0], color='k', linestyle='dashed')\n",
    "    plt.plot(fpr, tpr, color='b', label=\"AUC: \" + str(round(auc,2)))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('ROC Curve - ' + addtlNameInfo)\n",
    "    plt.savefig(output_dir + 'ROC_'+addtlNameInfo+'.png', bbox_inches='tight')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:46.231966Z",
     "start_time": "2024-03-28T23:00:46.223416Z"
    }
   },
   "outputs": [],
   "source": [
    "def EvaluateNetwork(best_model_name, model_name, dim_per_layer, activation_per_layer, loader_train, loader_val, \n",
    "                    use_class_weighting, modality='tabular'):\n",
    "    print('Evaluating', best_model_name)\n",
    "\n",
    "    model = DefineModel(model_name, dim_per_layer, activation_per_layer)\n",
    "\n",
    "    if use_class_weighting:\n",
    "        fpth = 'models/ClassWeighted/'\n",
    "    else:\n",
    "        fpth = 'models/NotClassWeighted/'\n",
    "        \n",
    "    model.load_state_dict(torch.load(fpth + model_name.upper() + '/' + best_model_name))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = 'mps'\n",
    "    model  = model.to(device)\n",
    "    model.eval()   # Set model to evaluation mode\n",
    "\n",
    "    all_preds  = []\n",
    "    all_labels = []\n",
    "    for i, input_tuple in enumerate(loader_val):\n",
    "        if modality == 'tabular':\n",
    "            inputs = input_tuple[0].float()\n",
    "            labels = input_tuple[1]\n",
    "        elif modality == 'text':\n",
    "            inputs = input_tuple[0]\n",
    "            # text   = input_tuple[1]  # don't need for evaluation!\n",
    "            labels = input_tuple[2]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).type(torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            y_pred = model(inputs.float())\n",
    "        all_preds.append(y_pred)\n",
    "        all_labels.append(labels)\n",
    "    # statistics\n",
    "    preds  = torch.cat(all_preds, dim=0)\n",
    "    labels = torch.cat(all_labels, dim=0).cpu()\n",
    "    \n",
    "    raw_preds      = preds.data[:, 1]\n",
    "    raw_preds_np   = raw_preds.view(-1).cpu().numpy()\n",
    "    class_preds    = raw_preds >= 0.5\n",
    "    class_preds_np = class_preds.view(-1).long().cpu().numpy()\n",
    "    \n",
    "    total_acc     = accuracy_score(labels.numpy(), class_preds_np)\n",
    "    total_f1      = f1_score(labels.numpy(), class_preds_np)\n",
    "    total_auc_roc = roc_auc_score(labels.numpy(), raw_preds_np)\n",
    "    \n",
    "    y_preds_test = []\n",
    "    for i, input_tuple in enumerate(loader_val):\n",
    "        inputs = input_tuple[0].float().to(device)\n",
    "        y_pred = model(inputs).data\n",
    "        y_pred = y_pred[:, 1]# >= 0.5  # True if bigger than 0.5\n",
    "        y_preds_test.append(y_pred.cpu())  # convert true and false to 1 and 0, respectively.\n",
    "    y_preds_test_flat = np.array([item for sublist in y_preds_test for item in sublist])\n",
    "\n",
    "    y_preds_train = []\n",
    "    for i, input_tuple in enumerate(loader_train):\n",
    "        inputs = input_tuple[0].float().to(device)\n",
    "        y_pred = model(inputs).data\n",
    "        y_pred = y_pred[:, 1]# >= 0.5  # True if bigger than 0.5\n",
    "        y_preds_train.append(y_pred.cpu())  # convert true and false to 1 and 0, respectively.\n",
    "    y_preds_train_flat = np.array([item for sublist in y_preds_train for item in sublist])\n",
    "\n",
    "    return total_acc, total_f1, total_auc_roc, y_preds_test_flat, y_preds_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:46.848682Z",
     "start_time": "2024-03-28T23:00:46.845386Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotConfusionMatrix(labels, preds, num_of_classes, output_dir, addtlNameInfo=''):\n",
    "    preds      = preds >= 0.5\n",
    "    conf_mat   = confusion_matrix(labels, preds, normalize=None)\n",
    "    pathToSave = os.path.join(output_dir + 'ConfusionMatrix_'+addtlNameInfo+'.png')\n",
    "    df_cm      = pd.DataFrame(conf_mat, range(num_of_classes), range(num_of_classes))\n",
    "    \n",
    "    plt.figure(figsize=(12, 9), dpi=100)\n",
    "    plt.title('Confusion Matrix - ' + addtlNameInfo)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    # sn.set(font_scale=2) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 18}, cmap=\"Blues\", fmt='d') # font size\n",
    "    plt.savefig(pathToSave, format = 'png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:47.044359Z",
     "start_time": "2024-03-28T23:00:47.036834Z"
    }
   },
   "outputs": [],
   "source": [
    "def SaveModelInfo(model_name, data_name, model, exp_id, epochs, learning_rate, X_train, y_train, X_val, y_val, X_test, y_test, total_f1, total_acc, total_auc_roc, loader_val, y_preds_test_flat, loader_train, y_preds_train_flat, layer_info_str, use_class_weighting, dim_per_layer='', activation_per_layer=''):\n",
    "    # Save to .txt\n",
    "    if use_class_weighting:\n",
    "        output_dir = 'models/ClassWeighted/' + model_name.upper() + '/'\n",
    "    else:\n",
    "        output_dir = 'models/NotClassWeighted/' + model_name.upper() + '/'\n",
    "    file_name  =  exp_id + '_' + layer_info_str + model_name.upper() + '_' + data_name + '_summary'\n",
    "\n",
    "    fpth = os.path.join(output_dir, file_name+'.txt')\n",
    "    paramTxt = open(fpth, 'w')\n",
    "\n",
    "    paramTxt.write(file_name)\n",
    "    paramTxt.write('Hyperparameters')\n",
    "    paramTxt.write('exp_id:\\t' + exp_id + '\\n')\n",
    "    paramTxt.write('data_name:\\t' + data_name + '\\n')\n",
    "    paramTxt.write('model_name:\\t' + model_name + '\\n')\n",
    "    paramTxt.write('epochs:\\t\\t' + str(epochs) + '\\n')\n",
    "    paramTxt.write('learning_rate:\\t' + str(learning_rate) + '\\n\\n')\n",
    "    paramTxt.write('X_train.shape:\\t' + str(X_train.shape) + '\\n')\n",
    "    paramTxt.write('y_train.shape:\\t' + str(y_train.shape) + '\\n\\n')\n",
    "    paramTxt.write('X_val.shape:\\t' + str(X_val.shape) + '\\n')\n",
    "    paramTxt.write('y_val.shape:\\t' + str(y_val.shape) + '\\n\\n')\n",
    "    paramTxt.write('X_test.shape:\\t' + str(X_test.shape) + '\\n')\n",
    "    paramTxt.write('y_test.shape:\\t' + str(y_test.shape) + '\\n\\n')\n",
    "    paramTxt.write('dim_per_layer:\\t' + str(dim_per_layer) + '\\n')\n",
    "    if 'ann' in model_name:\n",
    "        paramTxt.write('activation_per_layer:\\t' + str(activation_per_layer) + '\\n')\n",
    "    paramTxt.write('\\nF1-score: '+ str(round(total_f1,4)) +' | Accuracy: ' + str(round(total_acc, 4)) + ' | AUC-ROC: ' + str(round(total_auc_roc, 4)) + '\\n\\n')\n",
    "    paramTxt.write(\"Proportion of ones in test set: \" + str(round(np.mean(loader_val.dataset.targets),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones predicted in test set: \" + str(round(np.mean(y_preds_test_flat),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones in train set: \" + str(round(np.mean(loader_train.dataset.targets),3)) + '\\n')\n",
    "    paramTxt.write(\"Proportion of ones predicted in train set: \" + str(round(np.mean(y_preds_train_flat),3)) + '\\n')\n",
    "    paramTxt.write('\\nArchitecture:\\n')\n",
    "    paramTxt.write(str(model.__dict__['_modules']))\n",
    "    paramTxt.close()\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    PlotROC(fpth, y_val, y_preds_test_flat, addtlNameInfo = model_name.upper() + '_' + data_name)\n",
    "    \n",
    "    PlotConfusionMatrix(y_val, y_preds_test_flat, 2, output_dir, addtlNameInfo = model_name.upper() + '_' + data_name)\n",
    "\n",
    "    print(f'F1-score: {total_f1:.4f} | Accuracy: {total_acc:.4f} | AUC-ROC: {total_auc_roc:.4f}')\n",
    "    print(\"Proportion of ones in test set:\", round(np.mean(loader_val.dataset.targets),3))\n",
    "    print(\"Proportion of ones predicted in test set: \", round(np.mean(y_preds_test_flat),3))\n",
    "    print(\"Proportion of ones in train set:\", round(np.mean(loader_train.dataset.targets),3))\n",
    "    print(\"Proportion of ones predicted in train set: \", round(np.mean(y_preds_train_flat),3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T23:00:47.206902Z",
     "start_time": "2024-03-28T23:00:47.204455Z"
    }
   },
   "outputs": [],
   "source": [
    "def DefineModel(model_name, dim_per_layer=None, activation_per_layer=None):\n",
    "    input_size = loader_train.dataset.get_number_of_features()\n",
    "\n",
    "    if 'ann' in model_name:\n",
    "        dim_per_layer = [input_size] + dim_per_layer\n",
    "        model         = model_MLP.MLP(dim_per_layer, activation_per_layer)\n",
    "    elif model_name == 'lr':\n",
    "        dim_per_layer = [input_size] + dim_per_layer\n",
    "        model         = LogisticRegression(dim_per_layer[0], dim_per_layer[1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T01:38:35.640880Z",
     "start_time": "2024-03-29T01:38:35.629600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#get number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T01:39:23.942521Z",
     "start_time": "2024-03-29T01:39:23.890086Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: lr on blood\n",
      "lr\n",
      "num params 10\n",
      "Epoch 0/99\n",
      "----------\n",
      "train: Loss: 0.7136 | F1-score: 0.0000 | AUC ROC: 0.7871 | Accuracy: 0.7537\n",
      "test: Loss: 0.6751 | F1-score: 0.0000 | AUC ROC: 0.7232 | Accuracy: 0.7983\n",
      "new best model 0\n",
      "Epoch 1/99\n",
      "----------\n",
      "train: Loss: 0.7022 | F1-score: 0.0000 | AUC ROC: 0.7870 | Accuracy: 0.7537\n",
      "test: Loss: 0.6749 | F1-score: 0.0000 | AUC ROC: 0.7197 | Accuracy: 0.7983\n",
      "Epoch 2/99\n",
      "----------\n",
      "train: Loss: 0.6992 | F1-score: 0.0000 | AUC ROC: 0.7864 | Accuracy: 0.7537\n",
      "test: Loss: 0.6748 | F1-score: 0.0000 | AUC ROC: 0.7206 | Accuracy: 0.7983\n",
      "Epoch 3/99\n",
      "----------\n",
      "train: Loss: 0.6854 | F1-score: 0.0000 | AUC ROC: 0.7849 | Accuracy: 0.7537\n",
      "test: Loss: 0.6746 | F1-score: 0.0000 | AUC ROC: 0.7241 | Accuracy: 0.7983\n",
      "new best model 3\n",
      "Epoch 4/99\n",
      "----------\n",
      "train: Loss: 0.6898 | F1-score: 0.0000 | AUC ROC: 0.7852 | Accuracy: 0.7537\n",
      "test: Loss: 0.6745 | F1-score: 0.0000 | AUC ROC: 0.7224 | Accuracy: 0.7983\n",
      "Epoch 5/99\n",
      "----------\n",
      "train: Loss: 0.7077 | F1-score: 0.0000 | AUC ROC: 0.7841 | Accuracy: 0.7537\n",
      "test: Loss: 0.6744 | F1-score: 0.0000 | AUC ROC: 0.7197 | Accuracy: 0.7983\n",
      "Epoch 6/99\n",
      "----------\n",
      "train: Loss: 0.6977 | F1-score: 0.0000 | AUC ROC: 0.7824 | Accuracy: 0.7537\n",
      "test: Loss: 0.6742 | F1-score: 0.0000 | AUC ROC: 0.7175 | Accuracy: 0.7983\n",
      "Epoch 7/99\n",
      "----------\n",
      "train: Loss: 0.6980 | F1-score: 0.0000 | AUC ROC: 0.7810 | Accuracy: 0.7537\n",
      "test: Loss: 0.6741 | F1-score: 0.0000 | AUC ROC: 0.7145 | Accuracy: 0.7983\n",
      "Epoch 8/99\n",
      "----------\n",
      "train: Loss: 0.6849 | F1-score: 0.0000 | AUC ROC: 0.7801 | Accuracy: 0.7537\n",
      "test: Loss: 0.6740 | F1-score: 0.0000 | AUC ROC: 0.7127 | Accuracy: 0.7983\n",
      "Epoch 9/99\n",
      "----------\n",
      "train: Loss: 0.6776 | F1-score: 0.0000 | AUC ROC: 0.7783 | Accuracy: 0.7537\n",
      "test: Loss: 0.6738 | F1-score: 0.0000 | AUC ROC: 0.7092 | Accuracy: 0.7983\n",
      "Epoch 10/99\n",
      "----------\n",
      "train: Loss: 0.7163 | F1-score: 0.0000 | AUC ROC: 0.7783 | Accuracy: 0.7537\n",
      "test: Loss: 0.6737 | F1-score: 0.0000 | AUC ROC: 0.7114 | Accuracy: 0.7983\n",
      "Epoch 11/99\n",
      "----------\n",
      "train: Loss: 0.6953 | F1-score: 0.0000 | AUC ROC: 0.7761 | Accuracy: 0.7537\n",
      "test: Loss: 0.6736 | F1-score: 0.0800 | AUC ROC: 0.7092 | Accuracy: 0.8067\n",
      "Epoch 12/99\n",
      "----------\n",
      "train: Loss: 0.6859 | F1-score: 0.0000 | AUC ROC: 0.7745 | Accuracy: 0.7537\n",
      "test: Loss: 0.6735 | F1-score: 0.0800 | AUC ROC: 0.7083 | Accuracy: 0.8067\n",
      "Epoch 13/99\n",
      "----------\n",
      "train: Loss: 0.6918 | F1-score: 0.0000 | AUC ROC: 0.7734 | Accuracy: 0.7537\n",
      "test: Loss: 0.6733 | F1-score: 0.0800 | AUC ROC: 0.7092 | Accuracy: 0.8067\n",
      "Epoch 14/99\n",
      "----------\n",
      "train: Loss: 0.6940 | F1-score: 0.0168 | AUC ROC: 0.7731 | Accuracy: 0.7557\n",
      "test: Loss: 0.6732 | F1-score: 0.0800 | AUC ROC: 0.7083 | Accuracy: 0.8067\n",
      "Epoch 15/99\n",
      "----------\n",
      "train: Loss: 0.6948 | F1-score: 0.0168 | AUC ROC: 0.7720 | Accuracy: 0.7557\n",
      "test: Loss: 0.6731 | F1-score: 0.0800 | AUC ROC: 0.7083 | Accuracy: 0.8067\n",
      "Epoch 16/99\n",
      "----------\n",
      "train: Loss: 0.6944 | F1-score: 0.0168 | AUC ROC: 0.7703 | Accuracy: 0.7557\n",
      "test: Loss: 0.6730 | F1-score: 0.0800 | AUC ROC: 0.7061 | Accuracy: 0.8067\n",
      "Epoch 17/99\n",
      "----------\n",
      "train: Loss: 0.6734 | F1-score: 0.0168 | AUC ROC: 0.7676 | Accuracy: 0.7557\n",
      "test: Loss: 0.6729 | F1-score: 0.0800 | AUC ROC: 0.7022 | Accuracy: 0.8067\n",
      "Epoch 18/99\n",
      "----------\n",
      "train: Loss: 0.6967 | F1-score: 0.0168 | AUC ROC: 0.7681 | Accuracy: 0.7557\n",
      "test: Loss: 0.6727 | F1-score: 0.0800 | AUC ROC: 0.7009 | Accuracy: 0.8067\n",
      "Epoch 19/99\n",
      "----------\n",
      "train: Loss: 0.6978 | F1-score: 0.0168 | AUC ROC: 0.7671 | Accuracy: 0.7557\n",
      "test: Loss: 0.6726 | F1-score: 0.0800 | AUC ROC: 0.6982 | Accuracy: 0.8067\n",
      "Epoch 20/99\n",
      "----------\n",
      "train: Loss: 0.7100 | F1-score: 0.0168 | AUC ROC: 0.7670 | Accuracy: 0.7557\n",
      "test: Loss: 0.6725 | F1-score: 0.0800 | AUC ROC: 0.6982 | Accuracy: 0.8067\n",
      "Epoch 21/99\n",
      "----------\n",
      "train: Loss: 0.6908 | F1-score: 0.0333 | AUC ROC: 0.7648 | Accuracy: 0.7578\n",
      "test: Loss: 0.6724 | F1-score: 0.0800 | AUC ROC: 0.6956 | Accuracy: 0.8067\n",
      "Epoch 22/99\n",
      "----------\n",
      "train: Loss: 0.6869 | F1-score: 0.0492 | AUC ROC: 0.7632 | Accuracy: 0.7578\n",
      "test: Loss: 0.6723 | F1-score: 0.0800 | AUC ROC: 0.6930 | Accuracy: 0.8067\n",
      "Epoch 23/99\n",
      "----------\n",
      "train: Loss: 0.7011 | F1-score: 0.0492 | AUC ROC: 0.7633 | Accuracy: 0.7578\n",
      "test: Loss: 0.6722 | F1-score: 0.0800 | AUC ROC: 0.6952 | Accuracy: 0.8067\n",
      "Epoch 24/99\n",
      "----------\n",
      "train: Loss: 0.6804 | F1-score: 0.0492 | AUC ROC: 0.7614 | Accuracy: 0.7578\n",
      "test: Loss: 0.6721 | F1-score: 0.0800 | AUC ROC: 0.6947 | Accuracy: 0.8067\n",
      "Epoch 25/99\n",
      "----------\n",
      "train: Loss: 0.6894 | F1-score: 0.0492 | AUC ROC: 0.7608 | Accuracy: 0.7578\n",
      "test: Loss: 0.6720 | F1-score: 0.0800 | AUC ROC: 0.6939 | Accuracy: 0.8067\n",
      "Epoch 26/99\n",
      "----------\n",
      "train: Loss: 0.6999 | F1-score: 0.0650 | AUC ROC: 0.7599 | Accuracy: 0.7599\n",
      "test: Loss: 0.6719 | F1-score: 0.0800 | AUC ROC: 0.6921 | Accuracy: 0.8067\n",
      "Epoch 27/99\n",
      "----------\n",
      "train: Loss: 0.6793 | F1-score: 0.0650 | AUC ROC: 0.7584 | Accuracy: 0.7599\n",
      "test: Loss: 0.6718 | F1-score: 0.0800 | AUC ROC: 0.6908 | Accuracy: 0.8067\n",
      "Epoch 28/99\n",
      "----------\n",
      "train: Loss: 0.6827 | F1-score: 0.0650 | AUC ROC: 0.7569 | Accuracy: 0.7599\n",
      "test: Loss: 0.6717 | F1-score: 0.0800 | AUC ROC: 0.6895 | Accuracy: 0.8067\n",
      "Epoch 29/99\n",
      "----------\n",
      "train: Loss: 0.7020 | F1-score: 0.0650 | AUC ROC: 0.7571 | Accuracy: 0.7599\n",
      "test: Loss: 0.6716 | F1-score: 0.0800 | AUC ROC: 0.6877 | Accuracy: 0.8067\n",
      "Epoch 30/99\n",
      "----------\n",
      "train: Loss: 0.6573 | F1-score: 0.0650 | AUC ROC: 0.7540 | Accuracy: 0.7599\n",
      "test: Loss: 0.6715 | F1-score: 0.0800 | AUC ROC: 0.6877 | Accuracy: 0.8067\n",
      "Epoch 31/99\n",
      "----------\n",
      "train: Loss: 0.6983 | F1-score: 0.0650 | AUC ROC: 0.7562 | Accuracy: 0.7599\n",
      "test: Loss: 0.6714 | F1-score: 0.0800 | AUC ROC: 0.6868 | Accuracy: 0.8067\n",
      "Epoch 32/99\n",
      "----------\n",
      "train: Loss: 0.6931 | F1-score: 0.0650 | AUC ROC: 0.7546 | Accuracy: 0.7599\n",
      "test: Loss: 0.6714 | F1-score: 0.0800 | AUC ROC: 0.6868 | Accuracy: 0.8067\n",
      "Epoch 33/99\n",
      "----------\n",
      "train: Loss: 0.6906 | F1-score: 0.0650 | AUC ROC: 0.7535 | Accuracy: 0.7599\n",
      "test: Loss: 0.6713 | F1-score: 0.0800 | AUC ROC: 0.6868 | Accuracy: 0.8067\n",
      "Epoch 34/99\n",
      "----------\n",
      "train: Loss: 0.6916 | F1-score: 0.0650 | AUC ROC: 0.7530 | Accuracy: 0.7599\n",
      "test: Loss: 0.6712 | F1-score: 0.0800 | AUC ROC: 0.6851 | Accuracy: 0.8067\n",
      "Epoch 35/99\n",
      "----------\n",
      "train: Loss: 0.6759 | F1-score: 0.0650 | AUC ROC: 0.7519 | Accuracy: 0.7599\n",
      "test: Loss: 0.6711 | F1-score: 0.0800 | AUC ROC: 0.6816 | Accuracy: 0.8067\n",
      "Epoch 36/99\n",
      "----------\n",
      "train: Loss: 0.6885 | F1-score: 0.0650 | AUC ROC: 0.7518 | Accuracy: 0.7599\n",
      "test: Loss: 0.6710 | F1-score: 0.0800 | AUC ROC: 0.6811 | Accuracy: 0.8067\n",
      "Epoch 37/99\n",
      "----------\n",
      "train: Loss: 0.6946 | F1-score: 0.0650 | AUC ROC: 0.7507 | Accuracy: 0.7599\n",
      "test: Loss: 0.6709 | F1-score: 0.0800 | AUC ROC: 0.6781 | Accuracy: 0.8067\n",
      "Epoch 38/99\n",
      "----------\n",
      "train: Loss: 0.6891 | F1-score: 0.0650 | AUC ROC: 0.7505 | Accuracy: 0.7599\n",
      "test: Loss: 0.6709 | F1-score: 0.0800 | AUC ROC: 0.6781 | Accuracy: 0.8067\n",
      "Epoch 39/99\n",
      "----------\n",
      "train: Loss: 0.6985 | F1-score: 0.0650 | AUC ROC: 0.7501 | Accuracy: 0.7599\n",
      "test: Loss: 0.6708 | F1-score: 0.0800 | AUC ROC: 0.6776 | Accuracy: 0.8067\n",
      "Epoch 40/99\n",
      "----------\n",
      "train: Loss: 0.6814 | F1-score: 0.0650 | AUC ROC: 0.7492 | Accuracy: 0.7599\n",
      "test: Loss: 0.6707 | F1-score: 0.0800 | AUC ROC: 0.6750 | Accuracy: 0.8067\n",
      "Epoch 41/99\n",
      "----------\n",
      "train: Loss: 0.6964 | F1-score: 0.0650 | AUC ROC: 0.7485 | Accuracy: 0.7599\n",
      "test: Loss: 0.6706 | F1-score: 0.0800 | AUC ROC: 0.6737 | Accuracy: 0.8067\n",
      "Epoch 42/99\n",
      "----------\n",
      "train: Loss: 0.6933 | F1-score: 0.0806 | AUC ROC: 0.7489 | Accuracy: 0.7620\n",
      "test: Loss: 0.6706 | F1-score: 0.0800 | AUC ROC: 0.6728 | Accuracy: 0.8067\n",
      "Epoch 43/99\n",
      "----------\n",
      "train: Loss: 0.6702 | F1-score: 0.0806 | AUC ROC: 0.7458 | Accuracy: 0.7620\n",
      "test: Loss: 0.6705 | F1-score: 0.0800 | AUC ROC: 0.6763 | Accuracy: 0.8067\n",
      "Epoch 44/99\n",
      "----------\n",
      "train: Loss: 0.6936 | F1-score: 0.0806 | AUC ROC: 0.7476 | Accuracy: 0.7620\n",
      "test: Loss: 0.6704 | F1-score: 0.0800 | AUC ROC: 0.6754 | Accuracy: 0.8067\n",
      "Epoch 45/99\n",
      "----------\n",
      "train: Loss: 0.6989 | F1-score: 0.0806 | AUC ROC: 0.7462 | Accuracy: 0.7620\n",
      "test: Loss: 0.6704 | F1-score: 0.0800 | AUC ROC: 0.6754 | Accuracy: 0.8067\n",
      "Epoch 46/99\n",
      "----------\n",
      "train: Loss: 0.6879 | F1-score: 0.0806 | AUC ROC: 0.7442 | Accuracy: 0.7620\n",
      "test: Loss: 0.6703 | F1-score: 0.0800 | AUC ROC: 0.6759 | Accuracy: 0.8067\n",
      "Epoch 47/99\n",
      "----------\n",
      "train: Loss: 0.7003 | F1-score: 0.0806 | AUC ROC: 0.7441 | Accuracy: 0.7620\n",
      "test: Loss: 0.6702 | F1-score: 0.0800 | AUC ROC: 0.6750 | Accuracy: 0.8067\n",
      "Epoch 48/99\n",
      "----------\n",
      "train: Loss: 0.6734 | F1-score: 0.0806 | AUC ROC: 0.7423 | Accuracy: 0.7620\n",
      "test: Loss: 0.6702 | F1-score: 0.0800 | AUC ROC: 0.6728 | Accuracy: 0.8067\n",
      "Epoch 49/99\n",
      "----------\n",
      "train: Loss: 0.6835 | F1-score: 0.0806 | AUC ROC: 0.7426 | Accuracy: 0.7620\n",
      "test: Loss: 0.6701 | F1-score: 0.0800 | AUC ROC: 0.6711 | Accuracy: 0.8067\n",
      "Epoch 50/99\n",
      "----------\n",
      "train: Loss: 0.6898 | F1-score: 0.0806 | AUC ROC: 0.7420 | Accuracy: 0.7620\n",
      "test: Loss: 0.6700 | F1-score: 0.0800 | AUC ROC: 0.6711 | Accuracy: 0.8067\n",
      "Epoch 51/99\n",
      "----------\n",
      "train: Loss: 0.6885 | F1-score: 0.0800 | AUC ROC: 0.7415 | Accuracy: 0.7599\n",
      "test: Loss: 0.6700 | F1-score: 0.0800 | AUC ROC: 0.6715 | Accuracy: 0.8067\n",
      "Epoch 52/99\n",
      "----------\n",
      "train: Loss: 0.6791 | F1-score: 0.0800 | AUC ROC: 0.7408 | Accuracy: 0.7599\n",
      "test: Loss: 0.6699 | F1-score: 0.0800 | AUC ROC: 0.6715 | Accuracy: 0.8067\n",
      "Epoch 53/99\n",
      "----------\n",
      "train: Loss: 0.6836 | F1-score: 0.0800 | AUC ROC: 0.7397 | Accuracy: 0.7599\n",
      "test: Loss: 0.6699 | F1-score: 0.0800 | AUC ROC: 0.6711 | Accuracy: 0.8067\n",
      "Epoch 54/99\n",
      "----------\n",
      "train: Loss: 0.6821 | F1-score: 0.0952 | AUC ROC: 0.7403 | Accuracy: 0.7620\n",
      "test: Loss: 0.6698 | F1-score: 0.0800 | AUC ROC: 0.6702 | Accuracy: 0.8067\n",
      "Epoch 55/99\n",
      "----------\n",
      "train: Loss: 0.6638 | F1-score: 0.0952 | AUC ROC: 0.7384 | Accuracy: 0.7620\n",
      "test: Loss: 0.6698 | F1-score: 0.0800 | AUC ROC: 0.6689 | Accuracy: 0.8067\n",
      "Epoch 56/99\n",
      "----------\n",
      "train: Loss: 0.6988 | F1-score: 0.0952 | AUC ROC: 0.7398 | Accuracy: 0.7620\n",
      "test: Loss: 0.6697 | F1-score: 0.0800 | AUC ROC: 0.6689 | Accuracy: 0.8067\n",
      "Epoch 57/99\n",
      "----------\n",
      "train: Loss: 0.6838 | F1-score: 0.0952 | AUC ROC: 0.7384 | Accuracy: 0.7620\n",
      "test: Loss: 0.6697 | F1-score: 0.0800 | AUC ROC: 0.6684 | Accuracy: 0.8067\n",
      "Epoch 58/99\n",
      "----------\n",
      "train: Loss: 0.6681 | F1-score: 0.0952 | AUC ROC: 0.7374 | Accuracy: 0.7620\n",
      "test: Loss: 0.6696 | F1-score: 0.0800 | AUC ROC: 0.6675 | Accuracy: 0.8067\n",
      "Epoch 59/99\n",
      "----------\n",
      "train: Loss: 0.6898 | F1-score: 0.0952 | AUC ROC: 0.7378 | Accuracy: 0.7620\n",
      "test: Loss: 0.6696 | F1-score: 0.0800 | AUC ROC: 0.6662 | Accuracy: 0.8067\n",
      "Epoch 60/99\n",
      "----------\n",
      "train: Loss: 0.6862 | F1-score: 0.0945 | AUC ROC: 0.7371 | Accuracy: 0.7599\n",
      "test: Loss: 0.6695 | F1-score: 0.0800 | AUC ROC: 0.6662 | Accuracy: 0.8067\n",
      "Epoch 61/99\n",
      "----------\n",
      "train: Loss: 0.6777 | F1-score: 0.0945 | AUC ROC: 0.7361 | Accuracy: 0.7599\n",
      "test: Loss: 0.6695 | F1-score: 0.0800 | AUC ROC: 0.6675 | Accuracy: 0.8067\n",
      "Epoch 62/99\n",
      "----------\n",
      "train: Loss: 0.6882 | F1-score: 0.0945 | AUC ROC: 0.7375 | Accuracy: 0.7599\n",
      "test: Loss: 0.6694 | F1-score: 0.0800 | AUC ROC: 0.6662 | Accuracy: 0.8067\n",
      "Epoch 63/99\n",
      "----------\n",
      "train: Loss: 0.6621 | F1-score: 0.0945 | AUC ROC: 0.7356 | Accuracy: 0.7599\n",
      "test: Loss: 0.6694 | F1-score: 0.0800 | AUC ROC: 0.6662 | Accuracy: 0.8067\n",
      "Epoch 64/99\n",
      "----------\n",
      "train: Loss: 0.6831 | F1-score: 0.0945 | AUC ROC: 0.7360 | Accuracy: 0.7599\n",
      "test: Loss: 0.6693 | F1-score: 0.0800 | AUC ROC: 0.6654 | Accuracy: 0.8067\n",
      "Epoch 65/99\n",
      "----------\n",
      "train: Loss: 0.6936 | F1-score: 0.0945 | AUC ROC: 0.7367 | Accuracy: 0.7599\n",
      "test: Loss: 0.6693 | F1-score: 0.0769 | AUC ROC: 0.6654 | Accuracy: 0.7983\n",
      "Epoch 66/99\n",
      "----------\n",
      "train: Loss: 0.6829 | F1-score: 0.0945 | AUC ROC: 0.7350 | Accuracy: 0.7599\n",
      "test: Loss: 0.6692 | F1-score: 0.0769 | AUC ROC: 0.6654 | Accuracy: 0.7983\n",
      "Epoch 67/99\n",
      "----------\n",
      "train: Loss: 0.6884 | F1-score: 0.0938 | AUC ROC: 0.7346 | Accuracy: 0.7578\n",
      "test: Loss: 0.6692 | F1-score: 0.0769 | AUC ROC: 0.6654 | Accuracy: 0.7983\n",
      "Epoch 68/99\n",
      "----------\n",
      "train: Loss: 0.6811 | F1-score: 0.0930 | AUC ROC: 0.7337 | Accuracy: 0.7557\n",
      "test: Loss: 0.6692 | F1-score: 0.0769 | AUC ROC: 0.6605 | Accuracy: 0.7983\n",
      "Epoch 69/99\n",
      "----------\n",
      "train: Loss: 0.6925 | F1-score: 0.0930 | AUC ROC: 0.7319 | Accuracy: 0.7557\n",
      "test: Loss: 0.6691 | F1-score: 0.1481 | AUC ROC: 0.6601 | Accuracy: 0.8067\n",
      "Epoch 70/99\n",
      "----------\n",
      "train: Loss: 0.6823 | F1-score: 0.0930 | AUC ROC: 0.7308 | Accuracy: 0.7557\n",
      "test: Loss: 0.6691 | F1-score: 0.1481 | AUC ROC: 0.6583 | Accuracy: 0.8067\n",
      "Epoch 71/99\n",
      "----------\n",
      "train: Loss: 0.6830 | F1-score: 0.0930 | AUC ROC: 0.7305 | Accuracy: 0.7557\n",
      "test: Loss: 0.6691 | F1-score: 0.1481 | AUC ROC: 0.6583 | Accuracy: 0.8067\n",
      "Epoch 72/99\n",
      "----------\n",
      "train: Loss: 0.6825 | F1-score: 0.0930 | AUC ROC: 0.7284 | Accuracy: 0.7557\n",
      "test: Loss: 0.6690 | F1-score: 0.1481 | AUC ROC: 0.6583 | Accuracy: 0.8067\n",
      "Epoch 73/99\n",
      "----------\n",
      "train: Loss: 0.6805 | F1-score: 0.1077 | AUC ROC: 0.7295 | Accuracy: 0.7578\n",
      "test: Loss: 0.6690 | F1-score: 0.1481 | AUC ROC: 0.6561 | Accuracy: 0.8067\n",
      "Epoch 74/99\n",
      "----------\n",
      "train: Loss: 0.6832 | F1-score: 0.1077 | AUC ROC: 0.7281 | Accuracy: 0.7578\n",
      "test: Loss: 0.6690 | F1-score: 0.1481 | AUC ROC: 0.6557 | Accuracy: 0.8067\n",
      "Epoch 75/99\n",
      "----------\n",
      "train: Loss: 0.6878 | F1-score: 0.1221 | AUC ROC: 0.7286 | Accuracy: 0.7599\n",
      "test: Loss: 0.6689 | F1-score: 0.1481 | AUC ROC: 0.6561 | Accuracy: 0.8067\n",
      "Epoch 76/99\n",
      "----------\n",
      "train: Loss: 0.6760 | F1-score: 0.1353 | AUC ROC: 0.7272 | Accuracy: 0.7599\n",
      "test: Loss: 0.6689 | F1-score: 0.1481 | AUC ROC: 0.6553 | Accuracy: 0.8067\n",
      "Epoch 77/99\n",
      "----------\n",
      "train: Loss: 0.6723 | F1-score: 0.1353 | AUC ROC: 0.7270 | Accuracy: 0.7599\n",
      "test: Loss: 0.6689 | F1-score: 0.2069 | AUC ROC: 0.6539 | Accuracy: 0.8067\n",
      "Epoch 78/99\n",
      "----------\n",
      "train: Loss: 0.6828 | F1-score: 0.1353 | AUC ROC: 0.7271 | Accuracy: 0.7599\n",
      "test: Loss: 0.6688 | F1-score: 0.2069 | AUC ROC: 0.6535 | Accuracy: 0.8067\n",
      "Epoch 79/99\n",
      "----------\n",
      "train: Loss: 0.6855 | F1-score: 0.1353 | AUC ROC: 0.7270 | Accuracy: 0.7599\n",
      "test: Loss: 0.6688 | F1-score: 0.2069 | AUC ROC: 0.6535 | Accuracy: 0.8067\n",
      "Epoch 80/99\n",
      "----------\n",
      "train: Loss: 0.6779 | F1-score: 0.1353 | AUC ROC: 0.7265 | Accuracy: 0.7599\n",
      "test: Loss: 0.6688 | F1-score: 0.2667 | AUC ROC: 0.6535 | Accuracy: 0.8151\n",
      "Epoch 81/99\n",
      "----------\n",
      "train: Loss: 0.6905 | F1-score: 0.1353 | AUC ROC: 0.7262 | Accuracy: 0.7599\n",
      "test: Loss: 0.6687 | F1-score: 0.2667 | AUC ROC: 0.6518 | Accuracy: 0.8151\n",
      "Epoch 82/99\n",
      "----------\n",
      "train: Loss: 0.6855 | F1-score: 0.1353 | AUC ROC: 0.7260 | Accuracy: 0.7599\n",
      "test: Loss: 0.6687 | F1-score: 0.2667 | AUC ROC: 0.6513 | Accuracy: 0.8151\n",
      "Epoch 83/99\n",
      "----------\n",
      "train: Loss: 0.6889 | F1-score: 0.1353 | AUC ROC: 0.7259 | Accuracy: 0.7599\n",
      "test: Loss: 0.6687 | F1-score: 0.2667 | AUC ROC: 0.6513 | Accuracy: 0.8151\n",
      "Epoch 84/99\n",
      "----------\n",
      "train: Loss: 0.6688 | F1-score: 0.1481 | AUC ROC: 0.7245 | Accuracy: 0.7599\n",
      "test: Loss: 0.6687 | F1-score: 0.2667 | AUC ROC: 0.6513 | Accuracy: 0.8151\n",
      "Epoch 85/99\n",
      "----------\n",
      "train: Loss: 0.6629 | F1-score: 0.1481 | AUC ROC: 0.7242 | Accuracy: 0.7599\n",
      "test: Loss: 0.6686 | F1-score: 0.2667 | AUC ROC: 0.6509 | Accuracy: 0.8151\n",
      "Epoch 86/99\n",
      "----------\n",
      "train: Loss: 0.6796 | F1-score: 0.1481 | AUC ROC: 0.7249 | Accuracy: 0.7599\n",
      "test: Loss: 0.6686 | F1-score: 0.2667 | AUC ROC: 0.6504 | Accuracy: 0.8151\n",
      "Epoch 87/99\n",
      "----------\n",
      "train: Loss: 0.6803 | F1-score: 0.1481 | AUC ROC: 0.7244 | Accuracy: 0.7599\n",
      "test: Loss: 0.6686 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 88/99\n",
      "----------\n",
      "train: Loss: 0.6633 | F1-score: 0.1481 | AUC ROC: 0.7238 | Accuracy: 0.7599\n",
      "test: Loss: 0.6686 | F1-score: 0.2500 | AUC ROC: 0.6487 | Accuracy: 0.7983\n",
      "Epoch 89/99\n",
      "----------\n",
      "train: Loss: 0.6813 | F1-score: 0.1481 | AUC ROC: 0.7239 | Accuracy: 0.7599\n",
      "test: Loss: 0.6685 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 90/99\n",
      "----------\n",
      "train: Loss: 0.6780 | F1-score: 0.1471 | AUC ROC: 0.7235 | Accuracy: 0.7578\n",
      "test: Loss: 0.6685 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 91/99\n",
      "----------\n",
      "train: Loss: 0.6706 | F1-score: 0.1471 | AUC ROC: 0.7236 | Accuracy: 0.7578\n",
      "test: Loss: 0.6685 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 92/99\n",
      "----------\n",
      "train: Loss: 0.6843 | F1-score: 0.1471 | AUC ROC: 0.7245 | Accuracy: 0.7578\n",
      "test: Loss: 0.6685 | F1-score: 0.2500 | AUC ROC: 0.6496 | Accuracy: 0.7983\n",
      "Epoch 93/99\n",
      "----------\n",
      "train: Loss: 0.6714 | F1-score: 0.1471 | AUC ROC: 0.7238 | Accuracy: 0.7578\n",
      "test: Loss: 0.6684 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 94/99\n",
      "----------\n",
      "train: Loss: 0.6767 | F1-score: 0.1594 | AUC ROC: 0.7234 | Accuracy: 0.7578\n",
      "test: Loss: 0.6684 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 95/99\n",
      "----------\n",
      "train: Loss: 0.6727 | F1-score: 0.1727 | AUC ROC: 0.7232 | Accuracy: 0.7599\n",
      "test: Loss: 0.6684 | F1-score: 0.2500 | AUC ROC: 0.6504 | Accuracy: 0.7983\n",
      "Epoch 96/99\n",
      "----------\n",
      "train: Loss: 0.6804 | F1-score: 0.1714 | AUC ROC: 0.7235 | Accuracy: 0.7578\n",
      "test: Loss: 0.6684 | F1-score: 0.2500 | AUC ROC: 0.6500 | Accuracy: 0.7983\n",
      "Epoch 97/99\n",
      "----------\n",
      "train: Loss: 0.6794 | F1-score: 0.1714 | AUC ROC: 0.7234 | Accuracy: 0.7578\n",
      "test: Loss: 0.6684 | F1-score: 0.2353 | AUC ROC: 0.6496 | Accuracy: 0.7815\n",
      "Epoch 98/99\n",
      "----------\n",
      "train: Loss: 0.6655 | F1-score: 0.1714 | AUC ROC: 0.7232 | Accuracy: 0.7578\n",
      "test: Loss: 0.6683 | F1-score: 0.2353 | AUC ROC: 0.6522 | Accuracy: 0.7815\n",
      "Epoch 99/99\n",
      "----------\n",
      "train: Loss: 0.6848 | F1-score: 0.1714 | AUC ROC: 0.7240 | Accuracy: 0.7578\n",
      "test: Loss: 0.6683 | F1-score: 0.2353 | AUC ROC: 0.6522 | Accuracy: 0.7815\n",
      "Evaluating 20240520_2000_2__blood_lr_0.001_auc_roc_0.72.pt\n",
      "F1-score: 0.0000 | Accuracy: 0.7983 | AUC-ROC: 0.7241\n",
      "Proportion of ones in test set: 0.202\n",
      "Proportion of ones predicted in test set:  0.306\n",
      "Proportion of ones in train set: 0.246\n",
      "Proportion of ones predicted in train set:  0.305 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_per_layer_per_MLP = {'ann_s':  [16, 2],\n",
    "                         'ann_m':  [32, 16, 2],\n",
    "                         'ann_l':  [64, 32, 16, 2],\n",
    "                         'ann_xl': [256, 128, 64, 32, 16, 2],\n",
    "                         'ann_xxl': [512, 256, 128, 64, 32, 16, 8, 2], \n",
    "                         'lr':     [2]\n",
    "                         }  # dimension for each layer for each network to train, ignoring input layer size\n",
    "activation_per_layer_per_MLP = {'ann_s':  [nn.ReLU(), None],\n",
    "                                'ann_m':  [nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_l':  [nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_xl': [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'ann_xxl': [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU(), None],\n",
    "                                'lr':     [None]\n",
    "                                } # ignore input layer size\n",
    "\n",
    "data_names          = ['blood'] #'adult', 'compas', 'credit', 'german', 'heloc', 'credit']#, 'rcdv', 'student'] # 'lending-club',\n",
    "model_names         = ['lr'] #, 'ann_xxl']#['lr', 'ann_s', 'ann_m', 'ann_l', 'ann_xl']\n",
    "epochs              = 100\n",
    "learning_rate       = 0.001\n",
    "use_class_weighting = True\n",
    "\n",
    "for data_name in data_names:\n",
    "    if data_name == 'beauty':\n",
    "        modality = 'text'\n",
    "    else:\n",
    "        modality = 'tabular'\n",
    "    for model_name in model_names:\n",
    "        print(\"Training:\", model_name, \"on\", data_name)\n",
    "        # Define hyperparameters\n",
    "        exp_id   = getExperimentID()\n",
    "        dir_name = model_name.upper()\n",
    "\n",
    "        # Get the data for training and evaluation\n",
    "        if data_name in ['compas', 'blood', 'beauty']:\n",
    "            download_data = False\n",
    "        else:\n",
    "            download_data = True\n",
    "\n",
    "        loader_train, loader_val, loader_test = return_loaders(data_name=data_name, download=download_data, batch_size=256, scaler='minmax')\n",
    "\n",
    "        X_train, y_train = loader_train.dataset.data, loader_train.dataset.targets.to_numpy()\n",
    "        X_val, y_val     = loader_val.dataset.data, loader_val.dataset.targets.to_numpy()\n",
    "        X_test, y_test   = loader_test.dataset.data, loader_test.dataset.targets.to_numpy()\n",
    "\n",
    "        # Define the model\n",
    "        layer_info_str = '' #empty for lr, fill for ann\n",
    "        for d in dim_per_layer_per_MLP[model_name]:\n",
    "            layer_info_str += str(d) + '_'\n",
    "\n",
    "        model = DefineModel(model_name, dim_per_layer_per_MLP[model_name], activation_per_layer_per_MLP[model_name])\n",
    "        print(model_name)\n",
    "        print('num params', count_parameters(model))\n",
    "        # \n",
    "        # Train the model\n",
    "        best_model_name = training(model, loader_train, loader_val, model_name, dir_name,\n",
    "                                   learning_rate, epochs, data_name, exp_id, layer_info_str, use_class_weighting, modality=modality)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        total_acc, total_f1, total_auc_roc, y_preds_test_flat, y_preds_train_flat = \\\n",
    "            EvaluateNetwork(best_model_name, model_name, dim_per_layer_per_MLP[model_name],\n",
    "                            activation_per_layer_per_MLP[model_name], loader_train, loader_val, use_class_weighting, modality=modality)\n",
    "        \n",
    "        # Save model info\n",
    "        SaveModelInfo(model_name, data_name, model, exp_id, epochs, learning_rate,\n",
    "                      X_train, y_train, X_val, y_val, X_test, y_test, total_f1, total_acc, total_auc_roc,\n",
    "                      loader_val, y_preds_test_flat, loader_train, y_preds_train_flat, layer_info_str,\n",
    "                      use_class_weighting, dim_per_layer_per_MLP[model_name], activation_per_layer_per_MLP[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets:\n",
    "# LR, ANN_S, ANN_M, ANN_L Compas\n",
    "# LR, ANN_S, ANN_M, ANN_L german\n",
    "# LR, ANN_S, ANN_M, ANN_L heloc\n",
    "# LR, ANN_S, ANN_M, ANN_L adult income\n",
    "# synthetic dataset\n",
    "# LR, ANN_S, ANN_M, ANN_L give me some credit (credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T16:46:53.273803Z",
     "start_time": "2023-06-29T16:46:53.195361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed values saved to parsed_values.csv.\n",
      "Parsed values saved to parsed_values.csv.\n",
      "Parsed values saved to parsed_values.csv.\n"
     ]
    }
   ],
   "source": [
    "# gather all the scores and save them\n",
    "import os\n",
    "import csv\n",
    "\n",
    "for model_name in model_names:\n",
    "    folder_path = './models/ClassWeighted/' + model_name.upper() +'/' # Replace with the actual folder path containing the text files\n",
    "    output_file = 'parsed_values.csv'  # Replace with the desired output file name\n",
    "        \n",
    "    # Define the fieldnames for the CSV file\n",
    "    fieldnames = ['data_name', 'F1-score', 'Accuracy', 'AUC-ROC', 'Proportion of ones in test set',\n",
    "                  'Proportion of ones predicted in test set', 'Proportion of ones in train set',\n",
    "                  'Proportion of ones predicted in train set']\n",
    "    \n",
    "    # Create a list to store the parsed values\n",
    "    parsed_values = []\n",
    "    \n",
    "    # Iterate over the text files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):  # Process only text files\n",
    "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "                content = file.read()\n",
    "    \n",
    "                # Extract the required values using string manipulation or regular expressions\n",
    "                data_name = content.split('data_name:')[1].split('\\n')[0]\n",
    "                f1_score = content.split('F1-score: ')[1].split(' |')[0]\n",
    "                accuracy = content.split('Accuracy: ')[1].split(' |')[0]\n",
    "                auc_roc = content.split('AUC-ROC: ')[1].split('\\n')[0]\n",
    "                ones_test = content.split('Proportion of ones in test set: ')[1].split('\\n')[0]\n",
    "                ones_predicted_test = content.split('Proportion of ones predicted in test set: ')[1].split('\\n')[0]\n",
    "                ones_train = content.split('Proportion of ones in train set: ')[1].split('\\n')[0]\n",
    "                ones_predicted_train = content.split('Proportion of ones predicted in train set: ')[1].split('\\n')[0]\n",
    "    \n",
    "                # Append the parsed values to the list\n",
    "                parsed_values.append({\n",
    "                    'data_name': data_name,\n",
    "                    'F1-score': f1_score,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'AUC-ROC': auc_roc,\n",
    "                    'Proportion of ones in test set': ones_test,\n",
    "                    'Proportion of ones predicted in test set': ones_predicted_test,\n",
    "                    'Proportion of ones in train set': ones_train,\n",
    "                    'Proportion of ones predicted in train set': ones_predicted_train\n",
    "                })\n",
    "    \n",
    "            # sort the rows by data_name\n",
    "            parsed_values = sorted(parsed_values, key=lambda k: k['data_name'])\n",
    "            # Write the parsed values to the CSV file\n",
    "            with open(folder_path+output_file, 'w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(parsed_values)\n",
    "            \n",
    "            print(f\"Parsed values saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T16:20:26.642727Z",
     "start_time": "2023-06-29T16:20:26.604427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"20240328_1621_256_128_64_32_16_2_ANN_XL_compas_summaryHyperparametersexp_id:\\t20240328_1621\\ndata_name:\\tcompas\\nmodel_name:\\tann_xl\\nepochs:\\t\\t100\\nlearning_rate:\\t0.001\\n\\nX_train.shape:\\t(3950, 6)\\ny_train.shape:\\t(3950,)\\n\\nX_val.shape:\\t(987, 6)\\ny_val.shape:\\t(987,)\\n\\nX_test.shape:\\t(1235, 6)\\ny_test.shape:\\t(1235,)\\n\\ndim_per_layer:\\t[256, 128, 64, 32, 16, 2]\\nactivation_per_layer:\\t[ReLU(), ReLU(), ReLU(), ReLU(), ReLU(), None]\\n\\nF1-score: 0.8458 | Accuracy: 0.771 | AUC-ROC: 0.828\\n\\nProportion of ones in test set: 0.785\\nProportion of ones predicted in test set: 0.683\\nProportion of ones in train set: 0.822\\nProportion of ones predicted in train set: 0.63\\n\\nArchitecture:\\nOrderedDict([('layers', ModuleList(\\n  (0): Linear(in_features=6, out_features=256, bias=True)\\n  (1): ReLU()\\n  (2): Linear(in_features=256, out_features=128, bias=True)\\n  (3): ReLU()\\n  (4): Linear(in_features=128, out_features=64, bias=True)\\n  (5): ReLU()\\n  (6): Linear(in_features=64, out_features=32, bias=True)\\n  (7): ReLU()\\n  (8): Linear(in_features=32, out_features=16, bias=True)\\n  (9): ReLU()\\n  (10): Linear(in_features=16, out_features=2, bias=True)\\n))])\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
